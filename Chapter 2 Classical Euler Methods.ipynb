{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Euler methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    " 1. Chapter 2: Classical Methods\n",
    "    1. [Section 1.1: Explicit Euler](#explicitEuler)\n",
    "    1. [Section 1.2: Implicit Euler](#implicitEuler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading/installing packages\n",
    "\n",
    "# This is the basic package in python with all the numerical functions\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    %pip install numpy\n",
    "    import numpy as np\n",
    "\n",
    "# This package allows to  plot\n",
    "try:\n",
    "    import matplotlib.pyplot as plt \n",
    "except ImportError:\n",
    "    %pip install matplotlib\n",
    "    import matplotlib.pyplot as plt \n",
    "\n",
    "#This package already implemented some functions for Runge Kutta and multistep methods\n",
    "try:\n",
    "    from nodepy import rk\n",
    "except ImportError:\n",
    "    %pip install nodepy\n",
    "    from nodepy import rk\n",
    "\n",
    "# This package has some functions to deal with polynomials\n",
    "try:\n",
    "    from scipy import optimize\n",
    "except ImportError:\n",
    "    %pip install scipy\n",
    "    from scipy import optimize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to **approximate** the ODE on $I:=[t_0, t_{end}]\\subset \\mathbb{R}$ for the unknown variable $y:I\\to \\mathbb{R}^{S}$ with *continuous* function $F:I\\times \\mathbb{R}^S\\to\\mathbb{R}^S$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{cases}\n",
    "\\frac{dy}{dt} = F(t,y(t)),\\\\\n",
    "y(0)=y_0.\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* Why approximate? Solution may be unknown, or too complicated to be solved analytically.\n",
    "* How we want to approximate? We want to be **accurate** and we want to preserve the physical properties we have seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit Euler <a id='explicitEuler'></a>\n",
    "\n",
    "Consider the time interval $I=[t_0,t_{end}]$ and let us subdivide it into $N$ subintervals, \n",
    "\n",
    "$$t_0=t^0<t^1< \\dots <t^n < \\dots <t^N=t_{end}.$$\n",
    "\n",
    "We approximate naïvely the integral form\n",
    "\n",
    "$$ y(t^{n+1})=y(t^n) +\\int_{t^n}^{t^{n+1}} F(s,y(s))ds \\approx y(t^n) -\\underbrace{(t^{n+1}-t^n)}_{\\Delta t^n} F(t^n,y(t^n)) $$\n",
    "\n",
    "leading to the method (forward Euler/explicit Euler), where we use $y^n$ to approximate $y(t^n)$\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "y^0=y_0,\\\\\n",
    "y^{n+1}=y^n+\\Delta t^n F(t^n,y^n), \\qquad n=0,\\dots, N-1.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple implementation of the method\n",
    "# Input are F, (t^0,...,t^N), y_0\n",
    "def explicitEuler(func, tspan, y_0):\n",
    "    '''\n",
    "    Simple implementation of the explicit Euler method\n",
    "    Input are \n",
    "    func the function F of the ODE which takes as input y and t F(y,t)\n",
    "    tspan is the vector of all timesteps (t^0,...,t^N)\n",
    "    y_0 is the initial condition\n",
    "    '''\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)          # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions    \n",
    "    y[:,0]=y_0                 # first timestep \n",
    "    for n in range(N_time-1):    # n=0,..., N-1\n",
    "        y[:,n+1]=y[:,n]+ FILL IN THE EVOLUTION ## Code the explicit euler step\n",
    "    return tspan, y "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on \n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\begin{cases}\n",
    "c_1'(t)=c_2(t)-5c_1(t),\\\\\n",
    "c_2'(t)=5c_1(t)-c_2(t),\n",
    "\\end{cases}\n",
    "\\end{equation*}\n",
    "$$\n",
    "with \n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\begin{cases}\n",
    " c_1(0)=c_1^0=0.9, \\quad  &c_2(0)=c_2^0=0.1,  \\\\\n",
    " t\\in [0,3].\n",
    " \\end{cases}\n",
    "\\end{equation*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the function F\n",
    "def linSysF(y,t=0):\n",
    "    # evolution function \n",
    "    F=np.zeros(np.shape(y))\n",
    "    F[0] = FILL IN THE DEFINITION\n",
    "    F[1] = FILL IN THE DEFINITION\n",
    "    return F\n",
    "\n",
    "## Now we plot the solution with different number of timesteps\n",
    "for N in [100,30,10]:\n",
    "    tspan=np.linspace(0,3,N)\n",
    "    y0=np.array([0.9,0.1])\n",
    "\n",
    "    tt,yy=explicitEuler(linSysF,tspan,y0)\n",
    "\n",
    "    A=np.array([[-5,1],[5,-1]])\n",
    "\n",
    "    y_exact=np.zeros((len(y0),len(tt)))\n",
    "    for it, t in enumerate(tt):\n",
    "        y_exact[:,it]=y0+(1-np.exp(-6*t))/6*np.dot(A,y0)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(tt,y_exact[0,:],\":\", label=\"c1 ex\")\n",
    "    plt.plot(tt,y_exact[1,:],\":\", label=\"c2 ex\")\n",
    "\n",
    "    plt.plot(tt,yy[0,:],label=\"c1\")\n",
    "    plt.plot(tt,yy[1,:],label=\"c2\")\n",
    "    plt.title(\"N=%d\"%N)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary, we can observe that\n",
    "1. The more the points we put in the time discretization the better the solution gets\n",
    "1. Explicit Euler does not preserve **unconditionally** the positivity of the solution ($N=10$)\n",
    "1. The total mass is conserved \n",
    "\n",
    "$$ c_1^{n+1}+c_2^{n+1}=c_1^{n}+c_2^{n}+ \\Delta t\\left( -5c_1^{n}+c_2^{n}+5c_1^{n}-c_2^{n} \\right) = c_1^{n}+c_2^{n} $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis\n",
    "The error that we observe \n",
    "$$e_n=y(t^n)-y^n$$\n",
    "\n",
    "is composed of several parts that we can divide and study separately.\n",
    "\n",
    "#### Consistency error\n",
    "Given the exact solution $y(t)$, we define the consistency error to be\n",
    "\n",
    "$$\n",
    "\\varepsilon_n = y(t^{n+1})-y(t^n) - \\Delta t F(t^n,y(t^n)) = \\int_{t^n}^{t^{n+1}} y'(t) -y'(t^n)\\, dt.\n",
    "$$\n",
    "\n",
    "Notice that $|\\varepsilon_n|\\leq \\Delta t \\omega (y',\\Delta t)$, where $\\omega$ is the modulus of continuity of a bounded function, i.e.,\n",
    "$$\n",
    "\\omega(f,\\Delta t):= \\max_{t,t': |t-t'|\\leq \\Delta t} |f(t)-f(t')|.\n",
    "$$\n",
    "\n",
    "Essentially, this is the error that we obtain by substituting the exact solution inside the method. It is one of the 2 ingredients that leads the error of a method.\n",
    "\n",
    "Going back to the error, we observe that\n",
    "\n",
    "$$\n",
    "e_{n+1}=y(t^{n+1})-y^{n+1}=e_n +\\varepsilon_n +\\Delta t \\big(f(t^n,y(t^n))-f(t^n,y^n)\\big)\n",
    "$$\n",
    "\n",
    "using the Lipschitz continuity of $f$, we have\n",
    "\n",
    "$$\n",
    "|e_{n+1}|\\leq |e_n| +|\\varepsilon_n| +\\Delta t L|y(t^n)-y^n| =(1+L\\Delta t)|e_n| +|\\varepsilon_n|.\n",
    "$$\n",
    "\n",
    "Using the **Discrete Gronwall Lemma** we obtain that\n",
    "\n",
    "$$\n",
    "|e_{n}|\\leq e^{L|t^n-t^0|}|e_0| + \\sum_{i=0}^{n-1} e^{L(t^n-t^{i+1})}|\\varepsilon_i|.\n",
    "$$\n",
    "\n",
    "This tells us that, except for the initial error (that usually we can bound accurately or know its error), the consistency error leads this sum. So, if we keep $\\varepsilon_n$ small enough, the final error will be small enough. \n",
    "\n",
    "\n",
    "Using the estimation for $\\varepsilon_i$ and suppose $\\Delta t^n=\\Delta t$, we can collect\n",
    "$$\n",
    "\\begin{align}\n",
    "|e_{n}|&\\leq e^{L|t^n-t^0|}|e_0| + \\Delta t \\omega(y',\\Delta t) \\sum_{i=0}^{n-1} e^{L(t^n-t^{i+1})}\\\\\n",
    "&\\leq e^{L|t^n-t^0|}|y^0-y(t^0)| + \\Delta t \\omega(y',\\Delta t) \\frac{e^{L(t^n-t^{0})}-1}{L}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This shows that the solution converges to the exact one as $\\Delta t \\to 0$, if the initial datum is correct. \n",
    "\n",
    "\n",
    "If we know more on the regularity of the solution ($y\\in \\mathcal C^2$), we can say that\n",
    "\n",
    "$$\n",
    "|y(t^n)-y^n|\\leq e^{L(t^n-t^0)}|y^0-y(t^0)| + \\Delta t \\int_{t^0}^{t^n} e^{L(t^n-s)} |y''(s)| ds.\n",
    "$$\n",
    "\n",
    "\n",
    "#### Local vs Global Error\n",
    "A small remark must be done in order to understand how the global error generates from the local one.\n",
    "The local truncation error is the one given for one time step, i.e., using Taylor expansion and supposing $y^0=y(t^0)$,\n",
    "\n",
    "$$\n",
    "e_1=|y^1-y(t^1)|=|y^0 +\\Delta t F(t^0,y^0) - \\left(y(t^0) + \\Delta t y'(t^0) + \\frac{1}{2} \\Delta t^2 y''(t^0)\\right) + \\mathcal{O}(\\Delta t^3)| = \\frac{1}{2} \\Delta t^2 |y''(t^0)| +  \\mathcal{O}(\\Delta t^3).\n",
    "$$\n",
    "\n",
    "In one step we see an error of $\\mathcal O (\\Delta t^2)$, when integrating of the whole time interval $[t^0,t^N]$ one obtains an $\\mathcal O (\\Delta t)$ as we have seen before.\n",
    "\n",
    "Naïvely one can see it as if in every step we are adding an $\\mathcal O (\\Delta t^2)$ to the global error\n",
    "\n",
    "$$\n",
    "e_N\\approx \\sum_{i=1}^N |y(t^i)-y^i| \\approx N \\Delta t^2 \\max_{t\\in [t^0,t^N]} |y''(t)| = \\frac{t^N-t^0}{\\Delta t} \\Delta t^2\\max_{t\\in [t^0,t^N]} |y''(t)|= (t^N-t^0) \\Delta t\\max_{t\\in [t^0,t^N]} |y''(t)|\n",
    "$$\n",
    "\n",
    "The **order of accuracy** of a method is the largest *integer* $p$, such that the error can be bounded by\n",
    "\n",
    "$$\n",
    "|e_N| \\leq C \\Delta t^p, \\qquad \\forall \\Delta t \\in \\mathbb R ^+.\n",
    "$$\n",
    "\n",
    "This definition is of course meant to be verified in the limit for $\\Delta t\\to 0$ (in realistic cases we stop at $\\approx 10^{-14}$).\n",
    "\n",
    "The explicit Euler method is of order (at least) 1. (one can check that it is not 2 with numerical tests)\n",
    "\n",
    "\n",
    "#### Roundoff effects\n",
    "We should always keep in mind that the error we studied before is not the only one that a computer produces. \n",
    "Indeed, at each operation (initial value, evaluation of $F$, sums, products) we introduce a roundoff error due to the machine precision.\n",
    "One can get similar estimations to what we have seen before, knowing that the error can be controlled.\n",
    "\n",
    "\n",
    "We ignore this error in this course.\n",
    "\n",
    "### Stability\n",
    "Question: going with $\\Delta t \\to 0$ should produce nice results, but, what can we say about $\\Delta t >>0$?\n",
    "Can we give a qualitatively say when a method could be stable/reliable in particular when *stiff* problems are considered. *Stiff* problems are the ones for which a \"*normal*\" discretization can not produce decent results.\n",
    "\n",
    "This rough description can be made more precise and studied only in limited cases. In particular, we restrict to linear problems with constant coefficients.\n",
    "\n",
    "$$\n",
    "y'(t)=My(t)\n",
    "$$\n",
    "\n",
    "with $M$ constant matrix. We fix the timestep $\\Delta t$. The explicit Euler method gives the update\n",
    "\n",
    "$$\n",
    "y^{n}=y^{n-1}+\\Delta t M y^{n-1} =(I+\\Delta t M) y^{n-1} = (I+\\Delta t M)^{n} y^0.\n",
    "$$\n",
    "\n",
    "Doing a change of basis given by the nonsingular matrix $S$ so that  $\\hat{M}=S^{-1} M S$ is in the Jordan canonical form, and defining $\\hat{y}^n=S^{-1} y^n$, we have that\n",
    "\n",
    "$$\n",
    "\\hat y^{n}=\\hat y^{n-1}+\\Delta t \\hat M \\hat{y}^{n-1} =(I+\\Delta t \\hat M) \\hat{y}^{n-1} = (I+\\Delta t \\hat M)^{n} \\hat{y}^0.\n",
    "$$\n",
    "\n",
    "This means that for each distinct eigenvalue $q \\in \\mathbb C$ we can study the linear scalar equation \n",
    "\n",
    "$$\n",
    "y'(t)= q  y(t).\n",
    "$$\n",
    "\n",
    "The other components that correspond to the same Jordan block will depend on this solution, but will not contribute to its behaviour.\n",
    "\n",
    "The final question is whether $(1+\\Delta t q)^N$ is an *acceptable* approximation of $e^{N\\Delta t q }$.\n",
    "\n",
    "We are interested in bounded behaviors for $N\\to \\infty$ , this implies that $|1+\\Delta t q|\\leq 1$, or that $Re(q)\\leq 0$. ($q$ could be complex as it is an eigenvalue of $M$).\n",
    "\n",
    "Rewriting the problem with $z=q\\Delta t$, one can see that \n",
    "\n",
    "$$\n",
    "y^n=y^{n-1}+z y^{n-1}=(1+z)y^{n-1}\n",
    "$$\n",
    "\n",
    "and the method will be stable if\n",
    "$|1+z|\\leq 1$, which is the region in the complex plane denoted by a circle of radius 1 with center in $(-1,0)$.\n",
    "\n",
    "The function $R(z):=1+z$ for the explicit Euler is the *stability function*.\n",
    "For a general method for the Dahlquist's equation\n",
    "\n",
    "$$\n",
    "y'(t)=qy(t)\n",
    "$$\n",
    "\n",
    "denoting by $z=\\Delta t q$, the method can be written as\n",
    "\n",
    "$$\n",
    "y^{n+1}=R(z) y^n.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will see soon how to write a RK method\n",
    "## This is the explicit Euler method written into the RK formalism \n",
    "## and we plot the stability region using the nodepy module\n",
    "A=np.array([[0]])\n",
    "b=np.array([1])\n",
    "exEuler=rk.ExplicitRungeKuttaMethod(A,b)\n",
    "p,q=exEuler.stability_function()\n",
    "print(p)\n",
    "exEuler.plot_stability_region();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How can we ensure the belonging to the stability region?\n",
    "We want $z=q\\Delta t$ to stay in the stability region. On $q$ we do not have control, hence, we can only modify $\\Delta t$. \n",
    "In particular, denoting $q=p+ir$ with $p,r \\in \\mathbb R $ and $p\\leq 0$, the stability relation we have seen before leads to at least check that the real part verifies the relation\n",
    "\n",
    "$$\n",
    "|1+\\Delta t p + i \\Delta t r|\\leq 1 \\\\\n",
    "1-\\Delta t |p|  \\geq 1\\\\\n",
    "\\Delta t \\leq \\frac{2}{|p|}\n",
    "$$\n",
    "\n",
    "where $|p|$ is for sure bounded by the Lipschitz constant $L$ of the function $F$.\n",
    "\n",
    "So, it is necessary to check that\n",
    "\n",
    "$$\n",
    "\\Delta t \\leq \\frac{2}{L}.\n",
    "$$\n",
    "\n",
    "This can be generalized also for nonlinear problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imaginary eigenvalues\n",
    "If the problem we are considering contains only imaginary eigenvalues, then we cannot solve it with explicit Euler method. \n",
    "An example is\n",
    "\n",
    "$$\n",
    "u''=-u\n",
    "$$\n",
    "\n",
    "Consider the exact solution\n",
    "\n",
    "$$\n",
    "u=\\sin(t)\n",
    "$$\n",
    "\n",
    "So, we can put it into a system of first order ODEs with initial conditions\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "u'=v,\\\\\n",
    "v'=-u,\\\\\n",
    "u(0) = 0,\\\\\n",
    "v(0) = 1.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function F\n",
    "def linSysF(y,t=0):\n",
    "    # evolution function \n",
    "    F=np.zeros(np.shape(y))\n",
    "    F[0] = y[1]\n",
    "    F[1] = -y[0]\n",
    "    return F\n",
    "\n",
    "## Now we plot the solution with different number of timesteps\n",
    "dt = 1\n",
    "T_end = 100\n",
    "\n",
    "tspan=np.linspace(0,T_end,np.int(T_end/dt)+1)\n",
    "y0=np.array([0,1])\n",
    "\n",
    "tt,yy=explicitEuler(linSysF,tspan,y0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tt,np.sin(tt),\":\", label=\"c1 ex\")\n",
    "\n",
    "plt.plot(tt,yy[0,:],label=\"c1\")\n",
    "plt.title(\"N=%d\"%N)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(tt,yy[0,:]-np.sin(tt))\n",
    "plt.title(\"Error\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit Euler <a id='implicitEuler'></a>\n",
    "\n",
    "The implicit Euler method approximates our problem with the following strategy\n",
    "\n",
    "$$\n",
    "y^{n+1}=y^n +\\Delta t f(t^{n+1},y^{n+1}).\n",
    "$$\n",
    "\n",
    "1. It is not always easy to find the solution of such method, for example when $f$ is nonlinear, one may need nonlinear solvers to find the solution (e.g. Newton method, Broyden, and so on)\n",
    "1. We can compute the error estimate similarly to explicit Euler, obtaining that also implicit Euler is a *first* order method\n",
    "1. More interesting are the **stability** property of this scheme.\n",
    "\n",
    "Consider again the Dahlquist's equation\n",
    "\n",
    "$$y'=qy$$\n",
    "\n",
    "and the implicit Euler method\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y^{n+1}=y^n+ \\Delta t q y^{n+1},\\\\\n",
    "(1-\\Delta t q) y^{n+1}=y^n,\\\\\n",
    "y^{n+1}=\\frac{1}{1-\\Delta t q} y^n.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So the stability function is $R(z)=\\frac{1}{1-z}$ and the stability region $\\mathcal S := \\lbrace z \\in \\mathbb C : |R(z)|\\leq 1 \\rbrace$ contains the whole left complex semiplane. Indeed, if $Re(z)\\leq 0,$ then $Re(1-z)\\geq 1$ and $|1-z|\\geq 1$.\n",
    "So, $R(z)\\leq 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## We will see soon how to write a RK method\n",
    "## This is the implicit Euler and we plot the stability region\n",
    "A=np.array([[1]])\n",
    "b=np.array([1])\n",
    "imEuler=rk.RungeKuttaMethod(A,b)\n",
    "p,q=imEuler.stability_function()\n",
    "print(p) ## Numerator\n",
    "print(q) ## Denominator\n",
    "imEuler.plot_stability_region(bounds=[-10,4, -5,5]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear problems and implicit methods\n",
    "Differently from the explicit methods, the implicit methods require the solution of possibly nonlinear systems of equations, as the flux $f$ is evaluated in the unknown value $f(u^{n+1})$. This requires the use of nonlinear solvers when $f$ is nonlinear and this can require some extra computational effort.\n",
    "\n",
    "#### Newton's method for implicit Euler\n",
    "The simplest way of dealing with nonlinear problems is using Newton's method.\n",
    "To solve $$y^{n+1} = y^n+ \\Delta t f(t^{n+1},y^{n+1})$$\n",
    "one can proceed iteratively as\n",
    "$$\n",
    "u^{(k+1)} =  u^{(k)}- [I-\\Delta t Jf(u^{(k)})]^{-1}(u^{(k)}-y^n-\\Delta t f(t^{n+1},u^{(k)})),\n",
    "$$\n",
    "with $Jf$ being the Jacobian in $y$ of $f(t,y)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positivity of implicit Euler\n",
    "\n",
    "#### Unconditionally TVD/positivity preserving\n",
    "For some class of linear problems, it can be shown that for positive systems it is **positivity preserving**, or more in general for finite difference method in hyperbolic conservation laws, it is total variation diminishing (TVD).\n",
    "\n",
    "The clou is that these properties are true independently on the size of $\\Delta t$.\n",
    "\n",
    "For TVD one can read the SSPRK article by Gottlieb, Shu and Tadmor [link](https://www.researchgate.net/publication/2365594_Strong_Stability-Preserving_High-Order_Time_Discretization_Methods).\n",
    "\n",
    "##### TVD for incremental form problem\n",
    "The implicit Euler method for incremental problems, i.e.,\n",
    "$$\n",
    "U^{n+1}_j=U^{n}_j +\\Delta t \\left [ C_{j+1/2}(U_{j+1}^{n+1}-U_{j}^{n+1})-D_{j-1/2}(U_{j}^{n+1}-U_{j-1}^{n+1}) \\right]\n",
    "$$\n",
    "\n",
    "where $C_{j+1/2},D_{j+1/2}\\geq 0$ is TVD independently on $\\Delta t$.\n",
    "\n",
    "###### Proof (Harten)\n",
    "Define \n",
    "\n",
    "$$\n",
    "TV(U^n) = \\sum_j |U^n_{j+1}-U^n_j|.\n",
    "$$\n",
    "\n",
    "We can compute\n",
    "\\begin{align*}\n",
    "U^{n+1}_j&=U^{n}_j +\\Delta t \\left[ C_{j+1/2}(U_{j+1}^{n+1}-U_{j}^{n+1})-D_{j-1/2}(U_{j}^{n+1}-U_{j-1}^{n+1}) \\right]\\\\\n",
    "\\left[ 1+\\Delta t (C_{j+1/2}+D_{j+1/2}) \\right](U^{n+1}_{j+1}-U_j^{n+1})&=U^{n}_{j+1}-U_j^{n} +\\Delta t \\left[ C_{j+3/2}(U_{j+2}^{n+1}-U_{j+1}^{n+1})+D_{j-1/2}(U_{j}^{n+1}-U_{j-1}^{n+1}) \\right]\\\\\n",
    "\\left[1+\\Delta t (C_{j+1/2}+D_{j+1/2})\\right] \\lvert U^{n+1}_{j+1}-U_j^{n+1}\\rvert &\\leq \\lvert U^{n}_{j+1}-U_j^{n} \\rvert +\\Delta t \\left[ C_{j+3/2} \\lvert U_{j+2}^{n+1}-U_{j+1}^{n+1} \\rvert  +D_{j-1/2} \\lvert U_{j}^{n+1}-U_{j-1}^{n+1}\\rvert \\right]\\\\\n",
    "TV(U^{n+1}) +\\Delta t \\sum_j(C_{j+1/2}+D_{j+1/2})|U^{n+1}_{j+1}-U^{n+1}_j| &\\leq TV(U^{n}) +\\Delta t \\sum_j(C_{j+1/2}+D_{j+1/2})|U^{n+1}_{j+1}-U^{n+1}_j| \\\\\n",
    "TV(U^{n+1}) &\\leq TV(U^n).\n",
    "\\end{align*}\n",
    "\n",
    "Reminder: Total variation diminishing means for conservation laws, that if the initial solution is positive, it stays positive."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Positivity for production destruction system\n",
    "We will see the positivity for a specific case: a production-destruction system with constant coefficient. It can be written as\n",
    "\n",
    "$$\n",
    "y'=My\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\n",
    "M_{ii}<0,\\qquad M_{ij}\\geq 0,\\, i\\neq j, \\qquad \\sum_{i}M_{ij}=0.\n",
    "$$\n",
    "\n",
    "The linear system at the beginning of this chapter falls in this example.\n",
    "\n",
    "This system is positive if $y_i^0\\geq 0$. The implicit Euler is also positive.\n",
    "\n",
    "$$\n",
    "(I-\\Delta t M)y^{n+1}= y^{n}\n",
    "$$\n",
    "\n",
    "##### Theorem\n",
    "Defining with $A:=I-\\Delta t M$, we can prove that $A$ is non singular and that $A^{-1}\\geq 0$, i.e., every entry of the matrix is nonnegative.\n",
    "\n",
    "##### Proof\n",
    "1. $A$ is strictly diagonally dominant by columns\n",
    "Indeed, \n",
    "\n",
    "$$\n",
    "0< A_{ii} = 1+\\Delta t |M_{ii}| > \\Delta t \\sum_{j:j\\neq i} |M_{ji}| = \\sum_{j:j\\neq i} |A_{ji}|\n",
    "$$\n",
    "\n",
    "Hence, $A$ is nonsingular.\n",
    "\n",
    "2. The Jacobi method converges and the Jacobi Matrix is positive [Jacobi method](https://en.wikipedia.org/wiki/Jacobi_method)\n",
    "\n",
    "\n",
    "Define the Jacobi matrix $B=D^{-1}(D-A)$, with $D=\\text{diag}(A)$.\n",
    "The diagonal of $B$ is 0 and each element on the off diagonal terms are\n",
    "\n",
    "$$\n",
    "B_{ji}=\\frac{-A_{ji}}{A_{ii}}, \\quad j\\neq i. \n",
    "$$\n",
    "\n",
    "So, the spectral radius of $B$ is bounded by\n",
    "\n",
    "$$\n",
    "\\rho(B)\\leq ||B||_{\\infty} =\\max_{i}\\sum_{j\\neq i} \\frac{|A_{ji}|}{|A_{ii}|} \\leq 1.\n",
    "$$\n",
    "\n",
    "The iterative Jacobi method is convergent to the solution of $Ay^{n+1}=y^n$.\n",
    "\n",
    "The method reads\n",
    "\n",
    "$$\n",
    "w^{(k+1)}=D^{-1}(y^n- (D-A)w^{(k)})\n",
    "$$\n",
    "\n",
    "which is a linear combination of positive matrices and vectors. Hence, the solutions $w^{(k)}$ stay positive if $y^n$ is positive. Knowing that $Dy^{n+1}=(D-A)y^{n+1} +y^n$, the error at each iteration reads\n",
    "\n",
    "$$\n",
    "e^{(k+1)}:=w^{(k+1)}-y^{n+1} = D^{-1}(y^n- (D-A)w^{(k)})-D^{-1}(y^n- (D-A)y^{n+1})=D^{-1}(D-A)(w^{(k)}-y^{n+1})= B e^{(k)}.\n",
    "$$\n",
    "\n",
    "Knowing that $B$ has norm smaller than 1, we know that the iteration process converges to the solution of the system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement implicit Euler for linear systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicitEulerLinear(M, tspan, y_0):\n",
    "    '''\n",
    "    Simple implementation of the implicit Euler for Linear systems y'=My with M constant matrix\n",
    "    Input are \n",
    "    M the ODE constant matrix\n",
    "    tspan vector of timesteps (t^0,...,t^N)\n",
    "    y_0 initial value\n",
    "    '''\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)        # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions    \n",
    "    y[:,0]=y_0                 # first timestep \n",
    "    for n in range(N_time-1):    # n=0,..., N-1\n",
    "        A= FILL IN # define the matrix that need to be inverted\n",
    "        y[:,n+1]=np.linalg.solve(A,y[:,n])\n",
    "    return tspan, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test implicit Euler on the linear systems: first the production destruction system with matrix\n",
    "linSysM=np.array([[-5,1],[5,-1]])\n",
    "\n",
    "def linSysF(y,t=0):\n",
    "    # evolution function \n",
    "    F=np.zeros(np.shape(y))\n",
    "    F[0] = FILL IN THE EVOLUTION\n",
    "    F[1] = FILL IN THE EVOLUTION\n",
    "    return F\n",
    "\n",
    "\n",
    "for N in [100,30,10]: #testing different number of timesteps\n",
    "    tspan=np.linspace(0,3,N)  # timesteps between 0 and 3\n",
    "    y0=np.array([0.9,0.1])    # initial condition\n",
    "\n",
    "    tt,yy=implicitEulerLinear(linSysM,tspan,y0)  # method implicit euler\n",
    "\n",
    "    A=np.array([[-5,1],[5,-1]])    # Matrix of the system to plot the exact solution\n",
    "\n",
    "    y_exact=np.zeros((len(y0),len(tt)))\n",
    "    for it, t in enumerate(tt): # exact solution at time t\n",
    "        y_exact[:,it]=y0+(1-np.exp(-6*t))/6*np.dot(A,y0)\n",
    "\n",
    "    plt.figure() # plotting exact solution\n",
    "    plt.plot(tt,y_exact[0,:],\":\", label=\"c1 ex\")\n",
    "    plt.plot(tt,y_exact[1,:],\":\", label=\"c2 ex\")\n",
    "    # plotting implicit euler approximation\n",
    "    plt.plot(tt,yy[0,:],label=\"c1\")\n",
    "    plt.plot(tt,yy[1,:],label=\"c2\")\n",
    "    plt.title(\"N=%d\"%N)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the order of accuracy of the implicit and explicit Euler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convergence error\n",
    "def linSysF(y,t=0):\n",
    "    # evolution function \n",
    "    F=np.zeros(np.shape(y))\n",
    "    F[0] = y[1]-5*y[0]\n",
    "    F[1] = -F[0]\n",
    "    return F\n",
    "\n",
    "# structures for the exact solution\n",
    "linSysM=np.array([[-5,1],[5,-1]])\n",
    "\n",
    "y0=np.array([0.9,0.1])\n",
    "\n",
    "def exact_sol(t):\n",
    "    return y0+(1-np.exp(-6*t))/6*np.dot(linSysM,y0)\n",
    "\n",
    "# integral over time of the difference between the simulation and the exact solution\n",
    "# to compute the integral error\n",
    "def error(tt,yy):\n",
    "    '''\n",
    "    Compute the average error over the whole time domain, \n",
    "    in norm 2 on the components of the system\n",
    "    '''\n",
    "    errors=np.zeros(len(tt))\n",
    "    for it, t in enumerate(tt):\n",
    "        errors[it]=np.linalg.norm(yy[:,it]-exact_sol(t))\n",
    "    return np.mean(errors)\n",
    "\n",
    "# Checking the convergence over different mesh refinements (number of timesteps)\n",
    "Ns=[2**k for k in range(1,12)]\n",
    "errorEx=np.zeros(len(Ns))\n",
    "errorIm=np.zeros(len(Ns))\n",
    "dts=    np.zeros(len(Ns))\n",
    "\n",
    "\n",
    "for iN, N in enumerate(Ns): # loop over different Nt\n",
    "    tspan=np.linspace(0,3,N) # timesteps\n",
    "    dts[iN]=tspan[1]-tspan[0] # dt\n",
    "    \n",
    "    tt,yy=explicitEuler(linSysF,tspan,y0) # explicit Euler simulation\n",
    "    errorEx[iN]=error(tt,yy)              # explicit Euler error\n",
    "    tt,yy=implicitEulerLinear(linSysM,tspan,y0) # implicit Euler simulation \n",
    "    errorIm[iN]=error(tt,yy)              # implicit Euler error\n",
    "\n",
    "# Plot of the error wrt to dt in loglog scale (too exponential behaviors dt^p)\n",
    "plt.figure()\n",
    "plt.loglog(dts,errorEx,label=\"ex Euler\")\n",
    "plt.loglog(dts,errorIm, label=\"im Euler\")\n",
    "plt.loglog(dts,0.1*dts,\":\", label=\"order 1\")\n",
    "plt.loglog(dts,0.1*dts**2., \":\", label=\"order 2\")\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: implicit Euler on purely imaginary system problem\n",
    "Use the system introduced before for explicit Euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the implicit Euler method with the linear system with purely imaginary eigenvalues\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra exercise: code implicit Euler for nonlinear problems\n",
    "* Use a nonlinear solver to solve $y^{n+1}-\\Delta t F(y^{n+1},t^{n+1})=y^n$ (you can use **scipy.optimize.newton**, scipy.optimize.broyden1 or implement your Newton's method)\n",
    "  * Use lambda function to define the nonlinear function (for nonlinear solvers) \n",
    "  * Search the documentation on Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicitEuler(func, tspan, y_0):\n",
    "    '''\n",
    "    Implicit Euler method with a nonlinear solver\n",
    "    Input:\n",
    "    func (nonlinear) function fo the ODE\n",
    "    tspan vector of timesteps (t^0,...,t^N)\n",
    "    y_0 initial value    \n",
    "    '''\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)          # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions    \n",
    "    y[:,0]=y_0                 # first timestep \n",
    "    for n in range(N_time-1):    # loop through timesteps n=0,..., N-1\n",
    "        FILL IN WITH THE OPERATIONS THAT LEAD\n",
    "        TO THE SOLUTION OF THE NONLINEAR FUNCTION\n",
    "        y[:,n+1] = ### \n",
    "    return tspan, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nonlinear 3x3 system production destruction\n",
    "def nonlinear_system3_flux(u,t=0):\n",
    "    ff=np.zeros(len(u))\n",
    "    ff[0]= -u[0]*u[1]/(u[0]+1)\n",
    "    ff[1]= u[0]*u[1]/(u[0]+1) -0.3*u[1]\n",
    "    ff[2]= 0.3*u[1]\n",
    "    return ff\n",
    "\n",
    "y_0 = np.array([9.98,0.01,0.01])\n",
    "T_fin = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run implicit Euler method and plot the solution\n",
    "tt=np.linspace(0,T_fin, 100)\n",
    "tt,yy = implicitEuler(nonlinear_system3_flux, tt, y_0)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"implicit Euler\")\n",
    "plt.plot(tt,yy[0,:])\n",
    "plt.plot(tt,yy[1,:])\n",
    "plt.plot(tt,yy[2,:])\n",
    "\n",
    "\n",
    "tt,yy = explicitEuler(nonlinear_system3_flux, tt, y_0)\n",
    "plt.subplot(122)\n",
    "plt.title(\"explicit Euler\")\n",
    "plt.plot(tt,yy[0,:])\n",
    "plt.plot(tt,yy[1,:])\n",
    "plt.plot(tt,yy[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nonlinear stiff problem: Robertson\n",
    "\n",
    "def Robertson_flux(u,t=0,alpha=10**4,beta=0.04, gamma=3*10**7):\n",
    "    ff=np.zeros(np.shape(u))\n",
    "    ff[0] = alpha*u[1]*u[2]-beta*u[0]\n",
    "    ff[1] = beta*u[0]-alpha*u[1]*u[2] - gamma*u[1]**2\n",
    "    ff[2] = gamma*u[1]**2\n",
    "    return ff\n",
    "\n",
    "NN=10000\n",
    "tt = np.array([10**k for k in np.linspace(-7,11,NN)])\n",
    "y_0 = np.array([1.,10**-20,10**-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt,yy = implicitEuler(Robertson_flux, tt, y_0)\n",
    "plt.semilogx(tt,yy[0,:])\n",
    "plt.semilogx(tt,yy[1,:]*10**4)\n",
    "plt.semilogx(tt,yy[2,:])\n",
    "plt.ylim([-0.05, 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt,yy = explicitEuler(Robertson_flux, tt, y_0)\n",
    "plt.semilogx(tt,yy[0,:])\n",
    "plt.semilogx(tt,yy[1,:]*10**4)\n",
    "plt.semilogx(tt,yy[2,:])\n",
    "plt.ylim([-0.05, 1.05])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9 (default, Nov 25 2022, 14:10:45) \n[GCC 8.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
