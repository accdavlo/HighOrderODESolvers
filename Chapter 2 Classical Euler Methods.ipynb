{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Euler methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    " 1. Chapter 2: Classical Methods\n",
    "    1. [Section 1.1: Explicit Euler](#explicitEuler)\n",
    "    1. [Section 1.2: Implicit Euler](#implicitEuler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not have numpy, matplotlib, scipy or nodepy, run this cell\n",
    "!pip install numpy\n",
    "# This is the basic package in python with all the numerical functions\n",
    "\n",
    "!pip install scipy\n",
    "# This package has some functions to deal with polynomials\n",
    "\n",
    "!pip install matplotlib\n",
    "# This package allows to  plot\n",
    "\n",
    "!pip install nodepy\n",
    "# This package has some interesting features for RK methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a couple of packages in this chapter\n",
    "import numpy as np  \n",
    "# This is the basic package in python with all the numerical functions\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "# This package allows to  plot\n",
    "\n",
    "from scipy import optimize\n",
    "# This module has optimization tools\n",
    "\n",
    "from nodepy import * \n",
    "#This package already implemented some functions for Runge Kutta and multistep methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to **approximate** the ODE on $I:=[t_0, t_{end}]\\subset \\mathbb{R}$ for the unknown variable $y:I\\to \\mathbb{R}^{S}$ with *continuous* function $F:I\\times \\mathbb{R}^S\\to\\mathbb{R}^S$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{cases}\\label{eq:IVP}\n",
    "\\frac{dy}{dt} = F(t,y(t)),\\\\\n",
    "y(0)=y_0.\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "* Why approximate? Solution may be unknown, or too complicated to be solved analytically.\n",
    "* How we want to approximate? We want to be **accurate** and we want to preserve the physical properties we have seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit Euler <a id='explicitEuler'></a>\n",
    "\n",
    "Consider the time interval $I=[t_0,t_{end}]$ and let us subdivide it into $N$ subintervals, \n",
    "\n",
    "$$t_0=t^0<t^1< \\dots <t^n < \\dots <t^N=t_{end}.$$\n",
    "\n",
    "We approximate naïvely the integral form\n",
    "\n",
    "$$ y(t^{n+1})=y(t^n) +\\int_{t^n}^{t^{n+1}} F(s,y(s))ds \\approx y(t^n) -\\underbrace{(t^{n+1}-t^n)}_{\\Delta t^n} F(t^n,y(t^n)) $$\n",
    "\n",
    "leading to the method (forward Euler/explicit Euler), where we use $y^n$ to approximate $y(t^n)$\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "y^0=y_0,\\\\\n",
    "y^{n+1}=y^n+\\Delta t^n F(t^n,y^n), \\qquad n=0,\\dots, N-1.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explicitEuler(func, tspan, y_0):\n",
    "    '''\n",
    "    Simple implementation of the explicit Euler method\n",
    "    Input are \n",
    "    func the function F of the ODE which takes as input y and t F(y,t)\n",
    "    tspan is the vector of all timesteps (t^0,...,t^N)\n",
    "    y_0 is the initial condition\n",
    "    '''\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)          # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions    \n",
    "    y[:,0]=y_0                 # first timestep \n",
    "    for n in range(N_time-1):    # n=0,..., N-1\n",
    "        y[:,n+1]=y[:,n]+ FILL IN THE EVOLUTION ## Code the explicit euler step\n",
    "    return tspan, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on $$\n",
    "\\begin{equation}\\label{eq:linear_test}\n",
    "\\begin{aligned}\n",
    "& \\begin{cases}\n",
    "c_1'(t)=c_2(t)-5c_1(t),\\\\\n",
    "c_2'(t)=5c_1(t)-c_2(t),\n",
    "\\end{cases}\\\\\n",
    " &c_1(0)=c_1^0=0.9, \\quad  &c_2(0)=c_2^0=0.1 \\, ,\\\\\n",
    " &t\\in [0,3].\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the function F\n",
    "def linSysF(y,t=0):\n",
    "    # evolution function \n",
    "    F=np.zeros(np.shape(y))\n",
    "    F[0] = FILL IN THE DEFINITION\n",
    "    F[1] = FILL IN THE DEFINITION\n",
    "    return F\n",
    "\n",
    "## Now we plot the solution with different number of timesteps\n",
    "for N in [100,30,10]:\n",
    "    tspan=np.linspace(0,3,N)\n",
    "    y0=np.array([0.9,0.1])\n",
    "\n",
    "    tt,yy=explicitEuler(linSysF,tspan,y0)\n",
    "\n",
    "    A=np.array([[-5,1],[5,-1]])\n",
    "\n",
    "    y_exact=np.zeros((len(y0),len(tt)))\n",
    "    for it, t in enumerate(tt):\n",
    "        y_exact[:,it]=y0+(1-np.exp(-6*t))/6*np.dot(A,y0)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(tt,y_exact[0,:],\":\", label=\"c1 ex\")\n",
    "    plt.plot(tt,y_exact[1,:],\":\", label=\"c2 ex\")\n",
    "\n",
    "    plt.plot(tt,yy[0,:],label=\"c1\")\n",
    "    plt.plot(tt,yy[1,:],label=\"c2\")\n",
    "    plt.title(\"N=%d\"%N)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary, we can observe that\n",
    "1. The more the points we put in the time discretization the better the solution gets\n",
    "1. Explicit Euler does not preserve **unconditionally** the positivity of the solution ($N=10$)\n",
    "1. The total mass is conserved \n",
    "\n",
    "$$ c_1^{n+1}+c_2^{n+1}=c_1^{n}+c_2^{n}+ \\Delta t\\left( -5c_1^{n}+c_2^{n}+5c_1^{n}-c_2^{n} \\right) = c_1^{n}+c_2^{n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis\n",
    "The error that we observe \n",
    "$$e_n=y(t^n)-y^n$$\n",
    "\n",
    "is composed of several parts that we can divide and study separately.\n",
    "\n",
    "### Theorem Convergence (Lax)\n",
    "If a method is stable and consistent then it is convergent.\n",
    "\n",
    "#### Consistency error\n",
    "Given the exact solution $y(t)$, we define the consistency error to be\n",
    "\n",
    "$$\n",
    "\\varepsilon_n = y(t^{n+1})-y(t^n) - \\Delta t F(t^n,y(t^n)) = \\int_{t^n}^{t^{n+1}} y'(t) -y'(t^n)\\, dt.\n",
    "$$\n",
    "\n",
    "Notice that $|\\varepsilon_n|\\leq \\Delta t \\omega (y',\\Delta t)$, where $\\omega$ is the modulus of continuity of a bounded function, i.e.,\n",
    "$$\n",
    "\\omega(f,\\Delta t):= \\max_{t,t': |t-t'|\\leq \\Delta t} |f(t)-f(t')|.\n",
    "$$\n",
    "\n",
    "Essentially, this is the error that we obtain by substituting the exact solution inside the method. It is one of the 2 ingredients that leads the error of a method.\n",
    "\n",
    "Going back to the error, we observe that\n",
    "\n",
    "$$\n",
    "e_{n+1}=y(t^{n+1})-y^{n+1}=e_n +\\varepsilon_n +\\Delta t \\big(f(t^n,y(t^n))-f(t^n,y^n)\\big)\n",
    "$$\n",
    "\n",
    "using the Lipschitz continuity of $f$, we have\n",
    "\n",
    "$$\n",
    "|e_{n+1}|\\leq |e_n| +|\\varepsilon_n| +\\Delta t L|y(t^n)-y^n| =(1+L\\Delta t)|e_n| +|\\varepsilon_n|.\n",
    "$$\n",
    "\n",
    "Using the **Discrete Gronwall Lemma** we obtain that\n",
    "\n",
    "$$\n",
    "|e_{n}|\\leq e^{L|t^n-t^0|}|e_0| + \\sum_{i=0}^{n-1} e^{L(t^n-t^{i+1})}|\\varepsilon_i|.\n",
    "$$\n",
    "\n",
    "This tells us that, except for the initial error (that usually we can bound accurately or know its error), the consistency error leads this sum. So, if we keep $\\varepsilon_n$ small enough, the final error will be small enough. \n",
    "\n",
    "\n",
    "Using the estimation for $\\varepsilon_i$ and suppose $\\Delta t^n=\\Delta t$, we can collect\n",
    "$$\n",
    "\\begin{align}\n",
    "|e_{n}|&\\leq e^{L|t^n-t^0|}|e_0| + \\Delta t \\omega(y',\\Delta t) \\sum_{i=0}^{n-1} e^{L(t^n-t^{i+1})}\\\\\n",
    "&\\leq e^{L|t^n-t^0|}|y^0-y(t^0)| + \\Delta t \\omega(y',\\Delta t) \\frac{e^{L(t^n-t^{0})}-1}{L}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This shows that the solution converges to the exact one as $\\Delta t \\to 0$, if the initial datum is correct. \n",
    "\n",
    "\n",
    "If we know more on the regularity of the solution ($y\\in \\mathcal C^2$), we can say that\n",
    "\n",
    "$$\n",
    "|y(t^n)-y^n|\\leq e^{L(t^n-t^0)}|y^0-y(t^0)| + \\Delta t \\int_{t^0}^{t^n} e^{L(t^n-s)} |y''(s)| ds.\n",
    "$$\n",
    "\n",
    "\n",
    "#### Local vs Global Error\n",
    "A small remark must be done in order to understand how the global error generates from the local one.\n",
    "The local truncation error is the one given for one time step, i.e., using Taylor expansion and supposing $y^0=y(t^0)$,\n",
    "\n",
    "$$\n",
    "e_1=|y^1-y(t^1)|=|y^0 +\\Delta t F(t^0,y^0) - \\left(y(t^0) + \\Delta t y'(t^0) + \\frac{1}{2} \\Delta t^2 y''(t^0)\\right) + \\mathcal{O}(\\Delta t^3)| = \\frac{1}{2} \\Delta t^2 |y''(t^0)| +  \\mathcal{O}(\\Delta t^3).\n",
    "$$\n",
    "\n",
    "In one step we see an error of $\\mathcal O (\\Delta t^2)$, when integrating of the whole time interval $[t^0,t^N]$ one obtains an $\\mathcal O (\\Delta t)$ as we have seen before.\n",
    "\n",
    "Naïvely one can see it as if in every step we are adding an $\\mathcal O (\\Delta t^2)$ to the global error\n",
    "\n",
    "$$\n",
    "e_N\\approx \\sum_{i=1}^N |y(t^i)-y^i| \\approx N \\Delta t^2 \\max_{t\\in [t^0,t^N]} |y''(t)| = \\frac{t^N-t^0}{\\Delta t} \\Delta t^2\\max_{t\\in [t^0,t^N]} |y''(t)|= (t^N-t^0) \\Delta t\\max_{t\\in [t^0,t^N]} |y''(t)|\n",
    "$$\n",
    "\n",
    "The **order of accuracy** of a method is the largest *integer* $p$, such that the error can be bounded by\n",
    "\n",
    "$$\n",
    "|e_N| \\leq C \\Delta t^p, \\qquad \\forall \\Delta t \\in \\mathbb R ^+.\n",
    "$$\n",
    "\n",
    "This definition is of course meant to be verified in the limit for $\\Delta t\\to 0$ (in realistic cases we stop at $\\approx 10^{-14}$).\n",
    "\n",
    "The explicit Euler method is of order (at least) 1. (one can check that it is not 2 with numerical tests)\n",
    "\n",
    "\n",
    "#### Roundoff effects\n",
    "We should always keep in mind that the error we studied before is not the only one that a computer produces. \n",
    "Indeed, at each operation (initial value, evaluation of $F$, sums, products) we introduce a roundoff error due to the machine precision.\n",
    "One can get similar estimations to what we have seen before, knowing that the error can be controlled.\n",
    "\n",
    "\n",
    "We ignore this error in this course.\n",
    "\n",
    "### Stability\n",
    "Question: going with $\\Delta t \\to 0$ should produce nice results, but, what can we say about $\\Delta t >>0$?\n",
    "Can we give a qualitatively say when a method could be stable/reliable in particular when *stiff* problems are considered. *Stiff* problems are the ones for which a *normal* discretization can not produce decent results.\n",
    "\n",
    "This rough description can be made more precise and studied only in limited cases. In particular, we restrict to linear problems with constant coefficients.\n",
    "\n",
    "$$\n",
    "y'(t)=My(t)\n",
    "$$\n",
    "\n",
    "with $M$ constant matrix. We fix the timestep $\\Delta t$. The explicit Euler method gives the update\n",
    "\n",
    "$$\n",
    "y^{n}=y^{n-1}+\\Delta t M y^{n-1} =(I+\\Delta t M) y^{n-1} = (I+\\Delta t M)^{n} y^0.\n",
    "$$\n",
    "\n",
    "Doing a change of basis given by the nonsingular matrix $S$ so that  $\\hat{M}=S^{-1} M S$ is in the Jordan canonical form, and defining $\\hat{y}^n=S^{-1} y^n$, we have that\n",
    "\n",
    "$$\n",
    "\\hat y^{n}=\\hat y^{n-1}+\\Delta t \\hat M \\hat{y}^{n-1} =(I+\\Delta t \\hat M) \\hat{y}^{n-1} = (I+\\Delta t \\hat M)^{n} \\hat{y}^0.\n",
    "$$\n",
    "\n",
    "This means that for each distinct eigenvalue $q$ we can study the linear scalar equation \n",
    "\n",
    "$$\n",
    "y'(t)= q  y(t).\n",
    "$$\n",
    "\n",
    "The other components that correspond to the same Jordan block will depend on this solution, but will not contribute to its behaviour.\n",
    "\n",
    "The final question is whether $(1+\\Delta t q)^N$ is an *acceptable* approximation of $e^{N\\Delta t q }$.\n",
    "\n",
    "We are interested in bounded behaviors for $N\\to \\infty$ , this implies that $|1+\\Delta t q|\\leq 1$, or that $Re(q)\\leq 0$. ($q$ could be complex as it is an eigenvalue of $M$).\n",
    "\n",
    "Rewriting the problem with $z=q\\Delta t$, one can see that \n",
    "\n",
    "$$\n",
    "y^n=y^{n-1}+z y^{n-1}=(1+z)y^{n-1}\n",
    "$$\n",
    "\n",
    "and the method will be stable if\n",
    "$|1+z|\\leq 1$, which is the region in the complex plane denoted by a circle of radius 1 with center in $(-1,0)$.\n",
    "\n",
    "The function $R(z):=1+z$ for the explicit Euler is the *stability function*.\n",
    "For a general method for the Dahlquist's equation\n",
    "\n",
    "$$\n",
    "y'(t)=qy(t)\n",
    "$$\n",
    "\n",
    "denoting by $z=\\Delta t q$, the method can be written as\n",
    "\n",
    "$$\n",
    "y^{n+1}=R(z) y^n.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will see soon how to write a RK method\n",
    "## This is the explicit Euler method written into the RK formalism \n",
    "## and we plot the stability region using the nodepy module\n",
    "A=np.array([[0]])\n",
    "b=np.array([1])\n",
    "exEuler=runge_kutta_method.ExplicitRungeKuttaMethod(A,b)\n",
    "p,q=exEuler.stability_function()\n",
    "print(p)\n",
    "exEuler.plot_stability_region();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How can we ensure the belonging to the stability region?\n",
    "We want $z=q\\Delta t$ to stay in the stability region. On $q$ we do not have control, hence, we can only modify $\\Delta t$. \n",
    "In particular, denoting $q=p+ir$ with $p,r \\in \\mathbb R $ and $p\\leq 0$, the stability relation we have seen before leads to at least check that the real part verifies the relation\n",
    "\n",
    "$$\n",
    "|1+\\Delta t p + i \\Delta t r|\\leq 1 \\\\\n",
    "1-\\Delta t |p|  \\geq 1\\\\\n",
    "\\Delta t \\leq \\frac{2}{|p|}\n",
    "$$\n",
    "\n",
    "where $|p|$ is for sure bounded by the Lipschitz constant $L$ of the function $F$.\n",
    "\n",
    "So, it is necessary to check that\n",
    "\n",
    "$$\n",
    "\\Delta t \\leq \\frac{2}{L}.\n",
    "$$\n",
    "\n",
    "This can be generalized also for nonlinear problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit Euler <a id='implicitEuler'></a>\n",
    "\n",
    "The implicit Euler method approximates our problem with the following strategy\n",
    "\n",
    "$$\n",
    "y^{n+1}=y^n +\\Delta t f(t^{n+1},y^{n+1}).\n",
    "$$\n",
    "\n",
    "1. It is not always easy to find the solution of such method, for example when $f$ is nonlinear, one may need nonlinear solvers to find the solution (e.g. Newton method, Broyden, and so on)\n",
    "1. We can compute the error estimate similarly to explicit Euler, obtaining that also implicit Euler is a *first* order method\n",
    "1. More interesting are the **stability** property of this scheme.\n",
    "\n",
    "Consider again the Dahlquist's equation\n",
    "\n",
    "$$y'=qy$$\n",
    "\n",
    "and the implicit Euler method\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y^{n+1}=y^n+ \\Delta t q y^{n+1},\\\\\n",
    "(1-\\Delta t q) y^{n+1}=y^n,\\\\\n",
    "y^{n+1}=\\frac{1}{1-\\Delta t q} y^n.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So the stability function is $R(z)=\\frac{1}{1-z}$ and the stability region $\\mathcal S := \\lbrace z \\in \\mathbb C : |R(z)|\\leq 1 \\rbrace$ contains the whole left complex semiplane. Indeed, if Re$(z)\\leq 0$, then Re$(1-z)\\geq 1$ and $|1-z|\\geq 1$.\n",
    "So, $R(z)\\leq 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## We will see soon how to write a RK method\n",
    "## This is the implicit Euler and we plot the stability region\n",
    "A=np.array([[1]])\n",
    "b=np.array([1])\n",
    "imEuler=runge_kutta_method.RungeKuttaMethod(A,b)\n",
    "p,q=imEuler.stability_function()\n",
    "print(p) ## Numerator\n",
    "print(q) ## Denominator\n",
    "imEuler.plot_stability_region(bounds=[-10,4, -5,5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unconditionally TVD/positivity preserving\n",
    "For some class of linear problems, it can be shown that for positive systems it is **positivity preserving**, or more in general for finite difference method in hyperbolic conservation laws, it is total variation diminishing (TVD).\n",
    "\n",
    "The clou is that these properties are true independently on the size of $\\Delta t$.\n",
    "\n",
    "For TVD one can read the SSPRK article by Gottlieb, Shu and Tadmor [link](https://www.researchgate.net/publication/2365594_Strong_Stability-Preserving_High-Order_Time_Discretization_Methods).\n",
    "\n",
    "##### TVD for incremental form problem\n",
    "The implicit Euler method for incremental problems, i.e.,\n",
    "$$\n",
    "U^{n+1}_j=U^{n}_j +\\Delta t \\left [ C_{j+1/2}(U_{j+1}^{n+1}-U_{j}^{n+1})-D_{j-1/2}(U_{j}^{n+1}-U_{j-1}^{n+1}) \\right]\n",
    "$$\n",
    "\n",
    "where $C_{j+1/2},D_{j+1/2}\\geq 0$ is TVD independently on $\\Delta t$.\n",
    "\n",
    "###### Proof (Harten)\n",
    "Define \n",
    "\n",
    "$$\n",
    "TV(U^n) = \\sum_j |U^n_{j+1}-U^n_j|.\n",
    "$$\n",
    "\n",
    "We can compute\n",
    "$$\n",
    "U^{n+1}_j=U^{n}_j +\\Delta t \\left [ C_{j+1/2}(U_{j+1}^{n+1}-U_{j}^{n+1})-D_{j-1/2}(U_{j}^{n+1}-U_{j-1}^{n+1}) \\right]\\\\\n",
    "[1+\\Delta t (C_{j+1/2}+D_{j+1/2})](U^{n+1}_j-U_j^{n+1})=U^{n}_j-U_j^{n} +\\Delta t \\left [ C_{j+3/2}(U_{j+2}^{n+1}-U_{j+1}^{n+1})+D_{j-1/2}(U_{j}^{n+1}-U_{j-1}^{n+1}) \\right]\\\\\n",
    "[1+\\Delta t (C_{j+1/2}+D_{j+1/2})]|U^{n+1}_j-U_j^{n+1}|\\leq|U^{n}_j-U_j^{n}| +\\Delta t \\left [ C_{j+3/2}|U_{j+2}^{n+1}-U_{j+1}^{n+1}|+D_{j-1/2}|U_{j}^{n+1}-U_{j-1}^{n+1}| \\right]=\\\\\n",
    "TV(U^{n+1}) +\\Delta t \\sum_j(C_{j+1/2}+D_{j+1/2})|U^{n+1}_{j+1}-U^{n+1}_j| \\leq TV(U^{n}) +\\Delta t \\sum_j(C_{j+1/2}+D_{j+1/2})|U^{n+1}_{j+1}-U^{n+1}_j| \\\\\n",
    "TV(U^{n+1}) \\leq TV(U^n).\n",
    "$$\n",
    "\n",
    "Reminder: Total variation diminishing means for conservation laws, that if the initial solution is positive, it stays positive.\n",
    "\n",
    "\n",
    "##### Positivity for production destruction system\n",
    "We will see the positivity for a specific case: a production-destruction system with constant coefficient. It can be written as\n",
    "\n",
    "$$\n",
    "y'=My\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\n",
    "M_{ii}<0,\\qquad M_{ij}>0,\\, i\\neq j, \\qquad \\sum_{i}M_{ij}=0.\n",
    "$$\n",
    "\n",
    "The linear system at the beginning of this chapter falls in this example.\n",
    "\n",
    "This system is positive if $y_i^0\\geq 0$. The implicit Euler is also positive.\n",
    "\n",
    "$$\n",
    "(I-\\Delta t M)y^{n+1}= y^{n}\n",
    "$$\n",
    "\n",
    "##### Theorem\n",
    "Defining with $A:=I-\\Delta t M$, we can prove that $A$ is non singular and that $A^{-1}\\geq 0$, i.e., every entry of the matrix is nonnegative.\n",
    "\n",
    "##### Proof\n",
    "1. $A$ is strictly diagonally dominant by columns\n",
    "Indeed, \n",
    "\n",
    "$$\n",
    "0< A_{ii} = 1+\\Delta t |M_{ii}| > \\Delta t \\sum_{j:j\\neq i} |M_{ij}| = \\sum_{j:j\\neq i} |A_{ij}|\n",
    "$$\n",
    "\n",
    "Hence, $A$ is nonsingular.\n",
    "\n",
    "2. The Jacobi method converge and the Jacobi Matrix is positive [Jacobi method](https://en.wikipedia.org/wiki/Jacobi_method)\n",
    "\n",
    "\n",
    "Define the Jacobi matrix $B=D^{-1}(D-A^T)$, with $D=\\text{diag}(A)$.\n",
    "The diagonal of $B$ is 0 and each element on the off diagonal terms are\n",
    "\n",
    "$$\n",
    "B_{ij}=\\frac{-A_{ij}}{A_{ii}}, \\quad j\\neq i. \n",
    "$$\n",
    "\n",
    "So, the spectral radius of $B$ is bounded by\n",
    "\n",
    "$$\n",
    "\\rho(B)\\leq ||B||_{\\infty} =\\max_{i}\\sum_{j\\neq i} \\frac{|A_{ij}|}{|A_{ii}|} \\leq 1.\n",
    "$$\n",
    "\n",
    "The iterative Jacobi method is convergent to the solution of $Ay^{n+1}=y^n$.\n",
    "\n",
    "The method reads\n",
    "\n",
    "$$\n",
    "w^{(k+1)}=D^{-1}(y^n- (D-A^T)w^{(k)})\n",
    "$$\n",
    "\n",
    "which is a linear combination of positive matrices and vectors. Hence, the solutions $w^{(k)}$ stay positive if $y^n$ is positive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicitEulerLinear(M, tspan, y_0):\n",
    "    '''\n",
    "    Simple implementation of the implicit Euler for Linear systems y'=My with M constant matrix\n",
    "    Input are \n",
    "    M the ODE constant matrix\n",
    "    tspan vector of timesteps (t^0,...,t^N)\n",
    "    y_0 initial value\n",
    "    '''\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)        # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions    \n",
    "    y[:,0]=y_0                 # first timestep \n",
    "    for n in range(N_time-1):    # n=0,..., N-1\n",
    "        A= FILL IN # define the matrix that need to be inverted\n",
    "        y[:,n+1]=np.linalg.solve(A,y[:,n])\n",
    "    return tspan, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test implicit Euler on the linear system\n",
    "def linSysF(y,t=0):\n",
    "    # evolution function \n",
    "    F=np.zeros(np.shape(y))\n",
    "    F[0] = y[1]-5*y[0]\n",
    "    F[1] = -F[0]\n",
    "    return F\n",
    "\n",
    "linSysM=np.array([[-5,1],[5,-1]])\n",
    "\n",
    "for N in [100,30,10]:\n",
    "    tspan=np.linspace(0,3,N)\n",
    "    y0=np.array([0.9,0.1])\n",
    "\n",
    "    tt,yy=implicitEulerLinear(linSysM,tspan,y0)\n",
    "\n",
    "    A=np.array([[-5,1],[5,-1]])\n",
    "\n",
    "    y_exact=np.zeros((len(y0),len(tt)))\n",
    "    for it, t in enumerate(tt):\n",
    "        y_exact[:,it]=y0+(1-np.exp(-6*t))/6*np.dot(A,y0)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(tt,y_exact[0,:],\":\", label=\"c1 ex\")\n",
    "    plt.plot(tt,y_exact[1,:],\":\", label=\"c2 ex\")\n",
    "\n",
    "    plt.plot(tt,yy[0,:],label=\"c1\")\n",
    "    plt.plot(tt,yy[1,:],label=\"c2\")\n",
    "    plt.title(\"N=%d\"%N)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's check the order of accuracy of the implicit and explicit Euler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convergence error\n",
    "def linSysF(y,t=0):\n",
    "    # evolution function \n",
    "    F=np.zeros(np.shape(y))\n",
    "    F[0] = y[1]-5*y[0]\n",
    "    F[1] = -F[0]\n",
    "    return F\n",
    "\n",
    "linSysM=np.array([[-5,1],[5,-1]])\n",
    "\n",
    "y0=np.array([0.9,0.1])\n",
    "\n",
    "def exact_sol(t):\n",
    "    return y0+(1-np.exp(-6*t))/6*np.dot(linSysM,y0)\n",
    "\n",
    "def error(tt,yy):\n",
    "    '''\n",
    "    Compute the average error over the whole time domain, \n",
    "    in norm 2 on the components of the system\n",
    "    '''\n",
    "    errors=np.zeros(len(tt))\n",
    "    for it, t in enumerate(tt):\n",
    "        errors[it]=np.linalg.norm(yy[:,it]-exact_sol(t))\n",
    "    return np.mean(errors)\n",
    "\n",
    "Ns=[2**k for k in range(1,12)]\n",
    "errorEx=np.zeros(len(Ns))\n",
    "errorIm=np.zeros(len(Ns))\n",
    "dts=    np.zeros(len(Ns))\n",
    "\n",
    "\n",
    "for iN, N in enumerate(Ns):\n",
    "    tspan=np.linspace(0,3,N)\n",
    "    dts[iN]=tspan[1]-tspan[0]\n",
    "    \n",
    "    tt,yy=explicitEuler(linSysF,tspan,y0)\n",
    "    errorEx[iN]=error(tt,yy)\n",
    "    tt,yy=implicitEulerLinear(linSysM,tspan,y0)\n",
    "    errorIm[iN]=error(tt,yy)\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(dts,errorEx,label=\"ex Euler\")\n",
    "plt.loglog(dts,errorIm, label=\"im Euler\")\n",
    "plt.loglog(dts,0.1*dts,\":\", label=\"order 1\")\n",
    "plt.loglog(dts,0.1*dts**2., \":\", label=\"order 2\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra exercise: code implicit Euler for nonlinear fluxes\n",
    "* Use a nonlinear solver to solve $y^{n+1}-\\Delta t F(y^{n+1},t^{n+1})=y^n$ (**scipy.optimize.newton**, scipy.optimize.broyden1)\n",
    "* Use lambda function to define the nonlinear function \n",
    "* Search the documentation on Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicitEuler(func, tspan, y_0):\n",
    "    '''\n",
    "    Implicit Euler method with a nonlinear solver\n",
    "    Input:\n",
    "    func (nonlinear) function fo the ODE\n",
    "    tspan vector of timesteps (t^0,...,t^N)\n",
    "    y_0 initial value    \n",
    "    '''\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)          # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions    \n",
    "    y[:,0]=y_0                 # first timestep \n",
    "    for n in range(N_time-1):    # n=0,..., N-1\n",
    "        FILL IN WITH THE OPERATIONS THAT LEAD\n",
    "        TO THE SOLUTION OF THE NONLIENEAR FUNCTION\n",
    "        y[:,n+1] = ### \n",
    "    return tspan, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nonlinear 3x3 system production destruction\n",
    "def nonlinear_system3_flux(u,t=0):\n",
    "    ff=np.zeros(len(u))\n",
    "    ff[0]= -u[0]*u[1]/(u[0]+1)\n",
    "    ff[1]= u[0]*u[1]/(u[0]+1) -0.3*u[1]\n",
    "    ff[2]= 0.3*u[1]\n",
    "    return ff\n",
    "\n",
    "y_0 = np.array([9.98,0.01,0.01])\n",
    "T_fin = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run implicit Euler method and plot the solution\n",
    "tt=np.linspace(0,T_fin, 100)\n",
    "tt,yy = implicitEuler(nonlinear_system3_flux, tt, y_0)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"implicit Euler\")\n",
    "plt.plot(tt,yy[0,:])\n",
    "plt.plot(tt,yy[1,:])\n",
    "plt.plot(tt,yy[2,:])\n",
    "\n",
    "\n",
    "tt,yy = explicitEuler(nonlinear_system3_flux, tt, y_0)\n",
    "plt.subplot(122)\n",
    "plt.title(\"explicit Euler\")\n",
    "plt.plot(tt,yy[0,:])\n",
    "plt.plot(tt,yy[1,:])\n",
    "plt.plot(tt,yy[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nonlinear stiff problem: Robertson\n",
    "\n",
    "def Robertson_flux(u,t=0,alpha=10**4,beta=0.04, gamma=3*10**7):\n",
    "    ff=np.zeros(np.shape(u))\n",
    "    ff[0] = alpha*u[1]*u[2]-beta*u[0]\n",
    "    ff[1] = beta*u[0]-alpha*u[1]*u[2] - gamma*u[1]**2\n",
    "    ff[2] = gamma*u[1]**2\n",
    "    return ff\n",
    "\n",
    "NN=10000\n",
    "tt = np.array([10**k for k in np.linspace(-7,11,NN)])\n",
    "y_0 = np.array([1.,10**-20,10**-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt,yy = implicitEuler(Robertson_flux, tt, y_0)\n",
    "plt.semilogx(tt,yy[0,:])\n",
    "plt.semilogx(tt,yy[1,:]*10**4)\n",
    "plt.semilogx(tt,yy[2,:])\n",
    "plt.ylim([-0.05, 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt,yy = explicitEuler(Robertson_flux, tt, y_0)\n",
    "plt.semilogx(tt,yy[0,:])\n",
    "plt.semilogx(tt,yy[1,:]*10**4)\n",
    "plt.semilogx(tt,yy[2,:])\n",
    "plt.ylim([-0.05, 1.05])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
