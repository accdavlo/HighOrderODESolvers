\PassOptionsToPackage{subsection=false}{beamerouterthememiniframes}
\documentclass[9pt,compress,t,aspectratio=169]{beamer}
\usetheme[
	bullet=circle,
	alternativetitlepage=true,
	titleline=true,
	titlepagelogo=img/sissa_and_mathlab,
]{mathlab}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{verbatim} % per comment
\usepackage{lmodern} % font più chiaro
\usepackage{ragged2e}
\usepackage{bm}
\usepackage{tikz}
\usepackage[thicklines]{cancel}
\usepackage{xcolor}
\usepackage{wasysym}
\usepackage{units}
\usepackage{tikzsymbols}
\usepackage{bbm}


\usepackage{multimedia}
\usepackage{graphicx}
\usepackage{pgfplots}
\usepackage{pgfplotstable}

\usetikzlibrary{shadows}

\usetikzlibrary{decorations.pathreplacing,calligraphy}

%\usepackage{media9}%
\newcommand\Ccancel[2][black]{\renewcommand\CancelColor{\color{#1}}\cancel{#2}}
\newcommand{\cfbox}[2]{%
    \colorlet{currentcolor}{.}%
    {\color{#1}%
    \fbox{\color{currentcolor}#2}}%
}


\newcommand{\bad}{\Sadey[2][red]}
\newcommand{\good}{\Smiley[2][green]}

\newcommand{\one}{$[1]$}
\newcommand{\two}{$[2]$}
\newcommand{\three}{$[3]$}


\setbeamertemplate{navigation symbols}{}

\graphicspath{{pictures/img/}}



\usepackage{amssymb}
\usepackage{cancel}
\usepackage{comment}
%\DeclareMathOperator{\supp}{supp}
\usepackage{mathrsfs}
%\usepackage{latexsym}
\DeclareGraphicsExtensions{.pdf,.jpg,.png}
\usepackage{hyperref}



%\usepackage{times}


\newtheorem{induction_hyp}{Induction Hypothesis}
\newtheorem{remark}{Remark}
\newtheorem{algo}{Algorithm}

\definecolor{green}{rgb}{0.0, 0.42, 0.14}
\include{config}
\title[ADER vs DeC]{ADER and DeC: \\ arbitrarily high order (explicit)\\ methods for PDEs and ODEs} 

\author[D. Torlo]{\Large Davide Torlo}
\institute[SISSA mathLab]{%
\vspace{-3mm}\\%
\small $^*$MathLab, Mathematics Area, SISSA International School for Advanced Studies, Trieste, Italy\\
\href{https://www.davidetorlo.it}{\underline{davidetorlo.it}\vspace{-3mm}}
}

\date[]
{ \small Based on: Han Veiga, M., Öffner, P. \& Torlo, D. 
\textit{DeC and ADER: Similarities, Differences and a Unified Framework.} 
J Sci Comput 87, 2 (2021). \url{https://doi.org/10.1007/s10915-020-01397-5}
}


\AtBeginSection[]
{
	\begin{frame}<beamer>
	\frametitle{Outline}
	  \tableofcontents[currentsection]
  
	\end{frame}


}

\begin{document}

\begin{frame}

\titlepage



\end{frame}

\begin{frame}<beamer>
	\frametitle{Outline}
	  \tableofcontents
  % You might wish to add the option [pausesections]
\end{frame}

\section{Motivation}

\begin{frame}{Motivation: high order accurate explicit method}
	Methods used to solve a hyperbolic  PDE system for $u:\R^+\times \Omega \to \R^D$
	\begin{equation}\label{eq:scalarPDE}
		\partial_t u + \nabla_{\mathbf{x}} \mathcal{F}(u) =0.
	\end{equation}

	Or ODE system for $\bc:\R^+\to \R^S$
	\begin{equation}\label{eq:scalarODE}
		\partial_t \bc = F(\bc) .
	\end{equation}
	
	Applications:
	\begin{itemize}
		\item Fluids/transport
		\item Chemical/biological processes
	\end{itemize}
	\vspace{5mm}
	
	How?
	\begin{itemize}
		\item Arbitrarily high order accurate
		\item \only<3>{Explicit (if nonstiff problem)}
	\end{itemize}
	
	\only<2>{
		\begin{tikzpicture}[remember picture,overlay]
			\node at (current page.center) {\includegraphics[width=0.81\textwidth]{pictures/HighOrderMethods.pdf}};
		\end{tikzpicture}
	}
	
\end{frame}




\begin{frame}{Classical time integration: Runge--Kutta}
\begin{align}
	&\bc^{(1)}:=\bc^n,\\
	&\bc^{(k)}:=\bc^n+\sum_{s=1}^{K} a_{ks} F\left(t^n+c_s\Delta t,\bc^{(s)}\right), \quad \text{for } k=2,\dots, K, \label{eq:RK}\\
	&\bc^{n+1}:= \bc^n+\sum_{s=1}^{K} b_{s} F\left(t^n+c_s\Delta t,\bc^{(s)}\right).
\end{align}
 
\end{frame}

\begin{frame}{Classical time integration: Explicit Runge--Kutta}
\begin{align*}
	&\bc^{(k)}:=\bc^n+\sum_{s=1}^{k-1} a_{ks} F\left(t^n+c_s\Delta t,\bc^{(s)}\right),\quad \text{for } k=2,\dots, K.
\end{align*}

\begin{itemize}
\item Easy to solve
\item High orders involved:
\begin{itemize}
\item Order conditions: system of many equations
\item Stages  $K\geq d$ order of accuracy (e.g. RK44, RK65) 
\end{itemize}
\end{itemize} 
 
\end{frame}

\begin{frame}{Classical time integration: Implicit Runge--Kutta}
\begin{align*}
	&\bc^{(k)}:=\bc^n+\sum_{s=1}^{K} a_{ks} F\left(t^n+c_s\Delta t,\bc^{(s)}\right), \quad \text{for } k=2,\dots, K.
\end{align*}

\begin{itemize}
\item More complicated to solve for nonlinear systems
\item High orders easily done:
\begin{itemize}
\item Take a high order quadrature rule on $[t^n,t^{n+1}]$
\item Compute the coefficients accordingly, see Gauss--Legendre or Gauss--Lobatto polynomials
\item Order up to $d=2K$ 
\end{itemize}
\end{itemize} 
 
\end{frame}

\begin{frame}{ADER and DeC}
Two iterative explicit arbitrarily high order accurate methods.
\begin{itemize}
\item ADER\footnote{M. Dumbser, D. S. Balsara, E. F. Toro, and C.-D. Munz. A unified framework for the construction of one-step finite volume and discontinuous galerkin schemes on unstructured meshes. Journal of Computational Physics, 227(18):8209–8253, 2008.} for hyperbolic PDE, after a first analytic more complicated approach.
\item Deferred Correction (DeC): introduced for explicit ODE\footnote{A. Dutt, L. Greengard, and V. Rokhlin. Spectral Deferred Correction Methods for Ordinary Differential Equations. BIT Numerical Mathematics, 40(2):241–266, 2000.}, extended to implicit ODE\footnote{M. L. Minion. Semi-implicit spectral deferred correction methods for ordinary differential equations. Commun. Math. Sci., 1(3):471–500, 09 2003.} and to hyperbolic PDE\footnote{R. Abgrall. High order schemes for hyperbolic problems using globally continuous approximation and avoiding mass matrices. Journal of Scientific Computing, 73(2):461–494, Dec 2017.}.
\end{itemize}
\end{frame}

\section{DeC}
\begin{frame}{DeC high order time discretization: $\L^2$}
	\begin{minipage}{0.65\textwidth}
	High order in time: we discretize our variable on $[t^n, t^{n+1}]$ in $M$ substeps ($\bc^{m}$).
		\begin{equation*}
			\partial_t\bc = F(\bc(t)).
		\end{equation*}
	
		Thanks to Picard–Lindelöf theorem, we can rewrite 	\begin{equation*}
			\bc^{m}=\bc^0 +\int_{t^0}^{t^m} F(\bc(t))dt.
		\end{equation*} and if we want to reach order $r+1$ we need $M=r$. 
	\end{minipage}
	\begin{minipage}{0.32\textwidth}
		\begin{figure}[h]
			\centering
			\begin{tikzpicture}
				\draw [thick]   (0,0) -- (0,6) node [right=2mm]{};
				% nodes
				\fill[black]    (0,0) circle (1mm) node[right=2mm] {$t^n=t^0$} node[left=2mm] {$\bc^{n}=\bc^0$} 
				(0,1) circle (0.7mm) node[right=2mm] {$t^1$} node[left=2mm] {$\bc^1$} 
				(0,2) circle (0.7mm) node[right=2mm] {}
				(0,3) circle (0.7mm) node[right=2mm] {$t^m$ } node[left=2mm] {$\bc^m$} 
				(0,4) circle (0.7mm) node[right=2mm] {}
				(0,5) circle (0.7mm) node[right=2mm] {}
				(0,6) circle (1mm) node[right=2mm] {$t^M=t^{n+1}$} node[left=2mm] {$\bc^{n+1}=\bc^M$} ;
			\end{tikzpicture}
		\end{figure}
	\end{minipage}
	
\end{frame}



\begin{frame}{DeC high order time discretization: $\L^2$}
	\begin{minipage}{0.77\textwidth}
		More precisely, for each $\sigma$ we want to solve $\L^2 (\bc^{n,0},\dots,\bc^{n,M})=0$, where 
		{\begin{align*}
			\L^2(\bc^0, \dots, \bc^M) &
			\only<1>{=
			\begin{pmatrix}
				\bc^M-\bc^0 +\sum_{r=0}^M \int_{t^0}^{t^M} F(\bc^r) \varphi_r(s) \diff s\\
				\vdots\\
				\bc^1-\bc^0 + \sum_{r=0}^M \int_{t^0}^{t^1} F(\bc^r) \varphi_r(s) \diff s
			\end{pmatrix}
		}
			\only<2>{=
			\begin{pmatrix}
				\bc^M-\bc^0 +\Delta t \sum_{r=0}^M \theta_r^M F(\bc^r) \\
				\vdots\\
				\bc^1-\bc^0 + \Delta t \sum_{r=0}^M  \theta_r^1  F(\bc^r) 
			\end{pmatrix}}
		\end{align*}
	}
		\begin{itemize}
			\item $\L^2=0$ is a system of $M \times S$ coupled (non)linear equations
			\item $\L^2$ is an implicit method (collocation method: Gauss, LobattoIIIA)
			\item Not easy to solve directly $\L^2(\bbc^*)=0$
			\item High order ($\geq M+1$), depending on points distribution
		\end{itemize}
		
	\end{minipage}\hfill
	\begin{minipage}{0.2\textwidth}
		\begin{figure}[h]
			\centering
			\begin{tikzpicture}
				\draw [thick]   (0,0) -- (0,6) node [right=2mm]{};
				% nodes
				\fill[black]    (0,0) circle (1mm) node[right=2mm] {$t^{0}$} node[left=2mm] {$\bc^{0}$} 
				(0,1) circle (0.7mm) node[right=2mm] {$t^{1}$} node[left=2mm] {$\bc^{1}$} 
				(0,2) circle (0.7mm) node[right=2mm] {}
				(0,3) circle (0.7mm) node[right=2mm] {$t^{m}$ } node[left=2mm] {$\bc^{m}$} 
				(0,4) circle (0.7mm) node[right=2mm] {}
				(0,5) circle (0.7mm) node[right=2mm] {}
				(0,6) circle (1mm) node[right=2mm] {$t^{M}$} node[left=2mm] {$\bc^{M}$} ;
			\end{tikzpicture}
		\end{figure}
	\end{minipage}
\end{frame}

\begin{frame}{DeC low order time discretization: $\L^1$}
	\begin{minipage}{0.77\textwidth}
		Instead of solving the implicit system directly (difficult), we introduce a first order scheme $\L^1(\bc^{n,0},\dots,\bc^{n,M})$:
		\begin{align*}
			&\L^1(\bc^{0},\dots,\bc^{M})=
			\begin{pmatrix}
				\bc^M-\bc^0 +\Delta t \beta^M F(\bc^0) \\
				\vdots\\
				\bc^1-\bc^0 + \Delta t \beta^1  F(\bc^0) 
			\end{pmatrix}
		\end{align*}
		\begin{itemize}
			\item First order approximation
			\item Explicit Euler
			\item Easy to solve $\L^1(\bbc)=0$
		\end{itemize}
	\end{minipage}\hfill
	\begin{minipage}{0.2\textwidth}
		\begin{figure}[h]
			\centering
			\begin{tikzpicture}
	\draw [thick]   (0,0) -- (0,6) node [right=2mm]{};
	% nodes
	\fill[black]    (0,0) circle (1mm) node[right=2mm] {$t^{0}$} node[left=2mm] {$\bc^{0}$} 
	(0,1) circle (0.7mm) node[right=2mm] {$t^{1}$} node[left=2mm] {$\bc^{1}$} 
	(0,2) circle (0.7mm) node[right=2mm] {}
	(0,3) circle (0.7mm) node[right=2mm] {$t^{m}$ } node[left=2mm] {$\bc^{m}$} 
	(0,4) circle (0.7mm) node[right=2mm] {}
	(0,5) circle (0.7mm) node[right=2mm] {}
	(0,6) circle (1mm) node[right=2mm] {$t^{M}$} node[left=2mm] {$\bc^{M}$} ;
\end{tikzpicture}
		\end{figure}
	\end{minipage}
\end{frame}
\begin{comment}
\begin{frame}{DeC: Iterative process}
	$K$ iterations where the iteration index is the superscript $(k)$, with $k=0,\dots, K$
	\begin{enumerate}
		\item Define $\bc^{(0),m}=\bc^n=\bc(t^n)$ for $m=0,\dots,M$
		\item Define $\bc^{(k),0}=\bc(t^n)$ for $k=0,\dots,K$
		\item Find $\bbc^{(k)}$ as $\L^1(\bbc^{(k)})=\L^1(\bbc^{(k-1)})-\L^2(\bbc^{(k-1)})$
		\item $\bc^{n+1}= \bc^{(K),M}$.
	\end{enumerate}
	
	\begin{theorem}[Convergence DeC]
		\begin{itemize}
			\item If $\L^1$ coercive with constant $C_1$
			\item If $\L^1-\L^2$ Lipschitz with constant $C_2 \Delta t$
		\end{itemize}
		Then $\lVert \bbc^{(k)}-\bbc^*\rVert \leq C\Delta t^k$
	\end{theorem}
	Hence, choosing $K=M+1$, then $\lVert \bc^{(K),M}-\bc^{ex}(t^{n+1})\rVert \leq C\Delta t ^K$
\end{frame}
\end{comment}
\begin{frame}{Deferred Correction\footnote{A. Dutt, L. Greengard, and V. Rokhlin. BIT Numerical Mathematics, 40(2):241–266,
			2000.}}
	How to combine two methods keeping the accuracy of the second and the stability and simplicity of the first one?
	
	\begin{minipage}{0.58\textwidth}
		\begin{equation*}\label{DeC_method}
			\begin{split}
				&\bc^{0,(k)}:=\bc(t^n), \quad k=0,\dots, K,\\
				&\bc^{m,(0)}:=\bc(t^n),\quad m=1,\dots, M\\
				&\L^1(\bbc^{(k)})=\L^1(\bbc^{(k-1)})-\L^2(\bbc^{(k-1)})\text{ with }k=1,\dots,K.
			\end{split}
		\end{equation*}\vspace{-4mm}
\begin{theorem}[Convergence DeC]
	\begin{itemize}
		\item $\L^2(\bbc^*)=0$
		\item If $\L^1$ coercive with constant $C_1$
		\item If $\L^1-\L^2$ Lipschitz with constant $C_2 \Delta t$
	\end{itemize}
	Then $\lVert \bbc^{(K)}-\bbc^*\rVert \leq C(\Delta t)^K$
\end{theorem}
	\end{minipage} \hfill
	\begin{minipage}{0.4\textwidth}
		\begin{itemize}
			{
				\item $\mathcal{L}^1(\bbc)=0$, first order accuracy, easily invertible.
				\item $\mathcal{L}^2(\bbc)=0$, high order $M+1$.
			}
		\end{itemize}
		\begin{tikzpicture}
			\tikzset{dot/.style={fill=black,circle}}
			
			\foreach\l[count=\y] in {0,1,2,M}
			{
				\draw (1,\y) -- (3,\y);
				\draw[dashed] (3,\y) -- (5,\y);
				\node at (0.6,\y){$t^{\l}$};
				\foreach\foreach\z[count=\x] in {0,1,2,k,K}
				{
					\only<\x>{\fill (\x,\y) circle (1mm) node[anchor=south west] {$\!\bc^{(\z),\l}$};}
				}
			}
			
			\foreach\l[count=\x] in {0,1,2,k,K}
			{
				\draw (\x,1) -- (\x,3);
				\draw[dashed] (\x,3) -- (\x,4);
				\node at (\x,0.5){$\l$};
			}
			
		\end{tikzpicture}
	\end{minipage}
	
\end{frame}
%\begin{frame}{Deferred Correction\footnote{A. Dutt, L. Greengard, and V. Rokhlin. Spectral Deferred Correction Methods
%			for Ordinary Differential Equations. BIT Numerical Mathematics, 40(2):241–266,
%			2000.}}
%	How to combine two methods keeping the accuracy of the second and the stability and simplicity of the first one?\\
%	\begin{itemize}
%		{
%			\item $\mathcal{L}^1(f^{n+1},f^n)=0$, first order accuracy, easily invertible (IMEX).
%			\item $\mathcal{L}^2(f^{n+1},f^n)=0$, high order $r$ (>1), not directly solvable.
%		}
%	\end{itemize}
%	\pause
%	\begin{algo}[DeC method]
%		\begin{itemize}
%			\item $\mathcal{L}^1(f^{(1)},f^n)=0$, prediction $f^{(1)}$.
%			\item For $j=2,\dots,K$ corrections: \\ $\quad \mathcal{L}^1(f^{(j)},f^n)=\mathcal{L}^1(f^{(j-1)},f^n)-\mathcal{L}^2(f^{(j-1)},f^n).$
%			\item $f^{n+1}:=f^{(K)}$.
%		\end{itemize}
%	\end{algo}
%	\begin{remark}
%		$\mathcal{L}^1$ is used implicitly and $\mathcal{L}^2$ only explicitly.
%	\end{remark}
%\end{frame}

%\begin{frame}{Deferred Correction}
%			\begin{theorem}[Deferred Correction convergence]
%		Given the DeC procedure. If
%		\begin{itemize}
%			\item $\mathcal{L}^1$ is coercive with constant $\alpha_1$
%			\item $\mathcal{L}^2-\mathcal{L}^1$ is Lipschitz continuous with constant $\alpha_2 \Delta$
%			\item $\exists !\, f^{*}_\Delta$ such that $\mathcal{L}^2(f^{*}_\Delta)=0$.
%		\end{itemize}
%		Then if $\eta=\frac{\alpha_2}{\alpha_1}\Delta<1$, the deferred correction is converging to $ f^*_\Delta$ and after $K$ iterations the error is smaller than $\eta^K$ times the original error.
%	\end{theorem}
%\end{frame}

\begin{frame}{DeC -- Proof}
	
	\small
	\begin{proof}
		Let $f^*$ be the solution of $\L^2(\bbc^*)=0$. We know that $\L^1(\bbc^*)=\L^1(\bbc^*)-\L^2(\bbc^*)$, so that
		\visible<2>{
		\begin{align*}
			\L^1(\bbc^{(k+1)})-\L^1(\bbc^*)=&\left(\L^1(\bbc^{(k)})-\L^2(\bbc^{(k)})\right)-\left(\L^1(\bbc^*)-\L^2(\bbc^*)\right)  \\
			{\color{red}C_1 }||\bbc^{(k+1)}-\bbc^*||\leq & ||\L^1(\bbc^{(k+1)})-\L^1(\bbc^*)||=\\
			=&||\L^1(\bbc^{(k)})-\L^2(\bbc^{(k)})-(\L^1(\bbc^*)-\L^2(\bbc^*))||\leq \\
			\leq &  {\color{red} C_2 \Delta } ||\bbc^{(k)}-\bbc^*||.\\
			||\bbc^{(k+1)}-\bbc^*||\leq &\left(\frac{C_2}{C_1}\Delta\right) ||\bbc^{(k)}-\bbc^*|| \leq \left(\frac{C_2}{C_1}\Delta\right)^{k+1} ||\bbc^{(0)}-\bbc^*||.
		\end{align*}
		After $K$ iteration we have an error at most of $\left(\frac{C_2}{C_1}\Delta\right)^K ||\bbc^{(0)}-\bbc^*||$. }
	\end{proof}
	
\end{frame}



\begin{comment}
\begin{frame}{DeC: $\L^2$ operator}
\begin{align*}
\L^2(\bc^0, \dots, \bc^M) &=
\begin{cases}
 \bc^M-\bc^0 -\int_{t^0}^{t^M} \I_M ( F(\bc^0),\dots,F(\bc^M))ds
\\
\dots\\
\bc^1-\bc^0 - \int_{t^0}^{t^1} \I_M ( F(\bc^0),\dots,F(\bc^M))ds
\end{cases}\\
 &=
\begin{cases}
\bc^M-\bc^0 -\sum_{r=0}^M \int_{t^0}^{t^M} F(\bc^r) \varphi_r(s) \diff s\\
\dots\\
\bc^1-\bc^0 - \sum_{r=0}^M \int_{t^0}^{t^1} F(\bc^r) \varphi_r(s) \diff s
\end{cases}
\\
 &=
\begin{cases}
\bc^M-\bc^0 -\Delta t \sum_{r=0}^M \theta_r^M F(\bc^r) \\
\dots\\
\bc^1-\bc^0 - \Delta t \sum_{r=0}^M  \theta_r^1  F(\bc^r) 
\end{cases}
\end{align*}

\end{frame}

\begin{frame}{DeC: $\L^2$ operator}
Goal: find $\bbc^*=(\bc^0, \dots, \bc^m, \dots, \bc^M)^*$ : $\L^2(\bbc^*)=0$.
\vspace{1cm}
\begin{itemize}
\item $\L^2=0$ is a system of $M \times S$ coupled (non)linear equations
\item $\L^2$ is an implicit method 
\item Not easy to solve directly
\item High order ($\geq M+1$), depending on points distribution
\end{itemize}
\end{frame}
\begin{frame}{DeC: $\L^1$ operator}
\begin{equation}\label{eq:L1}
\L^1(\bc^0, \dots, \bc^M) :=
\begin{cases}
 \bc^M-\bc^0 - \beta^M \Delta t F(\bc^0) \\
\vdots\\
\bc^1- \bc^0 - \beta^1 \Delta t F(\bc^0)
\end{cases} \quad\beta^m:=\frac{t^m-t^0}{t^M-t^0}. 
\end{equation}
\begin{itemize}
\item First order approximation
\item Explicit Euler
\item Easy to solve $\L^1(\bbc)=0$
\end{itemize}
\end{frame}

%
\end{comment}

\begin{comment}
\begin{frame}{DeC -- Proof}
\small
\begin{proof}
Let $\bbc^*$ be the solution of $\L^2(\bbc^*)=0$. We know that $\L^1(\bbc^*)=\L^1(\bbc^*)-\L^2(\bbc^*)$ and $\L^1(\bbc^{(k+1)})=\left(\L^1(\bbc^{(k)})-\L^2(\bbc^{(k)})\right)$, so that
\begin{align*}
C_1 ||\bbc^{(k+1)}-\bbc^*||\leq & ||\L^1(\bbc^{(k+1)})-\L^1(\bbc^*)||=\\
=&||\L^1(\bbc^{(k)})-\L^2(\bbc^{(k)})-(\L^1(\bbc^*)-\L^2(\bbc^*))||\leq \\
\leq &  C_2 \Delta t ||\bbc^{(k)}-\bbc^*||.\\
||\bbc^{(k+1)}-\bbc^*||\leq &\left(\frac{C_2}{C_1}\Delta t\right) ||\bbc^{(k)}-\bbc^*|| \leq \left(\frac{C_2}{C_1}\Delta t\right)^{k+1} ||\bbc^{(0)}-\bbc^*||.
\end{align*}
After $K$ iteration we have an error at most of $\eta^K\cdot ||\bbc^{(0)}-\bbc^*||$. 
\end{proof}

\end{frame}
\end{comment} 
%\begin{comment}
\begin{frame}{DeC: Second order example}

\end{frame}


\begin{frame}{DeC: Second order example}

\end{frame}

\begin{frame}{DeC: Second order example}
	
\end{frame}

\begin{frame}{DeC: Second order example}
	
\end{frame}

%\end{comment}

\begin{frame}{Simplification of DeC for ODE}
In practice
\begin{equation*}
	\L^1(\bbc^{(k)})= \L^1(\bbc^{(k-1)})-\L^2(\bbc^{(k-1)}),\qquad k=1,\dots, K,
\end{equation*}
For $m=1,\dots, M$
\begin{align*}
	&  \bc^{(k),m}\!\!\!\! -\only<2->{\cancel}{\bc^0\!\!-\beta^m\Delta t F(\bc^{0})}- \only<3->{\cancel}{\bc^{(k-1),m}}	\!\! +\only<2->{\cancel}{\bc^0\!\!+\!\!\beta^m\Delta t F(\bc^{0})}\\
&	+\only<3->{\cancel}{ \bc^{(k-1),m}}\!\!\!\!-\bc^0\!\! -\!\!\Delta t \sum_{r=0}^M\theta_r^m F(\bc^{(k-1),r}) =0 \only<4->{\\
		&    \bc^{(k),m} -\bc^0 -\Delta t \sum_{r=0}^M\theta_r^m F(\bc^{(k-1),r})=0.}
\end{align*}




\end{frame}

\begin{frame}{DeC and residual distribution}
	Deferred Correction + Residual distribution
	\begin{itemize}
		\item Residual distribution (FV  $\Rightarrow$ FE) $\Rightarrow$ High order in space
		\item Prediction/correction/iterations $\Rightarrow$ High order in time
		\item Subtimesteps $\Rightarrow$ High order in time
	\end{itemize}
	\begin{equation*}\label{oneline}
		\begin{split}
			U^{m,(k+1)}_\xi = U_\xi^{m,(k)} -
			|C_p|^{-1} 
			\sum_{\E|\xi \in \E}\bigg(\int_\E \Phi_\xi \left(U^{m,(k)} - U^{n,0} \right) \dd \mathbf{x} +\Delta t
			\sum_{r=0}^M \theta_{r}^m \mathcal{R}_\xi^\E(U^{r,(k)}) \bigg),
		\end{split}
	\end{equation*}
	\begin{center}
		with
	\end{center}
	\begin{equation*}\label{eq:L2RDspacetime}
		\sum_{\xi \in {\E}} {\mathcal{R}}^{{\E}}_\xi (u) = \int_{\E} \nabla_\mathbf{x}F(u)
		\dd \mathbf{x}.
	\end{equation*}
\begin{itemize}
	%Example: PDEs, FEM discretization \vspace{3mm}
	\item The $\L^2$ operator contains also the complications of the spatial discretization (e.g. mass matrix)\vspace{2mm}
	\item $\L^1$ operator further simplified up to a first order approximation (e.g. \textbf{mass lumping}) 
\end{itemize}
\end{frame}

\begin{frame}{$\L^1$ with mass lumping}
	
\end{frame}

\begin{frame}{Implicit simple DeC (Rosenbrock)}
	Define $\L^1$ as
			\begin{align*}
		\L^1(\bc^{0},\dots,\bc^{M})&=\only<1>{
		\begin{pmatrix}
			\bc^M-\bc^0 -\Delta t \beta^M F(\bc^0) \\
			\vdots\\
			\bc^1-\bc^0 - \Delta t \beta^1  F(\bc^0) 
		\end{pmatrix}}
	\only<2>{\begin{pmatrix}
			\bc^M-\bc^0 -\Delta t \beta^M \left( F(\bc^0) + \partial_{\bc} F(\bc^0) (\bc^M-\bc^0) \right)  \\
			\vdots\\
			\bc^1-\bc^0 - \Delta t \beta^1 \left( F(\bc^0) + \partial_{\bc} F(\bc^0) (\bc^1-\bc^0) \right) 
	\end{pmatrix}\\
    &=\begin{pmatrix}
		\bc^M-\bc^0 -\Delta t \beta^M  \partial_{\bc} F(\bc^0) \bc^M  \\
		\vdots\\
		\bc^1-\bc^0 - \Delta t \beta^1  \partial_{\bc} F(\bc^0) \bc^1
\end{pmatrix}}
	\end{align*}
\end{frame}

\begin{frame}{Implicit simple DeC (Rosenbrock)}
			\begin{align*}
				\L^{1,m}(\bc^{0},\dots,\bc^{M})&=
				\bc^m-\bc^0 -\Delta t \beta^m \partial_{\bc} F(\bc^0) \bc^m \\
				\L^{2,m}(\bc^{0},\dots,\bc^{M})&=
		\bc^m-\bc^0 -\Delta t \sum_r \theta^m_r  F(\bc^r)
	\end{align*}
	\vspace{15cm}
\end{frame}

\begin{frame}{Implicit simple DeC (Rosenbrock)}
\end{frame}

\begin{frame}{DeC as RK}
$$\bc^{(k),m} -\bc^0 -\Delta t \sum_{r=0}^M\theta_r^m F(\bc^{(k-1),r})=0$$
\vspace{10cm}
\end{frame}

\begin{frame}{DeC as RK}

\end{frame}

\begin{frame}{DeC as RK}
	We can write DeC as RK defining $\vec{\theta}_0 = \lbrace\theta_0^m\rbrace_{m=1}^M$, $\vec{\theta}^M=\theta_r^{M}$ with $r \in 1, \dots, M, $  denoting the vector  $ \vec{\theta}_r^{M,T} =(\theta_1^M, \dots, \theta_M^M )$.
		The Butcher tableau for an arbitrarily high order DeC approach is given by:
		\begin{equation}\label{eq:DeC_RK}
			\begin{aligned}
				\begin{array}{c|cccccccc}
					0 & 0 &   & &  & & &  & \\
					\vec{\beta} & \vec{\beta} &  &   & & & & &  \\
					\vec{\beta}  & \vec{\theta}_0 &   \mat{\tilde{\theta}} & & & & & &\\
					\vdots & \vec{\theta}_0 & \mat{0}  &\mat{\tilde{\theta}}   && & & &\\
					\vdots & \vec{\theta}_0 &  \mat{0}   &   \mat{0}  & \mat{\tilde{\theta}}  &  &  & &\\
					\vdots &  \vdots  &  \vdots &  \vdots &  \ddots  &  \ddots& & & \\
					\vec{\beta} & \vec{\theta}_0 &  \mat{0}  &  \dots &  \dots & \mat{0}  &  \mat{\tilde{\theta}} & \\
					\hline
					&  \theta_0^M & \vec{0}^T    & \dots  &   &   \dots &    \vec{0}^T& \vec{\theta}_r^{M,T} 
				\end{array}.
			\end{aligned}
	\end{equation}
\end{frame}

\begin{frame}{Stability of (explicit) DeC}
	Idea: study the RK version!
\begin{equation}
	u'=\lambda u \qquad \Re(\lambda)<0.
\end{equation}
\begin{equation}
	u_{n+1}=R(\lambda \dt) u_n,\qquad	R(z) = 1+ z b^T (I-zA)^{-1} \mathbf{1},\qquad z=\lambda \dt
\end{equation}
Goal: find $z\in \mathbb C$ such that $\lvert R(z) \rvert< 1$. \\
Recall: stability function for explicit RK methods is a polynomial, indeed the inverse of $(I-zA)$ can be written in Taylor expansion as
\begin{equation}
	(I-zA)^{-1} = \sum_{r=0}^{\infty} z^r A^s = I + zA + z^2A^2+\dots, 
\end{equation} 
and, since $A$ is strictly lower triangular, it is nilpotent.
Hence, $R(z)$ is a polynomial in $z$ with degree at most equal to $S$.

\end{frame}

\begin{frame}{Stability of (explicit) DeC}
	
\begin{theorem}\label{th:RK_stab_functions}
	If the RK method is of order $P$, then\begin{equation}\label{eq:RK_order}
		R(z) = 1 + z + \frac{z^2}{2!} +\dots +\frac{z^P}{P!}+O(z^{P+1}).
	\end{equation}
\end{theorem}

The first $P+1$ terms of the stability functions $R(\cdot)$ for explicit DeCs of order $P$ are known.
\begin{theorem}\label{th:bDeC_equivalence} 
	The stability function of any explicit DeC of order $P$ (with $P$ iterations) is
	\begin{equation}
		R(z) = \sum_{r=0}^{P} \frac{z^r}{r!}= 1 + z + \frac{z^2}{2!} +\dots +\frac{z^P}{P!}
	\end{equation}
	and does not depend on the distribution of the subtimenodes.
\end{theorem}  
\end{frame}


\begin{frame}{Stability of (explicit) DeC}
	\begin{block}{Proof (1/3)}
				\begin{minipage}{0.4\textwidth}
			\begin{equation*}
			A= \begin{pmatrix}
				0 & 0 & 0&  \dots &0 &0\\
				\star & 0 & 0&  \dots & 0 &0\\
				\star & \star & 0 & \dots & 0 &0\\
				\star & 0& \star  & \dots & 0 &0\\
				\vdots & \vdots & \vdots &\ddots &\vdots&\vdots \\
				\star & 0 & 0 &\cdots   &\star &0
			\end{pmatrix},
		\end{equation*}
	\end{minipage}
	\begin{minipage}{0.55\textwidth}
		Block structure of the matrix $A$\\
		$\star$ are some non-zero block matrices and the 0 are some zero block matrices.\\
		The number of blocks in each line and row of these matrices is $P$, the order of the scheme.
	\end{minipage}
\end{block}

\end{frame}


\begin{frame}{Stability of (explicit) DeC}
		\begin{block}{Proof (2/3)}
	By induction, $A^k$ 
	has zeros in the upper triangular part, in the main block diagonal, and in all the $k-1$ block diagonals below the main diagonal, i.e., $$(A^k)_{i,j} = 0 \quad, \text{if } i< j+k,$$ where the indexes here refer to the blocks.
	Indeed, it is true that $A_{i,j}=0$ if $i<j+1$.
	Now, let us consider the entry $(A^{k+1})_{i,j}$ with $i<j+k+1$, i.e., $i-k<j+1$. It is defined as
	\begin{equation}
		(A^{k+1})_{i,j} = \sum_{w} (A^{k})_{i,w} A_{w,j}.
	\end{equation}
	Now, we can prove that all the terms of the sum are 0. Let $w<j+1$, then $A_{w,j}=0$ because of the structure of $A$; while, if $w\geq j+1 >i-k$, we have that $i<w+k$, so $(A^k)_{i,w} = 0$ by induction. 
\end{block}
\end{frame}


\begin{frame}{Stability of (explicit) DeC}
	\begin{block}{Proof (3/3)}
		In particular, this means that $A^{P}=\matz$, because $i$ is always smaller than $j+P$ as $P$ is the number of the block matrices that we have.
		Hence, 
		\begin{equation}
			(I-zA)^{-1}=\sum_{r=0}^{\infty} z^rA^s =\sum_{r=0}^{P-1} z^rA^s = I + zA + z^2A^2+\dots + z^{P-1}A^{P-1}. 
		\end{equation}
		Plugging this result into $R(z) = 1+ z b^T (I-zA)^{-1} \mathbf{1}$,
		the stability function $R(z)$ is a polynomial of degree $P$, the order of the scheme. 
		All terms of order lower or equal to $P$ must agree with the expansion of the exponential function, so it must be
		\begin{equation}
			R(z) = \sum_{r=0}^{P} \frac{z^r}{r!}= 1 + z + \frac{z^2}{2!} +\dots +\frac{z^P}{P!}.
		\end{equation}
		Note: no assumption on the distribution of the subtimenodes.
	\end{block}
\end{frame}

\begin{frame}{CODE}
\begin{itemize}
	\item Choice of iterations ($P$) and order
	\item Choice of point distributions $t^0, \dots, t^M$
	\item Computation of $\theta$
	\item Loop for timesteps
	\item Loop for correction
	\item Loop for subtimesteps
\end{itemize}
\end{frame}


\section{ADER}
\begin{frame}{ADER}
	\begin{minipage}{0.43\textwidth}
	\begin{itemize}
		\item Cauchy–Kovalevskaya theorem
		\item Modern  automatic version 
		\item Space/time DG
		\item Prediction/Correction
		\item Fixed-point iteration process
	\end{itemize}
\end{minipage}\hfill
\begin{minipage}{0.55\textwidth}
Modern approach is DG in space time for hyperbolic problem
\begin{equation}
	\label{eq:pde}
	\partial_t u(x,t) + \nabla \cdot F(u(x,t)) = 0, \,  x\in \Omega\subset \R^d,\; t>0.
\end{equation}
\end{minipage}

	Prediction: iterative procedure
	\begin{equation*}
		\int_{\STC}\!\!\!\!\!\!\!\! \theta_{rs}(x,t)\partial_t \theta_{pq}(x,t) z^{pq} \diff x \diff t+ \int_{\STC}\!\!\!\!\!\!\!\! \theta_{rs}(x,t) \nabla_{\mathbf{x}} \cdot F(\theta_{pq}(x,t) z^{pq})  \diff x \diff t=0.
	\end{equation*}
	Correction step: communication between cells
	\begin{equation*}
		\int_{\SC} \Phi_r\left( u(t^{n+1})-u(t^n) \right) \dd x + \int_{ \TC\times \partial \SC}\!\!\!\!\!\!\!\! \!\!\!\!\Phi_r(x) \mathcal{G}(z^{-},z^{+}) \cdot \boldsymbol{\mathrm{n}} \, \diff S\, \diff t - \int_{ \STC} \!\!\!\!\!\!\!\!\!\!\!\!\nabla_{\mathbf{x}} \Phi_r \cdot F(z) \, \diff x\, \diff t =0,
	\end{equation*}
	
\end{frame}

\begin{frame}{ADER: space-time discretization}

Defining $\theta_{rs}(x,t) =\Phi_r(x) \phi_s(t)$ basis functions in space and time
\begin{equation}
\int_{\STC}\!\!\!\!\!\! \theta_{rs}(x,t)\partial_t \theta_{pq}(x,t) u^{pq} \diff x \diff t+ \int_{\STC}\!\!\!\!\!\! \theta_{rs}(x,t) \nabla \cdot F(\theta_{pq}(x,t) u^{pq})  \diff x \diff t=0.\label{eq:spaceTimeDG}
\end{equation}
\pause

This leads to
\begin{equation}\label{eq:ADER_DG}
\vec{\vec{\M}}_{rspq} u^{pq} = \vec{\vec{r}}(\vec{\vec{\mathbf{u}}})_{rs},
\end{equation}
solved with fixed point iteration method.

 +  Correction step where cells communication is allowed (derived from \eqref{eq:spaceTimeDG}). 

\end{frame}

\begin{frame}{ADER: time integration method}
Simplify!  Take $\bc(t) = \sum_{m=0}^M \phi_m(t) \bc^m = \bphi(t)^T\bbc$
\begin{align*}\label{eq:ADERODEL2}
&\int_{T^n}  \psi(t)\partial_t \bc(t) dt - \int_{T^n} \psi(t)F(\bc(t))  dt = 0, \quad  \forall \psi: T^n=[t^n,t^{n+1}]\to \R.
\\
&\L^2(\bbc ):= \int_{T^n} \bphi(t) \partial_t \bphi(t)^T \bbc dt - \int_{T^n} \bphi(t)  F(\bphi(t)^T\bbc)  dt = 0\\
&\bphi(t) = \left( \phi_0(t), \dots, \phi_M(t) \right)^T
\end{align*}\\

Quadrature\dots

\begin{equation}\label{fix:point}
\L^2(\bbc):=\M\bbc-\vec{r}(\bbc)=0 \Longleftrightarrow  \M \bbc = \vec{r}(\bbc)  .
\end{equation}

Nonlinear system of $M \times S$ equations


\end{frame}
\begin{frame}{ADER: Mass matrix}
	What goes into the mass matrix? Use of the integration by parts
	\begin{align*}
		\L^2(\bbc ):=& \int_{T^n} \bphi(t) \partial_t \bphi(t)^T \bbc dt + \int_{T^n} \bphi(t)  F(\bphi(t)^T\bbc)  dt =\\
		&{\color{red}\bphi(t^{n+1}) \bphi(t^{n+1})^T \bbc} - \bphi(t^{n}) \bc^n -  {\color{red}\int_{T^n} \partial_t \bphi(t) \bphi(t)^T \bbc }  - \int_{T^n} \bphi(t)  F(\bphi(t)^T\bbc)  dt 
	\end{align*}
	$$
	\M = \bphi(t^{n+1}) \bphi(t^{n+1})^T -\int_{T^n} \partial_t \bphi(t) \bphi(t)^T 
	$$
	$$
	\vec{r}(\bbc) =  \bphi(t^{n}) \bc^n + \int_{T^n} \bphi(t)  F(\bphi(t)^T\bbc)  dt 
	$$
$$
\M \bbc = \vec{r}(\bbc)
$$
\end{frame}


\begin{frame}{ADER: Fixed point iteration}
Iterative procedure to solve the problem for each time step
\begin{equation}\label{fix:point}
\bbc^{(k)}=\M^{-1}\vec{r}(\bbc^{(k-1)}),\quad k=1,\dots, \text{convergence}
\end{equation}
with $\bbc^{(0)}=\bc(t^n)$.

Reconstruction step
\begin{equation*}
	\bc(t^{n+1}) = \bc(t^{n}) - \int_{T^n} F(\bc^{(K)}(t))  dt.
\end{equation*}
\begin{itemize}
\item Convergence?
\item How many steps $K$?
\item Accuracy $\L^2$?
\end{itemize}

\end{frame}

\begin{frame}{ADER 2nd order}
	Example with 2 Gauss Legendre points, Lagrange polynomials and 2 iterations

	Let us consider the timestep interval $[t^n,t^{n+1}]$, rescaled to $[0,1]$. 
	
	Gauss-Legendre points  quadrature and interpolation (in the interval $[0,1]$) 
	\[\ww{t}_q =  \left( t^0_q, t^1_q \right) = \left( t^0, t^1 \right) =  \left( \frac{\sqrt{3}-1}{2\sqrt{3}}, \frac{\sqrt{3}+1}{2\sqrt{3}} \right), \quad \ww{w} = \left(1/2,1/2\right). \]
	
	\[\ww{\phi}(t) = \left( \phi_0(t), \phi_1(t) \right) = \left( \frac{t-t^1}{t^0-t^1}, \frac{t-t^0}{t^1-t^0} \right). \]
	
	Then, the mass matrix is given by
	\[\M_{m,l} = \phi_m(1)\phi_l(1) - \phi'_m(t^l) w_l, \quad m, l = 0,1,\]
	\[ \M =
	\begin{pmatrix}
		1   & \frac{\sqrt{3}-1}{2}  \\
		-\frac{\sqrt{3}+1}{2}   & 1
	\end{pmatrix}.\]

\end{frame}

\begin{frame}{ADER 2nd order}

	The right hand side is given 
	
	\[ r(\bbc)_m = \alpha(0) \phi_m(0) + \Delta t F(\alpha(t^m)) w_m, \quad m=0,1. \] 
	
	\[ \vec{r}(\bbc) = \alpha(0)\vec{\phi}(0) +\Delta t
	\begin{pmatrix}
		F(\alpha(t^1)) w_1  \\
		F(\alpha(t^2)) w_2.
	\end{pmatrix}.\]
	
	
	Then, the coefficients $\bbc$ are given by
	
	\begin{align*}
		\bbc^{(k+1)} &= \M^{-1} \vec{r}( \bbc^{(k)} ).
	\end{align*}
	Finally, use $\bbc^{(k+1)}$ to reconstruct the solution at the time step $t^{n+1}$:
	
	\begin{align*}
		\bc^{n+1} &= \vec{\phi}(1)^T \bbc^{(k+1)}=\bc^n + \int_{T^n}\bphi(t)^T dt\, F(\bbc^{(k)}).
	\end{align*}
	
	
\end{frame}

\begin{frame}{CODE}
	\begin{itemize}
		\item Choice: $\phi$ Lagrangian basis functions
		\item Different subtimesteps: Gauss-Legendre, Gauss--Lobatto, equispaced
		\item Precompute $\M$
		\item Precompute the rhs vector part using quadratures after a further approximation 
		$$\vec{r}(\bbc) =  \bphi(t^{n}) \bc^n + \int_{T^n} \bphi(t)  F(\bphi(t)^T\bbc)  dt \approx \bphi(t^{n}) \bc^n + \underbrace{\int_{T^n} \bphi(t)\bphi(t)^Tdt}_{\text{Can be stored}}  F(\bbc)  $$
		\item Precompute the reconstruction coefficients $\bphi(1)^T$
	\end{itemize}
\end{frame}


\section{Similarities}
\begin{frame}{ADER\footnote{M. Dumbser, D. S. Balsara, E. F. Toro, and C.-D. Munz. A unified framework for the construction of one-step finite volume and discontinuous galerkin schemes on unstructured meshes. Journal of Computational Physics, 227(18):8209–8253, 2008.} and DeC\footnote{R. Abgrall. High order schemes for hyperbolic problems using globally continuous approximation and avoiding mass matrices. Journal of Scientific Computing, 73(2):461–494, Dec 2017.}: immediate similarities}
	\begin{itemize}
		\item High order time-space discretization
		\item Start from a well known space discretization (FE/DG/FV)
		\item FE reconstruction in time
		\item System in time, with $M$ equations 
		\item Iterative method / $K$ corrections  
	\end{itemize}
	\pause
	\begin{itemize}
		\item Both high order explicit time integration methods (neglecting spatial discretization)
	\end{itemize}
	
\end{frame}
\begin{frame}{ADER as DeC}

\end{frame}

\begin{frame}{ADER as DeC}
	
\end{frame}


\begin{frame}{ADER as DeC}
\begin{align*}
& \L^2(\bbc):=\M\bbc-r(\bbc),\\
& \L^1(\bbc):= \M\bbc-r(\bc(t^n)).
\end{align*}

\begin{equation*}
 \L^1(\bbc^{(k)})= \L^1(\bbc^{(k-1)})-\L^2(\bbc^{(k-1)}),\qquad k=1,\dots, K,
\end{equation*}

\begin{align*}
 &  \M \bbc^{(k)} -\only<2->{\cancel}{r(\bc^{(k),0})}- \only<3->{\cancel}{\M \bbc^{(k-1)}}	 +\only<2->{\cancel}{r(\bc^{(k-1),0})}
   +\only<3->{\cancel}{\M \bbc^{(k-1)}} -r(\bbc^{(k-1)}) =0 \only<4>{\\
&    \M \bbc^{(k)} -r(\bbc^{(k-1)}) =0.}
\end{align*}
\end{frame}

\begin{frame}{ADER as DeC}
\begin{align*}
& \L^2(\bbc):=\M\bbc-r(\bbc),\\
& \L^1(\bbc):= \M\bbc-r(\bc(t^n)).
\end{align*}

Apply the DeC Convergence theorem!

\begin{itemize}
\item $\L^1$ is coercive because $\M$ is always invertible
\item $\L^1-\L^2$ is Lipschitz with constant $C\Delta t$ because they are consistent approx of the same problem
\item Hence, after $K$ iterations we obtain a $K$th order accurate approximation of $\bbc^*$
\end{itemize}

\end{frame}

\begin{frame}{DeC as ADER}
	
\begin{align*}
	\L^2(\bc^0, \dots, \bc^M) &:=
	\begin{cases}
		\bc^M-\bc^0 -\sum_{r=0}^M \int_{t^0}^{t^M} F(\bc^r) \varphi_r(s) \diff s\\
		\dots\\
		\bc^1-\bc^0 - \sum_{r=0}^M \int_{t^0}^{t^1} F(\bc^r) \varphi_r(s) \diff s
	\end{cases}.
\end{align*}
	\vspace{10cm}
\end{frame}

\begin{frame}{DeC as ADER}
	
\end{frame}

\begin{frame}{DeC as ADER}
	
\end{frame}

\begin{frame}{DeC as ADER}

\begin{align*}\label{eq:L2op}
%\L^2(\bc^0, \dots, \bc^M) &:=
%\begin{cases}
% \bc^M-\bc^0 -\int_{t^0}^{t^M} \I_M ( F(\bc^0),\dots,F(\bc^M))
%\\
%\vdots\\
%\bc^1-\bc^0 - \int_{t^0}^{t^1} \I_M ( F(\bc^0),\dots,F(\bc^M))
%\end{cases}\\
\L^2(\bc^0, \dots, \bc^M) &:=
\begin{cases}
\bc^M-\bc^0 -\sum_{r=0}^M \int_{t^0}^{t^M} F(\bc^r) \varphi_r(s) \diff s\\
\dots\\
\bc^1-\bc^0 - \sum_{r=0}^M \int_{t^0}^{t^1} F(\bc^r) \varphi_r(s) \diff s
\end{cases}.
\end{align*}
\pause
\begin{align*}
&	\cc{m}(t^m)\bc^m-\cc{m}(t_0)\bc^0-  \int_{t^0}^{t^m} \cc{m}(t)   \sum_{r=0}^M F(\bc^r)\varphi_r(t) \diff t=0\\
%\begin{equation}\label{eq:characteristic}
% \cc{m}(t)=\begin{cases}
%         1, \qquad \text{if}  &t\in [t^0,t^m],\\
%         0, \qquad \text{else}.
%        \end{cases}
%\end{equation} 
%\pause
 &\int_{t^0}^{t^M} \cc{m}(t) \partial_t \left(\bc(t)\right) \diff t-
 \int_{t^0}^{t^M} \cc{m}(t) \sum_{r=0}^M  F(\bc^r) \varphi_r(t) \diff t=0,\\
 &\int_{T^n} \psi_{m}(t) \partial_t \bc(t) \diff t- \int_{T^n} \psi_{m}(t)
 F(\bc(t)) \diff t=0. 
\end{align*}
\end{frame}

\begin{comment}
\begin{frame}{DeC -- ADER}
Both are
\begin{itemize}
\item Iterative processes (only iterations $K=d$ order of accuracy) 
\item Arbitrarily high order accurate
\item Explicit
\end{itemize}

ADER as DeC iterative process
\begin{itemize}
\item The operators $\L^1$ and $\L^2$ can be written
\item Convergence results hold
\item We know in practice how many iteration $K$
\end{itemize}

DeC as ADER
\begin{itemize}
\item $\L^2$ is the same up to the choice of basis and test functions in time
\end{itemize}

\end{frame}
\end{comment}
%\subsection{}
\begin{frame}{Runge Kutta vs DeC--ADER}
	\begin{minipage}{0.54\textwidth}
		\begin{block}{Classical Runge Kutta (RK)}
			\begin{itemize}
				\item One step method\item Internal stages
			\end{itemize}
			%\pause
			Explicit Runge Kutta
			\begin{itemize}
				\item[\color{green}+] Simple to code 
				\item[\color{red}-] Not easily generalizable to arbitrary order
				\item[\color{red}-] Stages $>$ order 
			\end{itemize}
			%\pause
			Implicit Runge Kutta
			\begin{itemize}
				\item[\color{green}+] Arbitrarily high order
				\item[\color{red}-] Require nonlinear solvers for nonlinear systems
				\item[\color{red}-] May not converge
			\end{itemize}
		\end{block}
	\end{minipage}
	\hfill
	\begin{minipage}{0.41\textwidth}
		%\pause 
		\begin{block}{DeC -- ADER}
			\begin{itemize}
				\item One step method\item Internal subtimesteps \item Can be rewritten as explicit RK (for ODE)
				\item[\color{green}+] Explicit
				\item[\color{green}+] Simple to code 
				\item[\color{green}+] Iterations $=$ order 
				\item[\color{green}+] Arbitrarily high order
				\item[\color{red}-] Large memory storage
			\end{itemize}
		\end{block}
	\end{minipage}
	
	
\end{frame}

\section{ADER stability and accuracy}
\begin{frame}{Stability}
	Since ADER can be written as a DeC, the stability functions are 
	given by the same formula as for DeC and the stability regions are the following.
	\begin{figure}[h] 
		\centering
		\includegraphics[width=0.45\textwidth, trim={30 20 30 20},clip]{stab_glb.pdf}
		\includegraphics[width=0.45\textwidth, trim={30 20 30 20},clip]{ader_all.pdf}
		\caption{Stability region}
		\label{fig:stab}
	\end{figure}
\end{frame}

\begin{frame}{Accuracy of ADER $\L^2$ operators}
	The two things that determine the accuracy of the ADER method are the iterations $P$ and the accuracy of $\L^2$.

	\begin{block}{Accuracy of ADER $\L^2$ for different distributions}
		\begin{itemize}
			\item Equispaced: boring, minimum accuracy possible $M+1$ nodes $p=M+1$
			\item Guass--Lobatto: this generates the LobattoIIIC methods, $M+1$ nodes $p=2M$
			\item Gauss--Legendre: this does not generate Gauss methods, $M+1$ nodes $p=2M+1$ 
		\end{itemize}
		
	\end{block}

\end{frame}
\begin{frame}{$\L^2$ ADER as RK}
	Here, we see $\L^2$ as an implicit RK
	\begin{align*}
		&\L^{2,m}(\bbc) = \M^m_j \bc^{(j)} - \bphi^m(t^{n}) \bc^n - \underbrace{\int_{T^n} \bphi^m(t) 
		 \bphi(t)_j dt}_{\dt \RHS_j^m}  F(\bc^{(j)})=0\\
		&\tilde\L^{2,z}(\bbc) =  \bc^{(z)} - (\M^{-1})_m^z \bphi^m(t^{n})
		 \bc^n - \dt (\M^{-1})_m^z\RHS_j^m F(\bc^{(j)}) =0 \\
		 &\bc^{(z)} = 
		 \bc^n + \dt a_{z,j} F(\bc^{(j)})   
	\end{align*}
	\begin{itemize}
		\item $a_{mj} = (\M^{-1})_m^z\RHS_j^m$
		\item Prove that  $(\M^{-1})_m^z \bphi^m(t^{n})= 1$ for every $z$
		\item $c^m= \sum_r a_{mr} = t^m$
		\item $b_r = \frac{1}{\dt}\int_{T^m} \phi_r(t)dt =w_r$ quadrature weights
	\end{itemize}
\end{frame}
\begin{frame}{$\L^2$ ADER as RK}
	
\end{frame}
\begin{frame}{$\L^2$ ADER as RK}
	
\end{frame}

\begin{frame}{BCD conditions (Butcher 1964)}
	Define the conditions
\begin{align}
	B(p):\qquad  & \sum_{i=1}^s b_i c_i^{z-1}=\frac1z,\qquad & z=1,\dots,p;\\
	C(\eta):\qquad  & \sum_{j=1}^s a_{ij} c_j^{z-1}=\frac{c_i^z}{z},\qquad & 
	i=1,\dots,s,\,z=1,\dots,\eta;\\
	D(\zeta):\qquad  & \sum_{i=1}^s b_i c_i^{z-1}a_{ij}=\frac{b_j}{z}(1-c_j^z),
	\qquad &j=1,\dots,s,\, z=1,\dots,\zeta. 
\end{align}
\begin{theorem}[Butcher 1964]
	If the coefficients $b_i,c_i,a_{ij}$ of a RK scheme satisfy $B(p)$,
    $C(\eta)$ and $D(\zeta)$ with $p\leq \eta +\zeta +1$ and $p\leq 2\eta +2$, 
	then the method is of order $p$.
\end{theorem}
\end{frame}

\begin{frame}{$C(s-1)$ $D(s-1)$}
	\begin{lemma}
		$\mathcal{L}^2$ operator of ADER defined by Gauss--Lobatto or Gauss--Legendre points and quadrature (they coincide) with $s=M+1$ stages satisfies
		 $C(s-1)$ and $D(s-1)$.
	\end{lemma}
	\begin{block}{Proof (1/4).}
		Interpolation with $\phi^j$ is exact for polynomials
		 of degree $s-1$.\\
		The quadrature is exact for polynomials of degree $2s-3$.\\
		Recall that $\underline{\underline{A}} = \M \RHS$, Condition $C(s-1)$  reads  \vspace*{-2mm}
		\begin{equation*}
			\underline{\underline{A}}\, \underline{c^{z-1}}  = \frac{1}{z}\underline{c^z} 
			\Longleftrightarrow \RHS \, 
			\underline{c^{z-1}}= \frac{1}{z} \M\,\underline{c^z}
			\Longleftrightarrow \underline{\mathcal{X}}:=\RHS \, 
			\underline{c^{z-1}}- \frac{1}{z} \M\,\underline{c^z}=\underline{0}, 
			\qquad z=1,\dots, s-1.\vspace*{-2mm}
		\end{equation*}
		Recall $b_m=t^m$, $c_m=w_m$, $\RHS_{i,j}=\delta_{i,j}w_i$ and the definition of $\M$\vspace*{-2mm}
		\begin{equation*}
			\mathcal{X}_m:=w_m (t^{m})^{z-1} - \frac{1}{z} \left( \phi^m (1) \phi^j (1) (t^j)^z -
			 \int_0^1 \frac{d}{d\xi}\phi^m(\xi) \phi^j(\xi)(t^j)^z  d\xi  \right).
		\end{equation*}
	\end{block}
\end{frame}

\begin{frame}{$C(s-1)$ $D(s-1)$}
	\begin{block}{Proof (2/4).}
		Now, the interpolation of $t^z$ with $z\leq s-1$ with basis functions $\phi^j$ is exact. Hence, we can substitute $\phi^j(\xi)(t^j)^z  = \xi^z$ for all $z=1,\dots, s-1$, obtaining
		\begin{equation*}
			\mathcal{X}_m= w_m (t^{m})^{z-1} - \frac{1}{z} \left( \phi^m (1) 1^z - \int_0^1 \frac{d}{d\xi}\phi^m(\xi)\xi^z  d\xi  \right).
		\end{equation*}
		Using the exactness of the quadrature for polynomials of degree $2s-3$, both true for Gauss--Lobatto and Gauss--Legendre, we know that the previous integral is exactly computed as $\frac{d}{d\xi}\phi^m(\xi)$ is of degree at most $s-2$ and $\xi^z$ is at most $s-1$. So, we can use integration by parts and obtain
		\begin{equation*}
			\mathcal{X}_m= w_m (t^{m})^{z-1} - \frac{1}{z} \left( \phi^m (0) 0^z + \int_0^1 \phi^m(\xi)\frac{d}{d\xi}\xi^z  d\xi  \right) =  w_m (t^{m})^{z-1} - \int_0^1 \phi^m(\xi)\xi^{z-1}  d\xi =0
		\end{equation*}
		by the exactness of the quadrature rule and the definition of $w_m$. Note that the condition is sharp, since the interpolation is not anymore exact for $z=s$, hence $C(s)$ is not satisfied.\\
	\end{block}
\end{frame}

\begin{frame}{$C(s-1)$ $D(s-1)$}
	\begin{block}{Proof (3/4).}
		To prove $D(s-1)$, we write explicitly the condition in matricial form, for all $z=1,\dots, s-1$
			\begin{align*}
				\underline{bc^{z-1}} \, \underline{\underline{A}} = \frac{1}{z} \underline{b(1-c^z)} 
				\Longleftrightarrow \underline{bc^{z-1}} \, \M^{-1} \, \RHS 
				= \frac{1}{z} \underline{b(1-c^z)}
				\Longleftrightarrow \underline{bc^{z-1}}  = \frac{1}{z} \underline{b(1-c^z)}\,
				\RHS^{-1}\, \M.
			\end{align*}
		Note that $b^m=w_m $ and $\RHS_r^m = w_m \delta_r^m$, 
		so $\underline{b(1-c^z)}\,\RHS^{-1}=\underline{(1-c^z)}$. It is left to prove that
		\begin{align*}
		&	\mathcal{Y}:=\underline{bc^{z-1}}-\frac1z\underline{(1-c^z)}\M =\underline{0}.\\
		&	\mathcal{Y}_m= w_m (t^m)^{z-1} - \frac1z\sum_{j=1}^s \left(1-(t^j)^z\right) \left(\phi^j(1)\phi^m(1) - \int_0^1 \frac{d}{d\xi}\phi^j(\xi)\phi^m(\xi) d\xi  \right).
		\end{align*}
			\end{block}
\end{frame}

\begin{frame}{$C(s-1)$ $D(s-1)$}
	\begin{block}{Proof (4/4).}
		Let us observe that, since $z\leq s-1$, the polynomial is exactly represented by the Lagrangian interpolation $t^z = \sum_{j=1}^s \phi(t) (t^m)^z$. Hence, using the exactness of the quadrature for polynomials of degree at most $2s-3$, we have
		 \begin{align*}
			 \mathcal{Y}_m=& w_m (t^m)^{z-1} - \frac1z \left(1-(1)^z\right) \phi^m(1) + \frac1z\int_0^1 \frac{d}{d\xi}\left(1-(\xi)^z\right)\phi^m(\xi) d\xi \\
			 =&  w_m (t^m)^{z-1} -   \frac1z\int_0^1 z\, \xi^{z-1}\phi^m(\xi) d\xi  =w_m (t^m)^{z-1}-w_m (t^m)^{z-1}=0 .
		 \end{align*}
		Hence, ADER-Legendre and ADER-Lobatto satisfy $D(s-1)$. Note that the condition is sharp, since the interpolation is not anymore exact for $z=s$, hence $D(s)$ is not satisfied.
	\end{block}
\end{frame}


\begin{frame}{ADER Gauss--Legendre $\L^2$}
	\begin{remark}[ADER-Legendre is no collocation method]
		From the proof of previous Lemma, we can observe that ADER-Legendre methods do not satisfy $C(s)$, hence, the methods are not collocation methods and they do not coincide with Gauss--Legendre implicit RK methods.
	\end{remark}
	\begin{theorem}
		$\L^2$ of ADER with Gauss--Legendre is of order $2s-1$.
	\end{theorem}
	\begin{proof}
		 ADER-Legendre with $s=M+1$ stages satisfies $B(2s)$ for the quadrature rule and, 
		 hence, it satisfies $B(2s-1)$. For previous Lemma it also satisfies $C(s-1)$ and $D(s-1)$. 
		 Hence, Butcher's (1964) Theorem ($p\leq \eta +\zeta +1$ and $p\leq 2\eta +2$) guarantees that the method is of order $2s-1$, 
		 since it is satisfied with $p=2s-1$ and $\eta=\zeta=s-1$.
	\end{proof}
\end{frame}
	
\begin{frame}{ADER Gauss--Lobatto $\L^2$}
	\begin{theorem}
		$\L^2$ of ADER with Gauss-Lobatto is of order $2s-2$.
	\end{theorem}
	\begin{proof}
		The condition for $B(2s-2)$ is satisfied as $(c,b)$ is the Gauss--Lobatto quadrature 
		with order $2s-2$.
		Previous Lemma  guarantees that ADER-Lobatto satisfies $B(2s-2)$, $C(s-1)$ and $D(s-1)$, 
		so Butcher's (1964) Theorem  ($p\leq \eta +\zeta +1$ and $p\leq 2\eta +2$) is satisfied
		for order $p=2s-2$ and $\eta = \zeta=s-1$.
	\end{proof}	
\end{frame}
\begin{frame}{ADER Gauss--Lobatto $\L^2$}
	\begin{theorem}
		$\L^2$ of ADER with Gauss-Lobatto is LobattoIIIC.
	\end{theorem}

	The Lobatto IIIC method is defined using the condition
	\begin{equation}\label{eq:conditionLobattoIIIC}
		a_{i1}=b_1 \qquad \text{for }i=1,\dots,s.
	\end{equation}


\begin{lemma}\label{lem:conditionLobattoIIIC}
	$\L^2$ of ADER with Gauss-Lobatto satisfies \eqref{eq:conditionLobattoIIIC}.
\end{lemma}
	\begin{theorem}[Chipman 1971]\label{th:uniquenessLobatto}
		Lobatto IIIC schemes (in particular RK $a_{ij}$) are uniquely determined 
		by Gauss--Lobatto quadrature rule $(c,b)$, condition \eqref{eq:conditionLobattoIIIC} 
		and by $C(s-1)$. 
	\end{theorem}
	
\end{frame}

\begin{frame}{ADER Gauss--Lobatto $\L^2$}
	\begin{lemma}\label{lem:conditionLobattoIIIC}
		$\L^2$ of ADER with Gauss-Lobatto satisfies \eqref{eq:conditionLobattoIIIC}.
	\end{lemma}
	\begin{proof}
		\begin{align*}
			a_{i1}=\sum_j (\M^{-1})_{ij}\R_{j1}=&b_1 = w_1 \Longleftrightarrow	\\
			\sum_{i,j}\M_{ki}(\M^{-1})_{ij}\R_{j1}=&\sum_i \M_{ki}w_1 \Longleftrightarrow \\
			\delta_{k1}w_1=\R_{k1}=&\sum_i \M_{ki}w_1\\
			\sum_i \M_{ki}w_1=\phi^m(1) w_1 -  \int_0^1 \frac{d}{dt}\phi^m(\xi)  
			 w_1 dt  &= w_1 \phi^m(0)  = w_1 \delta_{m,1}.
		\end{align*}
	\end{proof}
\end{frame}


\section{Simulations}

\begin{frame}{Applications}
	\begin{minipage}{0.48\textwidth}
		\begin{block}{Usages}
			\begin{itemize}
				\item Hyperbolic PDEs as explicit iterative methods
				 (ADER: Toro, Dumbser, Klingenberg, Boscheri; DeC: Abgrall, Ricchiuto)
				\item IMEX solvers for hyperbolic with stiff sources (ADER: Dumbser, Boscheri; DeC: Abgrall, Torlo)
				\item IMEX solvers for hyperbolic with viscosity (treated implicitly) as compressible Navier Stokes (DeC: Minion, Dumbser, Zeifang)
			\end{itemize}
		\end{block}
		\begin{block}{IMEX}
			$\partial_t u = F(u) + S(u)$ \\ $S(u)$ stiff to be treated implicitly
		\end{block}
	\end{minipage}\hfill
	\begin{minipage}{0.48\textwidth}
		\begin{block}{Advantages}
			\begin{itemize}
				\item Arbitrary high order
				\item Unique framework to have matching between implicit and explicit terms
				\item Easy to code
				\item Iterative solver automatically included
			\end{itemize}
		\end{block}

		\begin{block}{Disadvantages}
			\begin{itemize}
				\item Explicit solver: many many stages
				\item Implicit: many stages
				\item Explicit: not amazing stability property (wrt SSP RK e.g.)
			\end{itemize}
		\end{block}
	\end{minipage}
\end{frame}

\begin{frame}{Convergence}

\begin{figure}
\begin{minipage}[c]{0.55\linewidth}
\begin{equation}
\label{eq:scalar-nonlinear}
\begin{split}
&y'(t) = - |y(t)| y(t) ,\\
&y(0) = 1,\\
&t\in [0,0.1].
\end{split}
\end{equation}
Convergence curves for ADER and DeC, varying the approximation order and collocation of nodes for the subtimesteps for a scalar nonlinear ODE 
\end{minipage}
\hfill
\begin{minipage}[c]{0.4\linewidth}
\includegraphics[width=\linewidth]{scalar-2.png}
\end{minipage}%
\end{figure}


\end{frame}

\begin{frame}{Lotka--Volterra}
%\begin{equation}
%\label{eq:system-nonlinear}
%\begin{split}
%y_1'(t) &= \alpha y_1(t) - \beta y_1(t) y_2(t) \\
%y_2'(t) &= -\gamma y_2(t) + \delta y_1(t) y_2(t)
%\end{split}
%\end{equation}
\begin{figure}
	\begin{columns}
	\column{.6\linewidth}
\includegraphics[width=0.95\linewidth]{n100_ader.png}
\includegraphics[width=0.95\linewidth]{n100_dec.png}
\column{.3\linewidth}
\caption{Numerical solution of the Lotka-Volterra system using ADER (top) and DeC (bottom) with Gauss-Lobatto nodes with timestep $\Delta T = 1$. \label{fig:lodka-sol-dec}}
\end{columns}
\end{figure}

\end{frame}

\begin{frame}{PDE: Burgers with spectral difference}
\begin{figure}
\begin{center}
	\begin{columns}
		\column{0.35\linewidth}
\includegraphics[width=\linewidth,trim={0 55 0 60},clip]{burgers_temp_ader.png}
		\column{0.35\linewidth}
\includegraphics[width=\linewidth,trim={0 55 0 60},clip]{burgers_temp_dec.png}
		\column{0.25\linewidth}
\caption{Convergence error for Burgers equations: Left ADER right DeC. Space discretization with spectral difference}
\label{fig:advection-conv-dec}
	\end{columns}
\end{center}
\end{figure}

\end{frame}


\section{Efficient DeC (ADER)}
\begin{frame}{Reduce computational cost for explicit DeC}
	\begin{block}{Literature}
		\small
		\begin{itemize}
			\item \textit{Micalizzi, L., Torlo, D. A new efficient explicit Deferred Correction framework: analysis and applications to hyperbolic PDEs and adaptivity.}
			\href{https://arxiv.org/abs/2210.02976}{arxiv.org/abs/2210.02976}
			\item \textit{Micalizzi, L., Torlo, D., Boscheri, W. Efficient iterative arbitrary high order methods: an adaptive bridge between low and high order.} \href{https://arxiv.org/abs/2212.07783}{arxiv.org/abs/2212.07783} 
		\end{itemize}
	\end{block}	

	\begin{block}{Goal}
		Reduce computational costs of explicit DeC.
	\end{block}
	
\end{frame}

\begin{frame}{DeC as RK for ODEs}
	\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor1}
		\begin{align*}
			&\L^1(\bbc^{(p)})=\L^1(\bbc^{(p-1)})-\L^2(\bbc^{(p-1)})\text{ with }p=1,\dots,P.\\
			& \bc^{m,(p)} = \bc^{0} + \sum_{r=0}^M \theta^m_r F(t^r,\bc^{r,(p-1)}), \qquad \forall m=1,\dots, M,\; p=1,\dots,P
		\end{align*}
	\end{beamercolorbox}
	\only<2->{
	\begin{minipage}{0.35\textwidth}
	\begin{tikzpicture}[scale=0.8]
			\tikzset{dot/.style={fill=black,circle}}
			
			\foreach\l[count=\y] in {0,1,2,M}
			{
				\draw (1,-\y) -- (3,-\y);
				\draw[dashed] (3,-\y) -- (5,-\y);
				\node at (0.6,-\y){$t^{\l}$};
				\foreach\z[count=\x] in {0,1,2,p,P}
				{
					\only<3->{\ifthenelse{\y=1 \OR \x=1 \AND \NOT \x=\y}{\fill (\x,-\y) circle (1mm) node[anchor=south west] {$\bc^{\l,(\z)}$};}{\fill[red] (\x,-\y) circle (1mm) node[anchor=south west] {$\bc^{\l,(\z)}$};}}
					\only<2>{\fill (\x,-\y) circle (1mm) node[anchor=south west] {$\bc^{\l,(\z)}$};}
				}
			}
			\only<4->{\fill (5,-4) circle (1mm) node[anchor=south west] {$\bc^{M,(P)}$};}
			\foreach\l[count=\x] in {0,1,2,p,P}
			{
				\draw (\x,-1) -- (\x,-3);
				\draw[dashed] (\x,-3) -- (\x,-4);
				\node at (\x,-4.5){$\l$};
			}
			
		\end{tikzpicture}
	\end{minipage}	
	\begin{minipage}{0.63\textwidth}
	%\only<3>{
	%\begin{table}
	%	\centering
	%	\resizebox{\columnwidth}{!}{
	%		\begin{tabular}{|c||ccccccc|l|}
	%			\hline
	%			$\uvec{c}$& $\bu^0$ & $\bbu^{(1)}$& $\bbu^{(2)}$&$\bbu^{(3)}$& $\cdots$& $\bbu^{(M)}$& $\bbu^{(M+1)}_{:M-1}$&A\\
	%			\hline
	%			$0$ & 0 & &&&&&&$\bu^0$\\
	%			$\vecbeta_{1:}$& $\vecbeta_{1:}$ & $\matz$ &&&&&&$\bbu^{(1)}$ \\
	%			$\vecbeta_{1:}$& $\Theta_{1:,0}$ & $(\Theta-\alpha \Gamma)_{1:,1:}$ &$\alpha \Gamma_{1:,1:}$ & $\matz$&&&&$\bbu^{(2)}$\\
	%			$\vecbeta_{1:}$& $\Theta_{1:,0}$&  $\matz$& $(\Theta-\alpha \Gamma)_{1:,1:}$ &$\alpha \Gamma_{1:,1:}$ & $\matz$&&&$\bbu^{(3)}$\\
	%			&$\vdots$   &$\vdots$ &&$\ddots$& $\ddots$&&& $\vdots$\\
	%			&$\vdots$   &$\vdots$ &&&$\ddots$& $\ddots$&& $\vdots$\\
	%			$\vecbeta_{1:M-1}$ &$\Theta_{1:M-1,0}$ &  $\matz$&$\cdots$&$\cdots$&$\matz$&$(\Theta-\alpha \Gamma)_{1:M-1,1:}$&$\alpha \Gamma_{1:M-1,1:M-1}$ &$\bbu^{(M+1)}_{:M-1}$\\ \hline\hline
	%			$\uvec{b}$&$\Theta_{M,0}$ &  $\vecz$&$\cdots$&$\cdots$&$\vecz$&$(\Theta-\alpha \Gamma)_{M,1:}$&$\alpha \Gamma_{M,1:M-1}$ & $\bbu^{M,(M+1)}$\\ \hline
	%	\end{tabular}}
	%	\caption{RK structures for the original $\alpha$DeC with equispaced subtimenodes, $\uvec{c}$ at the left $\uvec{b}$ at the bottom, $A$ in the middle. We add on top and right sides the reference to the iteration steps \label{tab:RKalphaDeC}}
	%\end{table}}
	\visible<4->{
	%	\begin{table}
			\centering
			\resizebox{\columnwidth}{!}{
			\begin{tabular}{|c||ccccccc|l|}
				\hline
				$\uvec{c}$& $\bu^0$ & $\bbu^{(1)}$& $\bbu^{(2)}$&$\bbu^{(3)}$& $\cdots$& $\bbu^{(M-1)}$& $\bbu^{(M)}$&A\\
				\hline
				$0$ & 0 & &&&&&&$\bu^0$\\
				$\vecbeta_{1:}$& $\vecbeta_{1:}$ & $\matz$ &&&&&&$\bbu^{(1)}$ \\
				$\vecbeta_{1:}$& $\Theta_{1:,0}$ & $\Theta_{1:,1:}$ & $\matz$&&&&&$\bbu^{(2)}$\\
				$\vecbeta_{1:}$& $\Theta_{1:,0}$&  $\matz$& $\Theta_{1:,1:}$ & $\matz$&&&&$\bbu^{(3)}$\\
				&$\vdots$   &$\vdots$ &&$\ddots$& $\ddots$&&& $\vdots$\\
				&$\vdots$   &$\vdots$ &&&$\ddots$& $\ddots$&& $\vdots$\\
				$\vecbeta_{1:}$ &$\Theta_{1:,0}$ &  $\matz$&$\cdots$&$\cdots$&$\matz$&$\Theta_{1:,1:}$&$\matz$&$\bbu^{(M)}$\\ \hline\hline
				$\uvec{b}$&$\Theta_{M,0}$ &  $\vecz$&$\cdots$&$\cdots$&$\cdots$&$\vecz$&$\Theta_{M,1:}$&$\bbu^{M,(M+1)}$\\ \hline
			\end{tabular}}
			%\caption{RK structures for the original bDeC with equispaced subtimenodes, $\uvec{c}$ at the left $\uvec{b}$ at the bottom, $A$ in the middle. We add on top and right sides the reference to the iteration steps \label{tab:RKbDeC}}
	%\end{table}
	}
	\end{minipage}}
	
	\end{frame}

	\begin{frame}{Costs}
		\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor1}
			\centering
			\Large \highlightB{Large costs!}
		\end{beamercolorbox}
	\vspace{5mm}\pause
	
	\begin{minipage}{0.4\textwidth}
		\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor1}
		\begin{itemize}
			\item DeC $S= M\cdot (P-1)+1$
			\begin{itemize}
				\item DeC equi $S=(P-1)^2+1$
				\item DeC GLB $S=\left\lceil \frac{P}{2} \right\rceil(P-1)+1$
			\end{itemize}
	%		\item sDeC $S= M\cdot P$ 
	%		\begin{itemize}
	%			\item sDeC equi $S=P^2-P$
	%			\item sDeC GLB $S=\left\lceil \frac{P}{2} \right\rceil \cdot P$
	%		\end{itemize}
		\end{itemize}
	\end{beamercolorbox}
	\end{minipage}
	\begin{minipage}{0.28\textwidth}
		\centering Equispaced
		
		\begin{tabular}{|c|c||c|}\hline
			$P$ &$M$ & DeC\\ \hline
			2&1&2\\
			3&2&5\\
			4&3&10\\
			{\color{red}5}&4&{\color{red}17}\\
			6&5&26\\
			7&6&37\\
			8&7&50\\
			9&8&65\\
			10&9&82\\ \hline
		\end{tabular}
	\end{minipage}
	\begin{minipage}{0.28\textwidth}
		\centering Gauss--Lobatto
		
		\begin{tabular}{|c|c||c|}\hline
			$P$ &$M$ & DeC\\ \hline
			2&1&2\\
			3&2&5\\
			4&2&7\\
			{\color{red}5}&3&{\color{red}13}\\
			6&3&16\\
			7&4&25\\
			8&4&29\\
			9&5&41\\
			10&5&46\\ \hline
		\end{tabular}
	\end{minipage}
	\vspace{5mm}
	\pause
	
	\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor2}
		\centering
		\Large \highlight{How can we save computational time?}
	\end{beamercolorbox}
	\end{frame}
	
	
	%% econ
	\section{An efficient Deferred Correction}
	%main idea plots
	
	\begin{frame}{Idea for reduction of stages}
		\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor2}
		\centering
		\begin{tikzpicture}[scale=1]
			\tikzset{dot/.style={fill=black,circle}}
			\tikzset{straightness/.style={straightness, draw, 
					minimum size=3pt, 
					inner sep=0pt, outer sep=0pt}}
			\tikzset{arrow/.style={
					color=black,
					draw=black,
					-latex,
					font=\fontsize{8}{8}\selectfont}}
			\newcommand{\xa}{1}
			\newcommand{\xb}{2.5}
			\newcommand{\xc}{4}
			\newcommand{\xd}{5.5}
			\newcommand{\xe}{7}
			\newcommand{\xf}{8.5}
			
			\newcommand{\ya}{5}
			\newcommand{\yb}{4}
			\newcommand{\yc}{3}
			\newcommand{\yd}{2}
			\newcommand{\ye}{1}
			
			\newcommand{\yf}{3.666666}
			\newcommand{\yg}{2.333333}
			
			\only<1>{
			\foreach\l[count=\y] in {4,3,2,1,0}
			{
				%\draw (1,\y) -- (8.5,\y);
				\foreach\w/\z[count=\x] in {\xa/0,\xb/1,\xc/2,\xd/3,\xe/4, \xf/5}
				{
					\fill (\w,\y) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
				}
			}
			\draw (1pt+0.3cm,1) -- (-1pt+0.3cm,1) node[anchor=east] {$t_{n+1}=t^{M}=t^4$};
			\draw (1pt+0.3cm,5) -- (-1pt+0.3cm,5) node[anchor=east] {$t_n=t^{0}$};
			\foreach\l[count=\y] in {3,2,1}
			{
				\draw (1pt+0.3cm,\y+1) -- (-1pt+0.3cm,\y+1) node[anchor=east] {$t^{\l}$};
			}
			}
		
			\only<2->{
			\foreach\w/\z[count=\x] in {\xa/0,\xb/1}
			{
				\foreach\l/\r[count=\y] in {0/\ya,1/\ye}
				{
					\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
				}
			}
			
			\foreach\w/\z[count=\x] in {\xc/2}
			{
				\foreach\l/\r[count=\y] in {0/\ya,1/\yc,2/\ye}
				{
					\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
				}
			}
		
			\foreach\w/\z[count=\x] in {\xd/3}
			{
				\foreach\l/\r[count=\y] in {0/\ya,1/\yf,2/\yg,3/\ye}
				{
					\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
				}
			}
		
			\foreach\w/\z[count=\x] in {\xe/4,\xf/5}
			{
				\foreach\l/\r[count=\y] in {0/\ya,1/\yb,2/\yc,3/\yd,4/\ye}
				{
					\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
				}
			}
			\draw (1pt+0.3cm,1) -- (-1pt+0.3cm,1) node[anchor=east] {$t_{n+1}=t^{M}=t^4$};
			\draw (1pt+0.3cm,5) -- (-1pt+0.3cm,5) node[anchor=east] {$t_n=t^{0}$};
			\foreach\l[count=\y] in {3,2,1}
			{
				\draw (1pt+0.3cm,\y+1) -- (-1pt+0.3cm,\y+1) node[anchor=east] {$t^{\l}$};
			}
			}
		
			\draw (0.3,1) -- (0.3,5);
			\node[anchor=center] at (0,0.55) {Iteration};
			\foreach\l/\w[count=\x] in {0/\xa,1/\xb,2/\xc,3/\xd,4/\xe,P=5/\xf}
			{
				\draw (\w,1) -- (\w,5);
				%\draw[dashed] (\w,1) -- (\w,2);
				\node at (\w,0.5){$\l$};
			}
		
			\node[anchor=center] at (0,5.7) {Order};
			\foreach\w/\l[count=\x] in {\xa/1,\xb/2,\xc/3,\xd/4,\xe/5, \xf/6} %,P+1}
			{
				\node[anchor=west] at (\w,5.7) {\small $\!\!O(\dt^{\l})$};
			}
					
			\foreach\w/\l[count=\x] in {\xa/1,\xb/2,\xc/3,\xd/4, \xe/5} 
			{
				\draw[arrow] (\w+0.02,0.8) to  [out=330,in=210] (\w+\xb-\xa -0.02,0.8);
			}
			%\node[anchor=west] at (5,4.7) {\small $\!\!O(\dt^{min{(P+1,M+2)}})$};
			\visible<3>{
				\draw[draw=red] (\xb-0.2,\ye-1) rectangle ++ (3,6);
			}
		\end{tikzpicture}
	\end{beamercolorbox}
	
	\end{frame}
	% u vs du
	\begin{frame}{How to communicate between iterations?}
		\begin{minipage}{0.66\textwidth}
		\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor2}
		\centering
		\begin{tikzpicture}[scale=1]
			\tikzset{dot/.style={fill=black,circle}}
			\tikzset{straightness/.style={straightness, draw, 
					minimum size=3pt, 
					inner sep=0pt, outer sep=0pt}}
			\tikzset{arrow/.style={
					color=black,
					draw=black,
					-latex,
					font=\fontsize{8}{8}\selectfont}}
			\newcommand{\xa}{1}
			\newcommand{\xb}{2.7}
			\newcommand{\xc}{4.4}
			\newcommand{\xd}{6.1}
			\newcommand{\xe}{7.8}
			\newcommand{\xf}{9.5}
			
			\newcommand{\ya}{5}
			\newcommand{\yb}{4}
			\newcommand{\yc}{3}
			\newcommand{\yd}{2}
			\newcommand{\ye}{1}
			
			\newcommand{\yf}{3.666666}
			\newcommand{\yg}{2.333333}
			
			
			\draw (1pt+0.3cm,1) -- (-1pt+0.3cm,1) node[anchor=east] {$t_{n+1}=t^{M}$};
			\draw (1pt+0.3cm,5) -- (-1pt+0.3cm,5) node[anchor=east] {$t_n=t^{0}$};
			
			\only<1>{
				\foreach\l[count=\y] in {4,3,2,1,0}
				{
					%\draw (1,\y) -- (8.5,\y);
					\foreach\w/\z[count=\x] in {\xa/1,\xd/2}
					{
						\fill (\w,\y) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
					}
				}
				\foreach\l[count=\y] in {3,2,1}
				{
					\draw (1pt+0.3cm,\y+1) -- (-1pt+0.3cm,\y+1) node[anchor=east] {$t^{\l}$};
				}
			}
			
			\only<2>{
				
				\draw (\xa,1) -- (\xa,5);
				\draw (\xb,1) -- (\xb,5);
				\draw (\xc,1) -- (\xc,5);
				\draw (\xd,1) -- (\xd,5);
				\foreach\w/\z[count=\x] in {\xa/1}
				{
					\foreach\l/\r[count=\y] in {0/\ya,1/\ye}
					{
						\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
					}
				}
			
				\foreach\w/\z[count=\x] in {\xb/1}
				{
					\foreach\l/\r[count=\y] in {0/\ya,1/\yc,2/\ye}
					{
						\fill (\w,\r) rectangle +(1.5mm,1.5mm) node[anchor=south west] {$\!\bu^{*,\l,(\z)}$};
					}
				}
			
				\foreach\w/\z[count=\x] in {\xc/1}
				{
					\foreach\l/\r[count=\y] in {0/\ya,1/\yc,2/\ye}
					{
						\fill (\w,\r) rectangle +(1.5mm,1.5mm) node[anchor=south west] {$\!\bE^{*,\l,(\z)}$};
					}
				}
				
				\foreach\w/\z[count=\x] in {\xd/2}
				{
					\foreach\l/\r[count=\y] in {0/\ya,1/\yc,2/\ye}
					{
						\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
					}
				}
				
	%			\foreach\w/\z[count=\x] in {\xd/3}
	%			{
	%				\foreach\l/\r[count=\y] in {0/\ya,1/\yf,2/\yg,3/\ye}
	%				{
	%					\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
	%				}
	%			}
	%			
	%			\foreach\w/\z[count=\x] in {\xe/4,\xf/5}
	%			{
	%				\foreach\l/\r[count=\y] in {0/\ya,1/\yb,2/\yc,3/\yd,4/\ye}
	%				{
	%					\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
	%				}
	%			}
				\foreach\l[count=\y] in {3,2,1}
				{
					\draw (1pt+0.3cm,\y+1) -- (-1pt+0.3cm,\y+1) node[anchor=east] {$t^{\l}$};
				}
			}
	
			\only<3->{
		
			\draw (\xa,1) -- (\xa,5);
			\draw (\xb,1) -- (\xb,5);
			\draw (\xc,1) -- (\xc,5);
			\draw (\xd,1) -- (\xd,5);
			\foreach\w/\z[count=\x] in {\xa/1}
			{
				\foreach\l/\r[count=\y] in {0/\ya,1/\ye}
				{
					\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
				}
			}
			
			\foreach\w/\z[count=\x] in {\xb/1}
			{
				\foreach\l/\r[count=\y] in {0/\ya,1/\ye}
				{
					\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bE(\bu^{\l,(\z)})$};
				}
			}
			
			\foreach\w/\z[count=\x] in {\xc/1}
			{
				\foreach\l/\r[count=\y] in {0/\ya,1/\yc,2/\ye}
				{
					\fill (\w,\r) rectangle +(1.5mm,1.5mm) node[anchor=south west] {$\!\bE^{*,\l,(\z)}$};
				}
			}
			
			\foreach\w/\z[count=\x] in {\xd/2}
			{
				\foreach\l/\r[count=\y] in {0/\ya,1/\yc,2/\ye}
				{
					\fill (\w,\r) circle (0.5mm) node[anchor=south west] {$\!\bu^{\l,(\z)}$};
				}
			}
	
			\foreach\l[count=\y] in {3,2,1}
			{
				\draw (1pt+0.3cm,\y+1) -- (-1pt+0.3cm,\y+1) node[anchor=east] {$t^{\l}$};
			}
		}
	
			
			\draw (0.3,1) -- (0.3,5);
			\node[anchor=center] at (0,0.55) {Iteration};
			\foreach\l/\w[count=\x] in {1/\xa,2/\xd}
			{
				\draw (\w,1) -- (\w,5);
				%\draw[dashed] (\w,1) -- (\w,2);
				\node at (\w,0.5){$\l$};
			}
			
			\node[anchor=center] at (0,5.7) {Order};
			\foreach\w/\l[count=\x] in {\xa/2,\xd/3} %,P+1}
			{
				\node[anchor=west] at (\w,5.7) {\small $\!\!O(\dt^{\l})$};
			}
		\only<3->{
			\draw[arrow] (\xa+0.02,0.8) to  [out=330,in=210] (\xb-0.02,0.8) ;
			\node[anchor=center] at (\xa/2+\xb/2, 0.4) {$\bE$};
			\draw[arrow] (\xb+0.02,0.8) to  [out=330,in=210] (\xc-0.02,0.8);
			\node[anchor=center] at (\xc/2+\xb/2, 0.4) {$H^{(p)}$};
			\draw[arrow] (\xc+0.02,0.8) to  [out=330,in=210] (\xd-0.02,0.8);
			\node[anchor=center] at (\xd/2+\xc/2, 0.4) {$\Theta^{(p)}$};
		}
		\only<2>{
			\draw[arrow] (\xa+0.02,0.8) to  [out=330,in=210] (\xb-0.02,0.8) ;
			\node[anchor=center] at (\xa/2+\xb/2, 0.4) {$H^{(p)}$};
			\draw[arrow] (\xb+0.02,0.8) to  [out=330,in=210] (\xc-0.02,0.8);
			\node[anchor=center] at (\xc/2+\xb/2, 0.4) {$\bE$};
			\draw[arrow] (\xc+0.02,0.8) to  [out=330,in=210] (\xd-0.02,0.8);
			\node[anchor=center] at (\xd/2+\xc/2, 0.4) {$\Theta^{(p)}$};
		}
		
		\only<1>{
			\draw[arrow] (\xa+0.02,0.8) to  [out=330,in=210] (\xd-0.02,0.8) ;
			\node[anchor=center] at (\xa/2+\xd/2, 0.3) {$\Theta \bE$};
		}
		
		
		%\node[anchor=west] at (5,4.7) {\small $\!\!O(\dt^{min{(P+1,M+2)}})$};
		\draw[draw=red] (\xa-0.2,\ye-1) rectangle ++ (6.6,6);
	\end{tikzpicture}
	\end{beamercolorbox}
		\end{minipage}\hfill
	\begin{minipage}{0.33\textwidth}
		\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor1}
				\centering
				 \highlightB{DeC}
				\begin{equation*}
						\bbc^{(p)}=\bbc^0+ \dt {\only<4>{\color{red}}\Theta} \bG(\bbc^{(p-1)})
				\end{equation*}
			\visible<2->{		
			\highlightB{DeCu}
			\begin{align*}
				&\bbc^{(p)}=\bbc^0+ \dt \Theta^{(p)} \bG(H^{(p)}\bbc^{(p-1)})\\
				\visible<4->{&\bbc^{*(p)}\!\!=\bbc^0\!+ \!\dt {\only<4>{\color{red}}H^{(p)} \Theta^{*(p-1)}} \bG(\bbc^{*(p-1)})}
		\end{align*}}
	
	\visible<3->{		
		\highlightB{DeCdu}
		\begin{equation*}
			\bbc^{(p)}=\bbc^0+ \dt{\only<4>{\color{red}} \Theta^{(p)} H^{(p)}}\bG(\bbc^{(p-1)})
	\end{equation*}}

	\visible<2->{
		$$H^{(p)}_{ij} = \phi^{(p-1)}_j(t^{i,(p)})$$
	}
		\end{beamercolorbox}
	\end{minipage}
	\end{frame}
	
	% RK
	\begin{frame}{Efficient DeC into RK framework}
		\only<1>{
		\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor1}
			\centering
			\Large \highlightB{DeC} \qquad $S=M\cdot (P-1)+1$
		\end{beamercolorbox}	
	\centering
			\resizebox{0.85\columnwidth}{!}{
		\begin{tabular}{|c||ccccccc|l|r|}
			\hline
			$\uvec{c}$& $\bu^0$ & $\bbu^{(1)}$& $\bbu^{(2)}$&$\bbu^{(3)}$& $\cdots$& $\bbu^{(M-1)}$& $\bbu^{(M)}$&A&dim\\
			\hline
			$0$ & 0 & &&&&&&$\bu^0$&1\\
			$\vecbeta_{1:}$& $\vecbeta_{1:}$ & $\matz$ &&&&&&$\bbu^{(1)}$ &M\\
			$\vecbeta_{1:}$& $\Theta_{1:,0}$ & $\Theta_{1:,1:}$ & $\matz$&&&&&$\bbu^{(2)}$&M\\
			$\vecbeta_{1:}$& $\Theta_{1:,0}$&  $\matz$& $\Theta_{1:,1:}$ & $\matz$&&&&$\bbu^{(3)}$&M\\
			&$\vdots$   &$\vdots$ &&$\ddots$& $\ddots$&&& $\vdots$&M\\
			&$\vdots$   &$\vdots$ &&&$\ddots$& $\ddots$&& $\vdots$&M\\
			$\vecbeta_{1:}$ &$\Theta_{1:,0}$ &  $\matz$&$\cdots$&$\cdots$&$\matz$&$\Theta_{1:,1:}$&$\matz$&$\bbu^{(M)}$&M\\ \hline\hline
			$\uvec{b}$&$\Theta_{M,0}$ &  $\vecz$&$\cdots$&$\cdots$&$\cdots$&$\vecz$&$\Theta_{M,1:}$&$\bbu^{M,(M+1)}$&\\ \hline
	\end{tabular}}
	}
		
		\only<2>{
			\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor1}
				\centering
				\Large \highlightB{DeCu} \qquad $S=M\cdot (P-1)+1\color{red}-\frac{(M-1)(M-2)}{2}$
			\end{beamercolorbox}
	\resizebox{\columnwidth}{!}{
		\begin{tabular}{|c||cccccccc|l||r|}
			\hline
			$\uvec{c}$& $\bu^0$ & $\bbu^{*(1)}$& $\bbu^{*(2)}$&$\bbu^{*(3)}$& $\cdots$& $\bbu^{*(M-2)}$& $\bbu^{*(M-1)}$& $\bbu^{(M)}$&A&dim\\
			\hline
			$0$ & 0 & &&&&&&&$\bu^0$&1\\
			$\vecbeta^{(2)}_{1:}$& $\vecbeta^{(2)}_{1:}$ & $\matz$ &&&&&&&$\bbu^{*(1)}$&2 \\
			$\vecbeta^{(3)}_{1:}$& $W^{(2)}_{1:,0}$ & $W^{(2)}_{1:,1:}$ & $\matz$&&&&&&$\bbu^{*(2)}$&3\\
			$\vecbeta^{(4)}_{1:}$& $W^{(3)}_{1:,0}$&  $\matz$& $W^{(3)}_{1:,1:}$ & $\matz$&&&&&$\bbu^{*(3)}$&4\\
			&$\vdots$   &$\vdots$ &&$\ddots$& $\ddots$&&&& $\vdots$&$\vdots$\\
			&$\vdots$   &$\vdots$ &&&$\ddots$& $\ddots$&&& $\vdots$&$\vdots$\\
			$\vecbeta^{(M)}_{1:}$ &$W^{(M-1)}_{1:,0}$ &  $\matz$&$\cdots$&$\cdots$&$\matz$ &$W^{(M-1)}_{1:,1:}$&$\matz$&$\matz$&$\bbu^{*(M-1)}$&$M$\\
			$\vecbeta^{(M)}_{1:}$&$W^{(M)}_{1:,0}$ &   $\matz$&$\cdots$&$\cdots$&$\cdots$&$\matz$&$W^{(M)}_{1:,1:}$&$\matz$&$\bbu^{(M)}$&$M$\\ \hline\hline
			$\uvec{b}$&$W^{(M+1)}_{M,0}$ &  $\vecz$&$\cdots$&$\cdots$&$\cdots$&$\cdots$&$\vecz$&$W^{(M+1)}_{M,1:}$&$\bbu^{M,(M+1)}$&\\ \hline
	\end{tabular} }	
	\begin{align*}
		W^{(p)} : = \begin{cases}
			H^{(p)}\Theta^{(p)} \in \R^{(p+2)\times(p+1)}, &\text{if } p =2, \dots, M-1,\\
			\Theta^{(M)} \in \R^{(M+1)\times (M+1)}, & \text{if } p \geq M.
		\end{cases}
	\end{align*}
	}
	\only<3>{
		\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor1}
			\centering
			\Large \highlightB{DeCdu} \qquad $S=M\cdot (P-1)+1\color{red}-\frac{M(M-1)}{2}$
		\end{beamercolorbox}
			\resizebox{\columnwidth}{!}{
			\begin{tabular}{|c||cccccccc|l||r|}
				\hline
				$\uvec{c}$& $\bu^0$ & $\bbu^{(1)}$& $\bbu^{(2)}$&$\bbu^{(3)}$& $\cdots$& $\bbu^{(M-2)}$& $\bbu^{(M-1)}$& $\bbu^{(M)}$&A&dim\\
				\hline
				$0$ & 0 & &&&&&&&$\bu^0$&1\\
				$\vecbeta^{(1)}_{1:}$& $\vecbeta^{(1)}_{1:}$ & $\matz$ &&&&&&&$\bbu^{(1)}$&1 \\
				$\vecbeta^{(2)}_{1:}$& $Z^{(2)}_{1:,0}$ & $Z^{(2)}_{1:,1:}$ & $\matz$&&&&&&$\bbu^{(2)}$&2\\
				$\vecbeta^{(3)}_{1:}$& $Z^{(3)}_{1:,0}$&  $\matz$& $Z^{(3)}_{1:,1:}$ & $\matz$&&&&&$\bbu^{(3)}$&3\\
				&$\vdots$   &$\vdots$ &&$\ddots$& $\ddots$&&&& $\vdots$&$\vdots$\\
				&$\vdots$   &$\vdots$ &&&$\ddots$& $\ddots$&&& $\vdots$&$\vdots$\\
				$\vecbeta^{(M-1)}_{1:}$ &$Z^{(M-1)}_{1:,0}$ &  $\matz$&$\cdots$&$\cdots$&$\matz$ &$Z^{(M-1)}_{1:,1:}$&$\matz$&$\matz$&$\bbu^{(M-1)}$&$M-1$\\
				$\vecbeta^{(M)}_{1:}$&$Z^{(M)}_{1:,0}$ &   $\matz$&$\cdots$&$\cdots$&$\cdots$&$\matz$&$Z^{(M)}_{1:,1:}$&$\matz$&$\bbu^{(M)}$&$M$\\ \hline\hline
				$\uvec{b}$&$Z^{(M+1)}_{M,0}$ &  $\vecz$&$\cdots$&$\cdots$&$\cdots$&$\cdots$&$\vecz$&$Z^{(M+1)}_{M,1:}$&$\bbu^{M,(M+1)}$&\\ \hline
		\end{tabular} } 
	\begin{align*}
		Z^{(p)} : = \begin{cases}
			\Theta^{(p)}H^{(p-1)} \in \R^{(p+1)\times p}, &\text{if } p =1, \dots, M,\\
			\Theta^{(M)} \in \R^{(M+1)\times (M+1)}, & \text{if } p >M.
		\end{cases}
	\end{align*}
	}
	\end{frame}
	
	% cost
	\begin{frame}{Computational costs reduction: RK stages}
	%	\begin{minipage}{0.33\textwidth}
	%		\begin{block}{Equispaced}
	%			\centering
	%				\highlightB{DeC }\\
	%				$S=(P-1)^2+1$\\
	%				\highlightB{DeCu }\\
	%				$S=(P-1)^2+1-\frac{(P-2)(P-3)}{2}$\\
	%				\highlightB{DeCdu}\\
	%				 $S=(P-1)^2+1-\frac{(P-1)(P-2)}{2}$
	%		\end{block}
	%	
	%		\begin{block}{Gauss-Lobatto}
	%			\centering
	%			\highlightB{bDeC }\\
	%			$S=\left\lceil\frac{P}{2} \right\rceil (P-1)+1$\\
	%			\highlightB{DeCu }\\
	%			$S=\left\lceil\frac{P}{2} \right\rceil (P-1)+1-\frac{(\left\lceil\frac{P}{2} \right\rceil-1)(\left\lceil\frac{P}{2} \right\rceil-2)}{2}$\\
	%			\highlightB{DeCdu}\\
	%			$S=(P-1)^2+1-\frac{\left\lceil\frac{P}{2} \right\rceil(\left\lceil\frac{P}{2} \right\rceil-1)}{2}$
	%		\end{block}
	%	\end{minipage}
		\begin{minipage}{0.49\textwidth}
			\centering
			\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor1}
				\begin{center}
					\LARGE 
					\highlight{Equispaced}
				\end{center}
			\end{beamercolorbox}
			\resizebox{0.9\columnwidth}{!}{%
			\begin{tabular}{|c|c||c|c|c|}\hline
				P &	M & DeC & DeCu  & DeCdu\\\hline
				2  &     1  &     2 &  2 &   2 \\ 
				3  &     2  &    5 &   5  &    4 \\ 
				4  &     3  &   10 &   9  &    7 \\ 
				{\color{red}5}  &     4  &  {\color{red} 17} &  {\color{red}14}  &   {\color{red}11} \\ 
				6  &     5  &   26 &  20  &   16 \\ 
				7  &     6  &   37 &  27  &   22 \\ 
				8  &     7  &   50 &  35  &   29 \\ 
				9  &     8  &   65 &  44  &   37 \\ 
				10  &     9  &  82 &  54  &   46 \\ 
				11  &    10  &  101 &  65  &  56 \\ 
				12  &    11  &  122 &  77  &  67 \\ 
				13  &    12  &  145 &  90  &  79 \\\hline		
			\end{tabular}
		}
	%		\caption{Number of stages for the original ($\alpha$DeC, DeC) and novel (DeCu, $\alpha$DeCdu, DeCdu) methods with equispaced subtimenodes: for $\alpha$DeC and DeC we have respectively $S=M\cdot P$ and $S=M\cdot (P-1) +1$; for DeCu we have $S=M\cdot (P-1) +1 -\frac{(M-1)(M-2)}{2} $; for $\alpha$DeCdu and DeCdu we have respectively $S=M\cdot P -\frac{M(M-1)}{2} $ and $S=M\cdot (P-1) +1 -\frac{M(M-1)}{2}$. \label{tab:stagesNumbersEquispaced}}
		\end{minipage}	
		\hfill
		\begin{minipage}{0.49\textwidth}
		\centering
	\begin{beamercolorbox}[sep=1em,wd=\textwidth]{blockcolor1}
		\begin{center}
			\LARGE 
			\highlight{Gauss-Lobatto}
		\end{center}
	\end{beamercolorbox}
		\resizebox{0.9\columnwidth}{!}{%
			\begin{tabular}{|c|c||c|c|c|}\hline
				P &	M &  DeC & DeCu &  DeCdu\\\hline
				2  &     1  &    2 &   2  &    2 \\ 
				3  &     2  &    5 &   5  &    4 \\ 
				4  &     2  &    7 &   7  &    6 \\ 
				{\color{red}5}  &     3  &   {\color{red}13} &  {\color{red}12}  &   {\color{red}10 }\\ 
				6  &     3  &   16 &  15  &   13 \\ 
				7  &     4  &   25 &  22  &   19 \\ 
				8  &     4  &   29 &  26  &   23 \\ 
				9  &     5  &   41 &  35  &   31 \\ 
				10  &     5  &   46 &  40  &   36 \\ 
				11  &     6  &   61 &  51  &   46 \\ 
				12  &     6  &   67 &  57  &   52 \\
				13  &     7  &   85 &  70  &   64 \\  \hline		
			\end{tabular}
		}
	\end{minipage}
	%		\caption{Number of stages for the original ($\alpha$DeC, DeC) and novel (DeCu, $\alpha$DeCdu, DeCdu) methods with Gauss-Lobatto subtimenodes: for $\alpha$DeC and DeC we have respectively $S=M\cdot P$ and $S=M\cdot (P-1) +1$; for DeCu we have $S=M\cdot (P-1) +1 -\frac{(M-1)(M-2)}{2} $; for $\alpha$DeCdu and DeCdu we have respectively $S=M\cdot P -\frac{M(M-1)}{2} $ and $S=M\cdot (P-1) +1 -\frac{M(M-1)}{2}$. \label{tab:stagesNumbersGL}}
	%	\end{table}
	\end{frame}
	
	% stability
	\begin{frame}{Stability Properties}
		\begin{minipage}{0.49\textwidth}
		\begin{block}{DeC-DeCu-DeCdu}
			\begin{center}
				The \highlightB{stability function} of DeC, DeCu, DeCdu of order $P$ for any nodes distribution is
				\begin{equation*}
					R(z) = 1 + z + \frac{z^2}{2!} +\dots +\frac{z^P}{P!}.
				\end{equation*}
			\end{center}
		\end{block}
	%\visible<2->{
	%	\begin{block}{DeCu and DeCdu}
	%	\begin{center}
	%		Given a DeC with a certain node distribution, the \highlightB{DeCu and DeCdu} version are \highlightB{equivalent} on \highlightB{linear} problems and have the same stability function and region.
	%	\end{center}
	%\end{block}
	%}
		\end{minipage}\hfill
	\begin{minipage}{0.49\textwidth}
		\centering 
		\only<1>{
		\begin{beamercolorbox}[sep=1mm,wd=\textwidth]{blockcolor1}
			\begin{center}
					\Large \highlight{ DeC, DeCu, DeCdu}
			\end{center}
		\end{beamercolorbox}
		\includegraphics[width=0.75\textwidth]{figures/stability/stability_region_DeC_equispaced.pdf}}
	%\only<2>{	\begin{beamercolorbox}[sep=1mm,wd=\textwidth]{blockcolor1}
	%		\begin{center}
	%			\Large \highlight{ sDeC equispaced}
	%		\end{center}
	%	\end{beamercolorbox}
	%\includegraphics[width=0.75\textwidth]{figures/stability/stability_region_DeC_small_equispaced.pdf}}
	%\only<3>{	\begin{beamercolorbox}[sep=1mm,wd=\textwidth]{blockcolor1}
	%		\begin{center}
	%			\Large \highlight{ sDeCu, sDeCdu equispaced}
	%		\end{center}
	%	\end{beamercolorbox}
	%	\includegraphics[width=0.75\textwidth]{figures/stability/stability_region_DeC_small_stag_equispaced.pdf}}
	%\only<4>{	\begin{beamercolorbox}[sep=1mm,wd=\textwidth]{blockcolor1}
	%	\begin{center}
	%		\Large \highlight{ sDeC Gauss-Lobatto}
	%	\end{center}
	%\end{beamercolorbox}
	%\includegraphics[width=0.75\textwidth]{figures/stability/stability_region_DeC_small_gaussLobatto.pdf}}
	%\only<5>{\begin{beamercolorbox}[sep=1mm,wd=\textwidth]{blockcolor1}
	%	\begin{center}
	%		\Large \highlight{ sDeCu, sDeCdu Gauss-Lobatto}
	%	\end{center}
	%\end{beamercolorbox}
	%\includegraphics[width=0.75\textwidth]{figures/stability/stability_region_DeC_small_stag_gaussLobatto.pdf}}
	\end{minipage}
	\end{frame}

\begin{frame}{Exercise}
	\begin{block}{Efficient DeC}
		\begin{itemize}
			\item Code DeCu or DeCdu
			\item Check order of accuracy
			\item Write a code to obtain its RK matrix
			\item Check the stability function with nodepy
			\item Compare computational costs with original DeC
		\end{itemize}		
	\end{block}
	
\end{frame}

\end{document}




