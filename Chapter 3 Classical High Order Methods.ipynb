{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical High Order Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    " 1. Chapter 3: Classical Methods\n",
    "    1. [Section 1.1: Runge Kutta](#RK)\n",
    "    1. [Section 1.2: Multistep methods](#multistep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading/installing packages\n",
    "\n",
    "# This is the basic package in python with all the numerical functions\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    %pip install numpy\n",
    "    import numpy as np\n",
    "\n",
    "# This package allows to  plot\n",
    "try:\n",
    "    import matplotlib.pyplot as plt \n",
    "except ImportError:\n",
    "    %pip install matplotlib\n",
    "    import matplotlib.pyplot as plt \n",
    "\n",
    "#This package already implemented some functions for Runge Kutta and multistep methods\n",
    "try:\n",
    "    from nodepy import rk\n",
    "except ImportError:\n",
    "    %pip install nodepy\n",
    "    from nodepy import rk\n",
    "#This package contains functions to solve nonlinear problems\n",
    "try:\n",
    "    from scipy import optimize\n",
    "except ImportError:\n",
    "    %pip install scipy\n",
    "    from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download collection of ODE problems\n",
    "try:\n",
    "    from ODEproblems import ODEproblem\n",
    "except ImportError:\n",
    "    ![ -f ODEproblems.py ] || wget https://github.com/accdavlo/HighOrderODESolvers/raw/master/ODEproblems.py -O ODEproblems.py\n",
    "    from ODEproblems import ODEproblem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How to obtain generalizations of the Euler methods?\n",
    "* How can we obtain higher order of accuracy $\\Delta t^p$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Generalization of Euler](https://github.com/accdavlo/HighOrderODESolvers/raw/master/images/chapter2/generalizeEuler.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runge Kutta Methods <a id='RK'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of Runge--Kutta methods is to introduce further stages inside the computation of one step, in order to achieve higher order of accuracy.\n",
    "\n",
    "### $\\theta$ method\n",
    "\n",
    "For example consider the following method:\n",
    "\n",
    "$$\n",
    "y^{*}=y^n +\\theta \\Delta t F(t^n,y^n)\\\\\n",
    "y^{n+1} = y^n +\\Delta t \\left( \\frac{2\\theta-1}{2\\theta}F(t^n,y^n) + \\frac{1}{2\\theta} F(t^n+\\theta\\Delta t,y^*) \\right).\n",
    "$$\n",
    "\n",
    "We introduced 1 extra stage. Do we get an extra order?\n",
    "\n",
    "#### Taylor expansion for local truncation\n",
    "Suppose that $y^n=y(t^n)$, define $t^*=t^n+\\theta \\Delta t$, and suppose that $F$ does not depends explicitly on time,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y(t^{n+1})&=y^n + \\Delta t y'(t^n) + \\frac{\\Delta t^2}{2} y''(t^n) + \\mathcal{O}(\\Delta t^3)\\\\\n",
    "y(t^{*})&=y^n + \\theta\\Delta t y'(t^n) + \\frac{\\theta^2\\Delta t^2}{2} y''(t^n) + \\mathcal{O}(\\Delta t^3)\\\\\n",
    "y^{*} &= y^n + \\theta \\Delta t F(y^n) = y(t^*)+ \\mathcal{O}(\\Delta t^2)\\\\\n",
    "y^{n+1} &= y^n +\\Delta t \\left( \\frac{2\\theta-1}{2\\theta}F(y^n) + \\frac{1}{2\\theta} F(y^*) \\right)\\\\\n",
    "&= y^n +\\Delta t \\left( \\frac{2\\theta-1}{2\\theta}y'(t^n) + \\frac{1}{2\\theta} F(y^n+\\theta \\Delta t y'(t^n)) \\right)\n",
    "\\\\\n",
    "&= y^n +\\Delta t \\left( \\frac{2\\theta-1}{2\\theta}y'(t^n) + \\frac{1}{2\\theta} F(y^n)+\\frac{1}{2\\theta} \\frac{dF}{dy}(y^n)\\theta \\Delta t y'(t^n)  \\right) \\\\\n",
    "&= y^n +\\Delta t \\left( \\frac{2\\theta-1}{2\\theta}y'(t^n) + \\frac{1}{2\\theta} y'(t^n)+\\frac{1}{2\\theta} \\frac{dF}{dt}(y^n)\\theta \\Delta t   \\right) \\\\\n",
    "&= y^n +\\Delta t \\left( y'(t^n)+\\frac{1}{2\\theta} \\frac{d}{dt}(y'(t^n))\\theta \\Delta t   \\right) \\\\\n",
    "&= y^n +\\Delta t \\left( y'(t^n)+\\frac{1}{2} y''(t^n) \\Delta t   \\right) =y(t^{n+1})+\\mathcal{O}(\\Delta t^3).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So, second order in the **global** error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General formulation\n",
    "A general Runge--Kutta method with $S$ stages can be written using a Butcher tableau\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|c}\n",
    "c&A\\\\\n",
    "\\hline\n",
    "& b^T\n",
    "\\end{array}\n",
    "$$\n",
    "where $A\\in \\mathbb R^{S\\times S},\\, b,c\\in\\mathbb R^S$, in the following formulation\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "y^{(k)}=y^n + \\Delta t \\sum_{j=1}^S a_{kj} F(t^n+c_j\\Delta t,y^{(j)}), \\quad k=1,\\dots, S,\\\\\n",
    "y^{n+1} = y^n+ \\Delta t \\sum_{j=1}^S b_{j} F(t^n+c_j\\Delta t,y^{(j)})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "To be an **explicit** scheme $A$ must be a strictly low-triangular matrix, i.e., $a_{ij}=0$ if $j\\geq i$. So they can be written as \n",
    "$$\n",
    "\\begin{cases}\n",
    "y^{(k)}=y^n + \\Delta t \\sum_{j=1}^{k-1} a_{kj} F(t^n+c_j\\Delta t,y^{(j)}), \\quad k=1,\\dots, S,\\\\\n",
    "y^{n+1} = y^n+ \\Delta t \\sum_{j=1}^S b_{j} F(t^n+c_j\\Delta t,y^{(j)})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "#### Example $\\theta$ scheme\n",
    "The $\\theta$ scheme we have seen before can be written as\n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|cc}\n",
    "0\\\\\n",
    "\\theta & \\theta\\\\\n",
    "\\hline\n",
    "& \\frac{2\\theta -1}{2\\theta} &\\frac{1}{2\\theta} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "We see that the scheme is explicit, because there is nothing on the top right of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order of explicit RK schemes\n",
    "How do we know that a RK scheme has a certain order?\n",
    "For $\\theta $ method we have written the Taylor expansion up to the order we were expecting and we matched the coefficients of the exact solution with the one of the approximated solutions at all the steps.\n",
    "\n",
    "If one wants to generalize this conditions using the Taylor expansion, it takes long, but you can get to similar results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Generalization of Euler](https://github.com/accdavlo/HighOrderODESolvers/raw/master/images/chapter2/orderCOnditionRK4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the first condition is for order 1 RK methods,\n",
    "\n",
    "the first 2 conditions are for order 2 RK methods,\n",
    "\n",
    "the first 4 conditions are for order 3 RK methods,\n",
    "\n",
    "all the 8 conditions are for order 4 RK methods.\n",
    "\n",
    "\n",
    "* How can the conditions be computed without doing the Taylor expansions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trees \n",
    "A very smart way of computing all the conditions is given by combinatorial arguments that can be represented as trees. \n",
    "You can find the proof in [Butcher](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119121534)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tree Order](https://github.com/accdavlo/HighOrderODESolvers/raw/master/images/chapter2/treeOrder.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tree is an object with nodes and branches as in figure, with **leaves** on top (nodes without further branches outward going) and a **root** at the bottom (the node with only branches outgoing).\n",
    "\n",
    "The **order** of a tree is the number of nodes in that tree.\n",
    "\n",
    "A RK scheme is of order $p$ if all the trees of order less or equal to $p$ verify certain conditions.\n",
    "\n",
    "All the conditions that must verified are of the type $\\Phi(a_{ij},b_i,c_j)=\\frac{1}{\\gamma}$ polynomial in the coefficients of the Butcher tableau equal to the inverse of an integer. \n",
    "For every tree is very easy to compute such polynomial $\\Phi$ and the integer $\\gamma$.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tree Order](https://github.com/accdavlo/HighOrderODESolvers/raw/master/images/chapter2/treePoly.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For order 4 we have all these trees and conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tree Order](https://github.com/accdavlo/HighOrderODESolvers/raw/master/images/chapter2/treesOrder4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: an explicit RK method with $S$ stages has $\\frac{S^2+3S-2}{2}$ coefficients.\n",
    "\n",
    "| Stages/Order  | Trees | Conditions | Explicit RK coefficient |\n",
    "|---|---|---|---|\n",
    "| 1  | 1  | 1  | 1  |\n",
    "| 2  | 1  | 2  | 4  |\n",
    "| 3  | 2  | 4  | 8  |\n",
    "| 4  | 4  | 8  | 13  |\n",
    "| 5  | 9  | 17  | 19  |\n",
    "| 6  | 20 | 37  | 26  |\n",
    "| 7  | 48 | 85     | 34  |\n",
    "| 8  | 115 | 200   | 43  |\n",
    "| 9  | 286 | 486   | 53  |\n",
    "| 10 | 719 | 1205  | 64  |\n",
    "\n",
    "Moreover, the solution of these conditions should be admissible. For example, there is no 5 stages 5th order explicit RK method, one needs 6 stages. As well, some of the relations may be redundant. Building higher order explicit Runge Kutta method is a challenge.\n",
    "\n",
    "An extract of Butcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Higher Order Butcher](https://github.com/accdavlo/HighOrderODESolvers/raw/master/images/chapter2/orderVsStages.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theorem 324C [Butcher](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119121534)\n",
    "For any positive integer $p$, an explicit RK method exists with order $p$ and $S$ stages, where\n",
    "$$\n",
    "S=\\begin{cases}\n",
    "\\frac{3p^2-10p+24}{8}, \\quad & p \\text{ even,}\\\\\n",
    "\\frac{3p^2-4p+9}{8}, \\quad & p \\text{ odd.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "| Order  | Stages  |\n",
    "|---|---|\n",
    "| 1  | 1  |\n",
    "| 2  | 2  | \n",
    "| 3  | 3  |\n",
    "| 4  | 4  | \n",
    "| 5  | 8  |\n",
    "| 6  | 9  | \n",
    "| 7  | 16 |\n",
    "| 8  | 17 |\n",
    "| 9  | 27 | \n",
    "| 10 | 28 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of explicit RK4\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|cccc}\n",
    "0\\\\\n",
    "\\frac{1}{2} & \\frac{1}{2}\\\\\n",
    "\\frac{1}{2} &0 &\\frac{1}{2} \\\\\n",
    "1& 0& 0& 1\\\\\n",
    "\\hline\n",
    "& \\frac{1}{6} &\\frac{1}{3} &\\frac{1}{3} &\\frac{1}{6} \n",
    "\\end{array} \\qquad  \\begin{array}\n",
    "{c|cccc}\n",
    "0\\\\\n",
    "\\frac{1}{4} & \\frac{1}{4}\\\\\n",
    "\\frac{1}{2} &0 &\\frac{1}{2} \\\\\n",
    "1& 1& -2& 2\\\\\n",
    "\\hline\n",
    "& \\frac{1}{6} &0 &\\frac{2}{3} &\\frac{1}{6} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "An explicit RK5\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|cccccc}\n",
    "0\\\\\n",
    "\\frac{1}{4} & \\frac{1}{4}\\\\\n",
    "\\frac{1}{4} &\\frac{1}{8} &\\frac{1}{8} \\\\\n",
    "\\frac{1}{2}& 0& 0& \\frac{1}{2}\\\\\n",
    "\\frac{3}{4}& \\frac{3}{16}& -\\frac{3}{8}& \\frac{3}{8}&\\frac{9}{16}\\\\\n",
    "1& -\\frac{3}{7}& \\frac{8}{7}& \\frac{6}{7} & -\\frac{12}{7} & \\frac{8}{7}\\\\\n",
    "\\hline\n",
    "& \\frac{7}{90}&0 &\\frac{32}{90} &\\frac{12}{90} &\\frac{32}{90}&\\frac{7}{90} \n",
    "\\end{array} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rk1 = rk.loadRKM('FE') # Forward euler)\n",
    "print(rk1)\n",
    "\n",
    "A=np.array([[0,0],[1/2,0]])\n",
    "b=np.array([0,1])\n",
    "rk2 = rk.ExplicitRungeKuttaMethod(A,b)\n",
    "rk2.name = \"Midpoint\"\n",
    "print(rk2)\n",
    "\n",
    "\n",
    "A=np.array([[0,0,0],[2/3,0,0],[1/3,1/3,0]])\n",
    "b=np.array([1/4,0,3/4])\n",
    "rk3 = rk.ExplicitRungeKuttaMethod(A,b)\n",
    "rk3.name = \"RK3\"\n",
    "\n",
    "print(rk3)\n",
    "\n",
    "\n",
    "rk44=rk.loadRKM('RK44')\n",
    "print(rk44)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Implement an explicit RK method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explicit RK method\n",
    "def explicitRK(flux, tspan, y_0, A, b, c):\n",
    "    # Solving u'=F(u,t)\n",
    "    # input: flux=F, tspan is a vector of times determining the RK steps\n",
    "    # input: y_0 the initial condition\n",
    "    # input: A,b,c are matrix and vectors of RK methods\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)          # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions    \n",
    "    y[:,0]=y_0                 # first timestep \n",
    "    S=np.shape(A)[0]\n",
    "    u=np.zeros((dim,S))       # Internal stages\n",
    "    Fu=np.zeros((dim,S))       # Flux at internal stages\n",
    "    for n in range(N_time-1):    # n=0,..., N-1\n",
    "        delta_t=tspan[n+1]-tspan[n]\n",
    "        for k in range(S):\n",
    "            u[:,k]=y[:,n] \n",
    "            for j in range(k):\n",
    "                u[:,k] =u[:,k]+ FILL WITH THE FORMULA    ## update the value of u^{(k)} adding all the contributions\n",
    "            Fu[:,k] = FILL IN WITH THE FORMULA           ## Compute the flux at the new found value\n",
    "        y[:,n+1]=y[:,n]\n",
    "        for j in range(S):\n",
    "            y[:,n+1]=y[:,n+1]+  FILL IN WITH FORMULA     ## Final update of y^{n+1}\n",
    "    return tspan, y "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the explicit RK method and do an error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=ODEproblem(\"linear_system2\")\n",
    "t_span=np.linspace(0,pr.T_fin,4)\n",
    "rk44=rk.loadRKM('RK44')\n",
    "tt,uu=explicitRK(pr.flux,t_span,pr.u0,rk44.A,rk44.b,rk44.c)\n",
    "plt.plot(tt,uu[0,:])\n",
    "plt.plot(tt,uu[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "# Check the order of accuracy for the rk1,2,3,4 we have defined before\n",
    "def error(tt,yy):\n",
    "    errors=np.zeros(len(tt))\n",
    "    for it, t in enumerate(tt):\n",
    "        errors[it]=np.linalg.norm(yy[:,it]-pr.exact(yy[:,0],t))\n",
    "    return np.mean(errors)\n",
    "\n",
    "Ns=[2**k for k in range(1,10)]\n",
    "solvers=[rk1,rk2,rk3,rk44]\n",
    "\n",
    "errorEx=np.zeros((len(solvers),len(Ns)))\n",
    "dts=    np.zeros(len(Ns))\n",
    "\n",
    "\n",
    "\n",
    "for iN, N in enumerate(Ns):\n",
    "    tspan=np.linspace(0,pr.T_fin,N)\n",
    "    dts[iN]=tspan[1]-tspan[0]\n",
    "    for iS, rk in enumerate(solvers):\n",
    "        tt,yy=explicitRK(pr.flux,tspan,pr.u0,rk.A,rk.b,rk.c)\n",
    "        errorEx[iS,iN]=error(tt,yy)\n",
    "\n",
    "## Plot the error with respect to the timestep dt\n",
    "plt.figure()\n",
    "for iS, rkm in enumerate(solvers):\n",
    "    plt.loglog(FILL IN WITH THE VARIABLES ,label=rk.name)                ## Error of RK\n",
    "    plt.loglog(dts,dts**(rk.order()),\":\", label=\"order %d\"%(rk.order())) ## Reference order\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=ODEproblem(\"nonLinearOscillator\")\n",
    "t_span=np.linspace(0,pr.T_fin,50)\n",
    "rk2=rk.loadRKM('Mid22')\n",
    "tt,uu=explicitRK(pr.flux,t_span,pr.u0,rk2.A,rk2.b,rk2.c)\n",
    "exact_sol = pr.exact_solution_times(pr.u0,tt)\n",
    "\n",
    "plt.plot(tt,uu[0,:])\n",
    "plt.plot(tt,uu[1,:])\n",
    "plt.plot(tt,exact_sol[0,:],\":\")\n",
    "plt.plot(tt,exact_sol[1,:],\":\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see problems of instability!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability\n",
    "As we have seen before for Euler, the stability can be evaluated on Dahlquist's equation\n",
    "\n",
    "$$ y'=qy$$ \n",
    "\n",
    "with $Re(q)\\leq 0$. Considering $z=\\Delta t q$ we want to write the RK methods on this problem as \n",
    "\n",
    "$$\n",
    "y^{n+1}=R(z)y^n\n",
    "$$\n",
    "\n",
    "and find the stability region $\\mathcal S=\\lbrace z\\in \\mathbb C : |R(z)|\\leq 1\\rbrace$.\n",
    "\n",
    "It is actually very simple to write the stability function $R$ for these problems. \n",
    "Let $Y\\in \\mathbb R^S$ be the solution of the RK method at all the stages, namely, it solves\n",
    "\n",
    "$$\n",
    "Y=\\mathbf{1}y^n + \\Delta t q A Y\n",
    "$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\n",
    "(I-zA)Y=\\mathbf{1}y^n \\quad \\Leftrightarrow Y=(I-zA)^{-1}\\mathbf{1} y^n\n",
    "$$\n",
    "\n",
    "with $\\mathbf 1$ the vector of dimension $S$ with all entries equal to 1.\n",
    "\n",
    "Substituting this into the final update, we have\n",
    "\n",
    "$$\n",
    "y^{n+1} = y^n + z b^{T}Y=y^n + z b^T(I-zA)^{-1}\\mathbf{1} y^n = (1+ z b^T(I-zA)^{-1}\\mathbf{1}) y^n$$\n",
    "\n",
    "\n",
    "which gives a way of computing the stability region very efficiently with \n",
    "\n",
    "$$\n",
    "R(z) =1+ z b^T(I-zA)^{-1}\\mathbf{1}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rk1.plot_stability_region(bounds=[-5,1,-5,5])\n",
    "rk2.plot_stability_region(bounds=[-5,1,-5,5])\n",
    "rk3.plot_stability_region(bounds=[-5,1,-5,5])\n",
    "rk44.plot_stability_region(bounds=[-5,1,-5,5]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise:\n",
    "Consider the RK3 method given by \n",
    "$$\n",
    "\\begin{array}\n",
    "{c|ccc}\n",
    "0& &&\\\\\n",
    "\\frac{2}{3}&\\frac{2}{3}&&\\\\\n",
    "\\frac{2}{3}&\\frac{1}{3}&\\frac{1}{3}&\\\\ \\hline\n",
    "&\\frac{1}{4}&&\\frac{3}{4} \n",
    "\\end{array}\n",
    "$$\n",
    "1. Check the order of accuracy of the method.\n",
    "1. Compute the stability function of the method.\n",
    "\n",
    "**Solution:**\n",
    " 1. * Order 1: $\\sum b_i=1$\n",
    "    * Order 2: $\\sum b_i c_i=\\frac14 \\cdot 0 + \\frac34 \\frac23=\\frac12$\n",
    "    * Order 3a: $\\sum b_i c_i^2=\\frac14 \\cdot 0 + \\frac34 \\frac49=\\frac13$\n",
    "    * Order 3b: $\\sum b_i a_{ij} c_j=\\frac14 \\left( \\frac13\\frac23+\\frac23\\frac23\\right) +\\frac34 \\cdot 0 =\\frac16$\n",
    "    * Order4a: $\\sum b_i c_i^3 = \\frac34\\frac{8}{27} = \\frac29 \\neq \\frac14$\n",
    "   Hence order 3.\n",
    " 1. $ R(z) =1+zb^T(I-zA)^{-1} \\underline{1}$ must be computed. To compute $(I-zA)^{-1}$ let us use the fact that $A$ is nilpotent ($A^k=0$ for $k\\geq 3$) and the Taylor expansion of $(I-zA)^{-1}= I +zA+z^2A^2+z^3A^3+\\dots$.\n",
    " $$(I-zA)^{-1}= I +zA+z^2A^2 = \\begin{pmatrix} \n",
    " 1 &0&0\\\\\n",
    " \\frac23z & 1 &0\\\\\n",
    " \\frac{z}{3}+\\frac{2}{9}z^2& \\frac{z}{3} &1 \n",
    " \\end{pmatrix}$$\n",
    " Then\n",
    " $$\n",
    " \\begin{align*}\n",
    "   R(z)& =1+zb^T(I-zA)^{-1} \\underline{1} = 1+z\\begin{pmatrix}\\frac{1}{4}&0&\\frac{3}{4} \\end{pmatrix} \\begin{pmatrix}\n",
    "    1\\\\ 1+\\frac23 z \\\\ 1+\\frac23 z +\\frac29 z^2 \n",
    "   \\end{pmatrix} \\\\\n",
    "   &= 1+z+\\frac{z^2}2+\\frac{z^3}{6}\n",
    " \\end{align*}\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit RK schemes\n",
    "The implicit RK schemes are defined as usual RK schemes and have at least a nonzero element in the upper triangular part of $A$. \n",
    "They have the advantage of requiring **less stages** (with respect to explicit RK) to obtain the order of accuracy required.\n",
    "\n",
    "For example \n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|cc}\n",
    "\\frac{1}{2}-\\frac{\\sqrt{3}}{6} & \\frac{1}{4} &\\frac{1}{4}-\\frac{\\sqrt{3}}{6}\\\\\n",
    "\\frac{1}{2}+\\frac{\\sqrt{3}}{6}  &\\frac{1}{4}+\\frac{\\sqrt{3}}{6} & \\frac{1}{4}\\\\\n",
    "\\hline\n",
    "& \\frac{1}{2} &\\frac{1}{2} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "has order 4. \n",
    "\n",
    "There are clever ways of building implicit RK methods using well known high order accurate quadrature rules.\n",
    "\n",
    "Take a quadrature rule of order $p$ with $S$ quadrature points $c_i \\in [0,1]$, provided with $S$ interpolation polynomials $\\varphi_i$, such that $\\varphi_i(c_j)=\\delta_{i,j}$ and\n",
    "\n",
    "$$\n",
    "y(t) = \\sum_{i=1}^S \\varphi_i(t) y(t^n+c_i\\Delta t) + \\mathcal{O}(\\Delta t^{p+1}), \\qquad \\forall t \\in [t^n,t^{n+1}].\n",
    "$$\n",
    "\n",
    "We can then define the $a_{ij}$ approximating \n",
    "\n",
    "$$\n",
    "y^{(i)}=y^n+\\int_{t^n}^{t^n+c_i\\Delta t} F(t,y(t))dt\\approx y^n+\\sum_{j} \\int_{t^n}^{t^n+c_i\\Delta t} \\varphi_j(t) dt F(t,y^{(j)})  \n",
    "$$\n",
    "\n",
    "so that\n",
    "\n",
    "$$\n",
    "a_{ij}:=\\int_{t^n}^{t^n+c_i\\Delta t} \\varphi_j(t) dt\n",
    "$$\n",
    "\n",
    "and similarly \n",
    "\n",
    "$$\n",
    "b_{j}:=\\int_{t^n}^{t^{n+1}} \\varphi_j(t) dt.\n",
    "$$\n",
    "\n",
    "This guarantees a high order quadrature rule also in the final step, keeping the right accuracy order in every step of the RK method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Gauss--Legendre polynomials one gets $p=2s$, examples\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|c}\n",
    "\\frac{1}{2} & \\frac{1}{2}\\\\\n",
    "\\hline\n",
    "s=1, p=2 & 1 \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|cc}\n",
    "\\frac{1}{2}-\\frac{\\sqrt{3}}{6} & \\frac{1}{4} &\\frac{1}{4}-\\frac{\\sqrt{3}}{6}\\\\\n",
    "\\frac{1}{2}+\\frac{\\sqrt{3}}{6}  &\\frac{1}{4}+\\frac{\\sqrt{3}}{6} & \\frac{1}{4}\\\\\n",
    "\\hline\n",
    "s=2, p=4 & \\frac{1}{2} &\\frac{1}{2} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|ccc}\n",
    "\\frac{1}{2}-\\frac{\\sqrt{15}}{10} & \\frac{5}{36} &\\frac{2}{9}-\\frac{\\sqrt{15}}{15} &\\frac{5}{36} -\\frac{\\sqrt{15}}{30} \\\\\n",
    "\\frac{1}{2} & \\frac{5}{36}+\\frac{\\sqrt{15}}{24}  &\\frac{2}{9}&\\frac{5}{36} -\\frac{\\sqrt{15}}{24} \\\\\n",
    "\\frac{1}{2}+\\frac{\\sqrt{15}}{10}+\\frac{\\sqrt{15}}{30} & \\frac{5}{36} &\\frac{2}{9}+\\frac{\\sqrt{15}}{15} &\\frac{5}{36}  \\\\\n",
    "\\hline\n",
    "s=3, p=6 & \\frac{5}{18} &\\frac{4}{9} &\\frac{5}{18} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Using Gauss--Lobatto or Radau points one decrease the order $p=2s-1$, but increases stability."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order conditions\n",
    "Butcher in 1964 proved that the following conditions are sufficient to obtain order $p$. They can be mostly verified for implicit schemes in easy manners.\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\tB(p):\\qquad  & \\sum_{i=1}^s b_i c_i^{z-1}=\\frac1z,\\qquad & z=1,\\dots,p; \\\\\n",
    "\tC(\\eta):\\qquad  & \\sum_{j=1}^s a_{ij} c_j^{z-1}=\\frac{c_i^z}{z},\\qquad & i=1,\\dots,S,\\,z=1,\\dots,\\eta;\\\\\n",
    "\tD(\\zeta):\\qquad  & \\sum_{i=1}^s b_i c_i^{z-1}a_{ij}=\\frac{b_j}{z}(1-c_j^z),\\qquad &j=1,\\dots,S,\\, z=1,\\dots,\\zeta.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "#### Theorem [Butcher 1964](https://doi.org/10.2307/2003405)\n",
    "If the coefficients $b_i,c_i,a_{ij}$ of a RK scheme satisfy $B(p)$, $C(\\eta)$ and $D(\\zeta)$ with $p\\leq \\eta +\\zeta +1$ and $p\\leq 2\\eta +2$, then the method is of order $p$.\n",
    "\n",
    "*Proof from page 208 of Hairer Solving Differential Equations I*\n",
    "\n",
    "![Proof of Butcher 1964](https://github.com/accdavlo/HighOrderODESolvers/raw/master/images/chapter2/proof_Butcher1964.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability for implicit method\n",
    "Implicit methods are able to deal with stiff problems, hence, other types of stability are more interesting in this situation.\n",
    "\n",
    "##### A-stability \n",
    "A methods is A-stable if $|R(z)|\\leq 1$ whenever $Re(z)\\leq 0$.\n",
    "This property is desirable as it would include the analytical area where the ODE is *stable*. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following methods are A-stable\n",
    "methods = [\"BE\",\"GL3\", \"RadauIIA3\", \"LobattoIIIC3\", \"SDIRK23\",\"SDIRK34\",\"SDIRK54\" ]\n",
    "\n",
    "\n",
    "for method in methods:\n",
    "    rk_method = rk.loadRKM(method)\n",
    "    print(rk_method)\n",
    "    rk_method.plot_stability_region()\n",
    "    print(rk_method.stability_function())\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from RungeKutta import IRK\n",
    "except ImportError:\n",
    "    ![ -f RungeKutta.py ] || wget https://github.com/accdavlo/HighOrderODESolvers/raw/master/RungeKutta.py -O RungeKutta.py\n",
    "    from RungeKutta import IRK \n",
    "\n",
    "k_ode = 2000.\n",
    "rhs= lambda u,t: -k_ode*(u-np.cos(t))\n",
    "jac = lambda u,t: -k_ode*np.eye(len(u))\n",
    "u0=np.array([0.])\n",
    "T_fin=1.5\n",
    "dt = 0.1\n",
    "N_t = int(T_fin/dt)\n",
    "tt = np.linspace(0,T_fin,N_t)\n",
    "\n",
    "methods = [\"FE\",\"BE\"]\n",
    "styles=[\"-\",\"-\",\"--\",\"--\",\"-.\",\"-.\",\":\",\":\"]\n",
    "markers=[\"o\",\"s\",\"x\",\"p\",\"d\",\"1\",\"2\",\"3\",\"+\"]\n",
    "for im,method in enumerate(methods):\n",
    "    rk_method = rk.loadRKM(method)\n",
    "    tt,uu = IRK(rhs, jac, rk_method.A, rk_method.b, tt, u0)\n",
    "    plt.plot(tt,uu[0,:], label=rk_method.name, marker=markers[im], linestyle=styles[im])\n",
    "\n",
    "plt.ylim([-0.5,2])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "methods = [\"LobattoIIIA3\", \"LobattoIIIC3\", \"GL3\", \"RadauIIA3\", \"SDIRK34\", \"SDIRK54\" ]\n",
    "for im,method in enumerate(methods):\n",
    "    rk_method = rk.loadRKM(method)\n",
    "    tt,uu = IRK(rhs, jac, rk_method.A, rk_method.b, tt, u0)\n",
    "    plt.plot(tt,uu[0,:], label=rk_method.name, marker=markers[im], linestyle=styles[im])\n",
    "\n",
    "plt.ylim([-0.5,2])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L-stability\n",
    "A method is L-stable if it is A-stable and $R(\\infty)=0$.\n",
    "\n",
    "This gives better stability conditions in case of stiff problems.\n",
    "\n",
    "RadauIA and RadauIIA and LobattoIIIC implicit RK methods are L-stable, while Gauss--Legendre are only A-stable.\n",
    "\n",
    "Looking at stability functions $R$ we can understand if the method is L-stable.\n",
    "Differently form explicit methods, implicit RK stability functions are ratios of polynomials of degree at most $S$.\n",
    "$$\n",
    "R(z) = \\frac{a_0+a_1z+\\dots a_mz^m}{b_0+b_1z+\\dots+b_nz^n},\n",
    "$$\n",
    "with $a_m\\neq 0 \\neq b_n$. If $m<n$ then the method is L-stable as \n",
    "$$\n",
    "\\lim_{z\\to \\infty} R(z)=0.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Compute the stability function for Crank-Nicolson and check if it is L-stable\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|cc}\n",
    "0& 0&0\\\\\n",
    "1 &\\frac12&\\frac12\\\\ \\hline\n",
    "&\\frac{1}{2}&\\frac{1}{2} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "**Solution**\n",
    "$$\n",
    "(I-zA)^{-1} =\\begin{pmatrix}\n",
    "1&0\\\\ -z/2 &1-z/2\n",
    "\\end{pmatrix}^{-1} = \\frac{2}{2-z} \\begin{pmatrix}\n",
    "1-z/2&0\\\\ z/2 &1\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "1&0\\\\ \\frac{z}{2-z} &\\frac{2}{2-z}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "$$\n",
    "\\begin{align*}\n",
    "R(z) = 1+zb^T (I-zA)^{-1} \\underline{1} =1+z b^T \\begin{pmatrix}\n",
    "1\\\\ \\frac{2+z}{2-z} \n",
    "\\end{pmatrix}= 1+z \\frac{2}{2-z} = \\frac{2+z}{2-z}.\n",
    "\\end{align*}\n",
    "$$\n",
    "Hence,\n",
    "$$\n",
    "\\lim_{z\\to \\infty} R(z) =\\lim_{z\\to \\infty}\\frac{2+z}{2-z} =-1 \\neq 0.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples:**\n",
    "* Implicit Euler\n",
    "$$ R(z)= \\frac{1}{1-z} $$\n",
    "* Gauss-Legendre RK36\n",
    "$$ R(z) = \\frac{z^3/120+ z^2/10+ z/2+ 1}{-z^3/120+ z^2/10- z/2+ 1} $$\n",
    "* Radau IIA3\n",
    "$$ R(z) = \\frac{z^2/20+ 2z/5+ 1}{-z^3/60+ 3z^2/20- 3z/5+ 1} $$\n",
    "* Lobatto IIIA3\n",
    "$$ R(z) = \\frac{z^2/12+ z/2+ 1}{z^2/12- z/2+ 1} $$\n",
    "* Lobatto IIIC3\n",
    "$$ R(z) = \\frac{z/4+ 1}{-z^3/24+z^2/4- 3z/4+ 1} $$\n",
    "* SDIRK54\n",
    "$$ R(z) = \\frac{7z^4/768+ z^3/96 -z^2/8 -z/4 1}{-z^6/1024+ 5z^4/256 -5z^3/32+ 5z^2/8 -5z/4+ 1} $$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocation methods\n",
    "Given some distinct collocation points $\\left\\lbrace c_i \\right\\rbrace_i \\subset [0,1]$ and defining the times $\\tau_i = t^n+c_i \\Delta t$, a collocation method searches for a polynomial $u(t) \\in \\mathbb P_{S}$, such that\n",
    "$$\n",
    "\\begin{cases}\n",
    "u(\\tau_i)' = f(\\tau_i, u(\\tau_i)), \\quad i=1,\\dots, S,\\\\\n",
    "u(t^n)=y^n\n",
    "\\end{cases}\n",
    "$$\n",
    "and the solution at the next timestep is evaluated as $y^{n+1}=u(t^{n+1})$.\n",
    "\n",
    "#### Lemma\n",
    "The collocation methods are (implicit) Runge--Kutta methods with \n",
    "$$\n",
    "\\begin{cases}\n",
    "a_{ij} = \\int_{0}^{c_i} \\ell_j(t) dt, \\quad & i,j=1,\\dots, S\\\\\n",
    "b_j = \\int_{0}^1 \\ell_j(t) dt, \\quad & j=1,\\dots, S\n",
    "\\end{cases}\n",
    "$$\n",
    "where $\\ell_j$ are the Lagrangian basis functions defined by the $c_i$, i.e., \n",
    "$$\n",
    "\\ell_j(t) = \\prod_{k\\neq j} \\frac{t-c_k}{c_j-c_k}. \n",
    "$$\n",
    "##### Proof\n",
    "We know that the polynomial $u' \\in \\mathbb P_{S-1}$ is exactly represented by its Lagrange interpolation\n",
    "$$\n",
    "u'(t^n+z \\Delta t) = \\sum_{j=1}^S \\ell_j(z) u'(\\tau_j).\n",
    "$$\n",
    "For the fundamental theorem of calculus, we have that\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(t^n+z \\Delta t) =& y^n + \\Delta t \\int_{0}^{z} u'(t^n+s \\Delta t) ds \\\\\n",
    "=& y^n +\\Delta t \\int_{0}^{z} \\sum_{j=1}^S \\ell_j(s) ds\\, u'(\\tau_j) \\\\\n",
    "=&   y^n + \\int_{0}^{z} \\sum_{j=1}^S \\ell_j(s) ds\\, f(\\tau_j,u(\\tau_j)).\n",
    "\\end{align*}\n",
    "$$\n",
    "Hence, we can write that\n",
    "$$\n",
    "u^{(k)} = y^n + \\Delta t \\sum_{j=1}^S \\int_0^{c_k} \\ell_j(s) ds\\, f(\\tau_j,u^{(j)}) \n",
    "=y^n + \\Delta t \\sum_{j=1}^S a_{kj} f(\\tau_j,u^{(j)}) \n",
    "$$\n",
    "and\n",
    "$$\n",
    "y^{n+1}=u(t^{n+1})= y^n + \\Delta t \\sum_{j=1}^S \\int_0^{1} \\ell_j(s) ds\\, f(\\tau_j,u^{(j)}) \n",
    "=y^n + \\Delta t \\sum_{j=1}^S b_{j} f(\\tau_j,u^{(j)}).\n",
    "$$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Property $B(p)$ for collocation methods\n",
    "Property $B(p)$ for a collocation method with $S$ stages, means that the underlying quadrature formula is of order $p$.\n",
    "Indeed, $c_i$ could be the quadrature points and $b_i= \\int_0^1 \\ell_j(s) ds $  the quadrature weights of a given quadrature rule $(c_i,b_i)$. Suppose that the quadrature rule is of order $p$, this means that it exactly integrate polynomials of degree at most $p-1$, i.e., for all $z = 1,\\dots, p$\n",
    "$$\n",
    "\\int_0^1 s^{z-1} ds = \\sum_{j} c_j^{z-1} b_j.\n",
    "$$\n",
    "On the other hand,\n",
    "$$\n",
    "\\int_0^1 s^{z-1} ds = \\left[ \\frac{s^z}{z}\\right]_0^1 = \\frac{1}{z}.\n",
    "$$\n",
    "This coincides exactly with condition $B(p)$ for which for all $z=1,\\dots, p$ we have \n",
    "$$\n",
    "\\sum_{j} c_j^{z-1} b_j=\\frac{1}{z}.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Property $C(S)$ for collocation methods\n",
    "An implicit RK method with all different $c_i$ is a collocation method iff it verifies $C(S)$.\n",
    "##### Proof\n",
    "We have seen before that collocation methods are defined by $c_i$ points with \n",
    "$$\n",
    "a_{ij}=\\int_{0}^{c_i} \\ell_j(s)ds.\n",
    "$$\n",
    "Property $C(S)$ states that for every $z\\leq S$\n",
    "$$\n",
    "\\sum_{j} a_{ij} c_j^{z-1} = \\frac{c_i^z}{z}.\n",
    "$$\n",
    "Let us note that the polynomial $s^{z-1}\\in \\mathbb P_{S-1}$ can be exactly represented by the Lagrangian interpolation polynomial $s^{z-1} = \\sum_j \\ell_j(s) c_j^{z-1}$. \n",
    "Hence,\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_{j} a_{ij} c_j^{z-1} = \\sum_{j} \\int_0^{c_i} \\ell_j(s) c_j^{z-1} ds = \\sum_{j} \\int_0^{c_i} s^{z-1} ds = \\left[ \\frac{s^z}{z}\\right]_{0}^{c_i} = \\frac{c_i^z}{z}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "On the other side, the $C(S)$ conditions determines uniquely the $a_{ij}$ given the $c_i$ as for every $i$ \n",
    "$$\n",
    "\\sum_{j=1}^s a_{ij} c_j^{z-1}=\\frac{c_i^z}{z}\n",
    "$$\n",
    "is a linear system for the vector $a_{i,:}$, where the matrix of the system is the Vandermond matrix $c_j^{z-1}$, which is invertible as $c_j$ are distinct. Hence, there is a unique solutions of $a_{ij}$ coefficients."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemma (Wanner,Hairer, Solving Differential Equation II, Lemma 5.4)\n",
    "Consider an S-stage RK with distinct $c_1,\\dots,c_S$ and nonzero weights $b_1, \\dots, b_S$. Then, we have\n",
    "$$\n",
    "C(S) \\text{ and } B(S+\\nu) \\Longrightarrow D(\\nu)\n",
    "$$\n",
    "and \n",
    "$$\n",
    "D(S) \\text{ and } B(S+\\nu) \\Longrightarrow C(\\nu).\n",
    "$$\n",
    "\n",
    "\n",
    "##### Proof (only first)\n",
    "One has to show that \n",
    "$$\n",
    "d_j^{(z)}:= \\sum_{i=1}^S b_i c_i^{z-1}a_{ij} - \\frac{b_j}{z} (1-c_j^z) =0, \\qquad j=1,\\dots, S,\\,z=1,\\dots, \\nu.\n",
    "$$\n",
    "What we can prove is first that \n",
    "$$\n",
    "\\sum_{j=1}^S d_j^{(z)} c_j^{k-1} = 0,\\qquad k=1,\\dots,S, \\, z=1,\\dots,\\nu.\n",
    "$$\n",
    "Indeed,\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_{j=1}^S d_j^{(z)} c_j^{k-1} &= \\sum_{j=1}^S \\sum_{i=1}^S b_i c_i^{z-1}a_{ij} c_j^{k-1} -\\sum_{j=1}^S \\frac{b_j}{z} (1-c_j^z)c_j^{k-1}\\\\\n",
    "&=  \\sum_{i=1}^S  b_i c_i^{z-1}\\sum_{j=1}^Sa_{ij} c_j^{k-1} -\\sum_{j=1}^S \\frac{b_j}{z}c_j^{k-1} + \\sum_{j=1}^S \\frac{b_j}{z}c_j^{z+k-1} \\\\\n",
    "&=  \\frac{1}{k}\\sum_{i=1}^S  b_i c_i^{z+k-1}- \\frac{1}{z}\\sum_{j=1}^S b_j c_j^{k-1} + \\frac{1}{z}\\sum_{j=1}^S b_jc_j^{z+k-1} \\\\\n",
    "&=  \\frac{1}{k}\\frac{1}{z+k} - \\frac{1}{z}\\frac{1}{k} + \\frac{1}{z}\\frac{1}{z+k} \\\\\n",
    "&=  \\frac{z-(k+z) +k}{kz(k+z)}=0.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then, we notice that for all $c_j^{k-1}$ for $j,k=1,\\dots,S$ defines a Vandermond matrix with all distinct points, so it is invertible. Hence, all entries of $d_j^{(z)}$ have to be zero for $j=1,\\dots,S$, $z=1,\\dots,\\nu$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### Gauss Methods\n",
    "Gauss--Legendre quadratures defined by $S$ points $(c_i,b_i)$ are of order $2S$. Hence, $B(2S)$ holds for Gauss methods. As we have seen, all collocation methods verify $C(S)$. Hence, $D(S)$ holds because of the previous theorem with $\\nu=S$.\n",
    "So, applying Butcher 1964, knowing that $B(p)$, $C(\\eta)$ and $D(\\zeta)$  with $p=2S$, $\\eta=\\zeta=S$ hold, we have that $p=2S\\leq \\eta+\\zeta+1=2S+1$ and $p=2S\\leq 2s+2=2S+2$.\n",
    "\n",
    "Recall that Gauss--Legendre are the only quadratures that guarantee order $2S$.\n",
    "This is how one can achieve optimal order for a given number of stages for a RK method.\n",
    "\n",
    "Gauss methods are A stable but not L-stable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* ##### RadauIA and RadauIIA\n",
    "RadauIA points are defined as the zeros of \n",
    "$$\n",
    "\\frac{d^{S-1}}{dx^{S-1}} \\left( x^S (x-1)^{S-1} \\right)\n",
    "$$\n",
    "The RK $a_{ij}$ for RadauIA are defined by $D(S)$ conditions and they are of order $2S-1$, but they are not collocation methods.\n",
    "\n",
    "RadauIIA points are defined as the zeros of \n",
    "$$\n",
    "\\frac{d^{S-1}}{dx^{S-1}} \\left( x^{S-1} (x-1)^{S} \\right).\n",
    "$$\n",
    "and the RK $a_{ij}$ are defined by $C(S)$ and, hence, they are collocation methods of order $2S-1$.\n",
    "\n",
    "Radau methods are L-stable.\n",
    "\n",
    "* ##### LobattoIIIA\n",
    "Lobatto points are defined as the zero of \n",
    "$$\n",
    "\\frac{d^{S-2}}{dx^{S-2}} \\left( x^{S-1} (x-1)^{S-1} \\right).\n",
    "$$\n",
    "This quadrature is the most accurate including the extrema of the interval $c_1=0$ and $c_S=1$.\n",
    "The order of accuracy of Gauss-Lobatto quadrature with $S$ points is $2S-2$.\n",
    "Hence, $B(2S-2)$ and $C(S)$ are verified, which implies that $D(S-2)$. Hence the collocation method with Gauss-Lobatto points, which is called LobattoIIIA.\n",
    "The order of the method is $p=2S-2$ as $p=2S-2\\leq S+S-2+1 = \\eta+\\zeta+1$ and $p=2S-2\\leq 2S+2=2\\eta+2$.\n",
    "\n",
    "LobattoIIIA methods are not L-stable.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc}0&0&0\\\\1&1/2&1/2\\\\\\hline &1/2&1/2\\\\\\end{array}, \\qquad \n",
    "\\begin{array}{c|ccc}0&0&0&0\\\\1/2&5/24&1/3&-1/24\\\\1&1/6&2/3&1/6\\\\\\hline &1/6&2/3&1/6\\\\\\end{array}\n",
    "$$\n",
    "\n",
    "* ##### LobattoIIIB\n",
    "There other variants where $C(S)$ is not satisfied.\n",
    "LobattoIIIB is defined by $D(S)$. It verifies $C(S-2)$. Moreover, $a_{iS}=0$ for all $i=1,\\dots,S.$ The order is $2S-2$.\n",
    "\n",
    "LobattoIIIB methods are not L-stable.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc}0&1/2&0\\\\1&1/2&0\\\\\\hline &1/2&1/2\\\\\\end{array},\\qquad\n",
    "\\begin{array}{c|ccc}0&1/6&-1/6&0\\\\1/2&1/6&1/3&0\\\\1&1/6&5/6&0\\\\\\hline &1/6&2/3&1/6\\\\\\end{array}\n",
    "$$\n",
    "\n",
    "* ##### LobattoIIIC\n",
    "These are defined by $C(S-1)$ (which imposes $S*(S-1)$ conditions) and by $a_{1j}=b_1$ for all $i=1,\\dots, S$. This gives also $D(S-1)$ and order $2S-2$.\n",
    "\n",
    "LobattoIIIC methods are L-stable.\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc}0&1/2&-1/2\\\\1&1/2&1/2\\\\\\hline &1/2&1/2\\\\\\end{array} , \\qquad \n",
    "\\begin{array}{c|ccc}0&1/6&-1/3&1/6\\\\1/2&1/6&5/12&-1/12\\\\1&1/6&2/3&1/6\\\\\\hline &1/6&2/3&1/6\\\\&-{\\frac {1}{2}}&2&-{\\frac {1}{2}}\\\\\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### DIRK \n",
    "    * Issue: general implicit RK increase a lot the complexity of the system. If the ODE has dimension $N_{ODE}$ and the RK has $S$ stages, at each time step we have to solve a (nonlinear) system of $N_{ODE}\\times S$ equations. This increases the complexity of the system!\n",
    "\n",
    "    It would be better to have more systems of dimension $N_{ODE}$ to decrease the complexity. Note: it is faster to solve $S$ systems of dimension $N_{ODE}$ than a system of dimension $S\\times N_{ODE}$ as even the linear solvers requires between $O(N^2)$ and $O(N^3)$.\n",
    "\n",
    "    * Cost of $S$ systems of dimension $N_{ODE}$ = $O(S N_{ODE}^2) \\leftrightarrow O(S N_{ODE}^3)$\n",
    "    * Cost of one system of dimension $S \\times N_{ODE}$ = $O(S^2 N_{ODE}^2)  \\leftrightarrow O(S^3 N_{ODE}^3)$ \n",
    "\n",
    "    * How to have the stability of an implicit method with systems of at most dimension $N_{ODE}$?\n",
    "    [***Diagonally implicit Runge Kutta methods***](https://en.wikipedia.org/wiki/List_of_Runge%E2%80%93Kutta_methods#Diagonally_Implicit_Runge%E2%80%93Kutta_methods)\n",
    "\n",
    "Examples:\n",
    "$$\n",
    "\\begin{array}{c|cc}{\\frac {1}{2}}+{\\frac {\\sqrt {3}}{6}}&{\\frac {1}{2}}+{\\frac {\\sqrt {3}}{6}}&0\\\\{\\frac {1}{2}}-{\\frac {\\sqrt {3}}{6}}&-{\\frac {\\sqrt {3}}{3}}&{\\frac {1}{2}}+{\\frac {\\sqrt {3}}{6}}\\\\\\hline &{\\frac {1}{2}}&{\\frac {1}{2}}\\\\\\end{array}\\qquad \\begin{array}{c|cccc}1/2&1/2&0&0&0\\\\2/3&1/6&1/2&0&0\\\\1/2&-1/2&1/2&1/2&0\\\\1&3/2&-3/2&1/2&1/2\\\\\\hline &3/2&-3/2&1/2&1/2\\\\\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "Code the CrankNicolson method for nonlinear problems\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|cc}\n",
    "0& 0&0\\\\\n",
    "1 &\\frac12&\\frac12\\\\ \\hline\n",
    "&\\frac{1}{2}&\\frac{1}{2} \n",
    "\\end{array}\n",
    "$$\n",
    "* Use the function `root` of `scipy.optimize` to find zeros of nonlinear systems, pass the residual equation AND the jacobian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(optimize.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrankNicolson(func, jac_func, tspan, y_0):\n",
    "    '''\n",
    "    Crank-Nicolson method with a nonlinear solver\n",
    "    Input:\n",
    "    func (nonlinear) function of the ODE, takes input u, t\n",
    "    jac_func jacobian wrt to u of func, takes input u, t\n",
    "    tspan vector of timesteps (t^0,...,t^N)\n",
    "    y_0 initial value    \n",
    "    '''\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)          # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions    \n",
    "    y[:,0]=y_0                 # first timestep \n",
    "    for n in range(N_time-1):    # loop through timesteps n=0,..., N-1\n",
    "        # define the nonlinear function to be solved and its jacobian\n",
    "        res = lambda yn1: INSERT HERE THE RESIDUAL FUNCTION\n",
    "        jacRes = lambda yn1: INSERT HERE THE JACOBIAN OF THE RESIDUAL FUNCTION\n",
    "        z = USE root from optimize TO SOLVE THE NONLINEAR SYSTEM\n",
    "        y[:,n+1] = z.x\n",
    "    return tspan, y "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the CrankNicolson code below with various tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pr=ODEproblem(\"pendulum\")\n",
    "t_span=np.linspace(0,pr.T_fin,30)\n",
    "rk_method=rk.loadRKM('Heun33')\n",
    "tt,uu=explicitRK(pr.flux,t_span,pr.u0,\\\n",
    "    np.float64(rk_method.A),np.float64(rk_method.b),np.float64(rk_method.c))\n",
    "\n",
    "for j in range(uu.shape[0]):\n",
    "    plt.plot(tt,uu[j,:],label=\"Heun\")\n",
    "\n",
    "tt,uu=CrankNicolson(pr.flux,pr.jacobian,t_span,pr.u0)\n",
    "for j in range(uu.shape[0]):\n",
    "    plt.plot(tt,uu[j,:],label=\"CN\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Stiff problem: Robertson\n",
    "pr = ODEproblem(\"Robertson\")\n",
    "\n",
    "Nt=100\n",
    "t_span = np.array([np.exp(k) for k in np.linspace(-14,np.log(pr.T_fin),Nt)])\n",
    "\n",
    "scaling_factors=[1,1e4,1]\n",
    "rk_method=rk.loadRKM('Heun33')\n",
    "tt,uu=explicitRK(pr.flux,t_span,pr.u0,\\\n",
    "    np.float64(rk_method.A),np.float64(rk_method.b),np.float64(rk_method.c))\n",
    "\n",
    "for j in range(uu.shape[0]):\n",
    "    plt.semilogx(tt,uu[j,:]*scaling_factors[j],label=\"Heun\")\n",
    "\n",
    "tt,uu=CrankNicolson(pr.flux,pr.jacobian,t_span,pr.u0)\n",
    "for j in range(uu.shape[0]):\n",
    "    plt.semilogx(tt,uu[j,:]*scaling_factors[j],label=\"CN\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim([-0.15,1.15])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "pr=ODEproblem(\"nonLinearOscillator\")\n",
    "t_span=np.linspace(0,pr.T_fin,50)\n",
    "\n",
    "rk_method=rk.loadRKM('Heun33')\n",
    "tt,uu=explicitRK(pr.flux,t_span,pr.u0,\\\n",
    "    np.float64(rk_method.A),np.float64(rk_method.b),np.float64(rk_method.c))\n",
    "\n",
    "plt.plot(uu[0,:],uu[1,:],\"o\",label=\"Heun\")\n",
    "\n",
    "tt,uu=CrankNicolson(pr.flux,pr.jacobian,t_span,pr.u0)\n",
    "plt.plot(uu[0,:],uu[1,:],\"d\",label=\"CN\")\n",
    "\n",
    "uu_ex = pr.exact_solution_times(pr.u0,tt)\n",
    "plt.plot(uu_ex[0,:],uu_ex[1,:],\"x\",label=\"exact\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim([-1.1,1.1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "pr=ODEproblem(\"nonLinearOscillatorDamped\")\n",
    "t_span=np.linspace(0,pr.T_fin,100)\n",
    "\n",
    "rk_method=rk.loadRKM('Heun33')\n",
    "tt,uu=explicitRK(pr.flux,t_span,pr.u0,\\\n",
    "    np.float64(rk_method.A),np.float64(rk_method.b),np.float64(rk_method.c))\n",
    "\n",
    "plt.plot(uu[0,:],uu[1,:],\"o-\",label=\"Heun\")\n",
    "\n",
    "tt,uu=CrankNicolson(pr.flux,pr.jacobian,t_span,pr.u0)\n",
    "plt.plot(uu[0,:],uu[1,:],\"d-\",label=\"CN\")\n",
    "\n",
    "uu_ex = pr.exact_solution_times(pr.u0,tt)\n",
    "plt.plot(uu_ex[0,:],uu_ex[1,:],\"x:\",label=\"exact\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim([-1.1,1.1])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pr=ODEproblem(\"stiff_scalar\")\n",
    "t_span=np.linspace(0,pr.T_fin,200)\n",
    "\n",
    "rk_method=rk.loadRKM('Heun33')\n",
    "tt,uu=explicitRK(pr.flux,t_span,pr.u0,\\\n",
    "    np.float64(rk_method.A),np.float64(rk_method.b),np.float64(rk_method.c))\n",
    "\n",
    "for j in range(uu.shape[0]):\n",
    "    plt.plot(tt,uu[j,:],label=\"Heun\")\n",
    "\n",
    "tt,uu=CrankNicolson(pr.flux,pr.jacobian,t_span,pr.u0)\n",
    "for j in range(uu.shape[0]):\n",
    "    plt.plot(tt,uu[j,:],label=\"CN\")\n",
    "plt.legend()\n",
    "plt.ylim([-0.5,2])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (pro)**\n",
    "\n",
    "Code an implicit Runge Kutta method.\n",
    "\n",
    "*Be careful with dimensions: the resulting systems is of size $S \\times N$ with $N$ the dimension of the problem.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def implicitRK(func, jac_func, A, b, tspan, y_0):\n",
    "    '''\n",
    "    Implicit RK method with a nonlinear solver\n",
    "    Input:\n",
    "    func (nonlinear) function of the ODE, takes input u, t\n",
    "    jac_func jacobian wrt to u of func, takes input u, t\n",
    "    tspan vector of timesteps (t^0,...,t^N)\n",
    "    y_0 initial value    \n",
    "    '''\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)          # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions   \n",
    "    RKdim = np.shape(A)[0]     # RK dimension \n",
    "    c = np.sum(A,axis=1)       # c RK\n",
    "    y[:,0]=y_0                 # first timestep\n",
    "    un = np.zeros((dim * RKdim)) # vector of previous value for RK\n",
    "    t_loc = np.zeros(RKdim)\n",
    "\n",
    "\n",
    "    for n in range(N_time-1):    # loop through timesteps n=0,..., N-1\n",
    "        dt = tspan[n+1]-tspan[n] #timestep\n",
    "        for i in range(RKdim):  # creating vector dimension dim*NRK with un everywhere\n",
    "            un[i*dim:(i+1)*dim] = y[:,n]\n",
    "            t_loc[i] = tspan[n] + dt*c[i]  # times of stages\n",
    "\n",
    "        def res_RK(u):\n",
    "            \"\"\"residual equation of implicit RK \"\"\"\n",
    "            FILL IN THE DEFINITION\n",
    "            return res\n",
    "        \n",
    "        def jac_res_RK(u):\n",
    "            \"\"\"jacobian of the residual equation\"\"\"\n",
    "            FILL IN THE DEFINITION\n",
    "            return jac\n",
    "\n",
    "        # finding the solution of the residual equation \n",
    "        z = USE ROOT to obtain the solution of the system\n",
    "        \n",
    "        # reconstructing at new timestep\n",
    "        y[:,n+1] = y[:,n]\n",
    "        for i in range(RKdim):\n",
    "            y[:,n+1] = y[:,n+1] + UPDATE THE VALUE OF THE NEXT TIMESTEP\n",
    "    return tspan, y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the implicit RK implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stiff problem: Robertson\n",
    "pr = ODEproblem(\"Robertson\")\n",
    "\n",
    "Nt=50\n",
    "t_span = np.array([np.exp(k) for k in np.linspace(-14,np.log(pr.T_fin),Nt)])\n",
    "\n",
    "scaling_factors=[1,1e4,1]\n",
    "\n",
    "methods = [\"GL2\",\"LobattoIIIA3\",\"LobattoIIIC3\", \"SDIRK54\",\"BE\"]\n",
    "for method in methods:\n",
    "    rk_method=rk.loadRKM(method)\n",
    "    A=rk_method.A\n",
    "    print(rk_method.name) \n",
    "    %time tt,uu=implicitRK(pr.flux,pr.jacobian,rk_method.A,rk_method.b,t_span,pr.u0)\n",
    "    plt.figure()\n",
    "    for j in range(uu.shape[0]):\n",
    "        plt.semilogx(tt,uu[j,:]*scaling_factors[j],label=rk_method.name)\n",
    "\n",
    "    plt.ylim([-0.15,1.15])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rosenbrock Methods\n",
    "* Avoid *exact* solution of nonlinear system\n",
    "* Linearization of the IRK\n",
    "* Connection to DIRK and SDIRK\n",
    "\n",
    "\n",
    "Known with different names (linearly implicit, semi-implicit, semi-explicit, generalized, modified, adaptive, additive Runge-Kutta methods).\n",
    "Simple idea: instead of solving a nonlinear system, let us linearize the problem in the implicit term. Case of autonomous systems $y'=F(y)$. Start from a DIRK\n",
    "$$\n",
    "\\begin{cases}\n",
    "y^{(k)}=y^n + \\Delta t \\sum_{j=1}^i a_{kj} F(y^{(j)}), \\quad k=1,\\dots, S,\\\\\n",
    "y^{n+1} = y^n+ \\Delta t \\sum_{j=1}^S b_{j} F(y^{(j)})\n",
    "\\end{cases}\n",
    "$$\n",
    "or equivalently\n",
    "$$\n",
    "\\begin{cases}\n",
    "G^{(k)}=\\Delta t F(y^n +  \\sum_{j=1}^i a_{kj} G^{(j)}), \\quad k=1,\\dots, S,\\\\\n",
    "y^{n+1} = y^n+  \\sum_{j=1}^S b_{j} G^{(j)}\n",
    "\\end{cases}\n",
    "$$\n",
    "and **linearize** the implicit term, introducing new coefficients for that approximation\n",
    "$$\n",
    "\\begin{cases}\n",
    "G^{(k)}= \\Delta t F(y^n+ \\sum_{j=1}^{k-1} \\alpha_{kj}  G^{(j)})+ \\Delta t \\sum_{j=1}^{k} \\gamma_{kj} J_y F(y^n) G^{(j)} , \\quad k=1,\\dots, S,\\\\\n",
    "y^{n+1} = y^n+ \\sum_{j=1}^S b_{j} G^{(j)}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "To solve each iteration, we need to solve the linear system\n",
    "$$\n",
    "(I-\\Delta t \\gamma_{kk} J_yF(y^n)) G^{(k)}  = \\Delta t F(y^n+ \\sum_{j=1}^{k-1} \\alpha_{kj}  G^{(j)})+ \\Delta t \\sum_{j=1}^{k-1} \\gamma_{kj} J_y F(y^n) G^{(j)}.\n",
    "$$\n",
    "\n",
    "\n",
    "**Advantages**:\n",
    "* No nonlinear systems\n",
    "* Fewer iterations with respect to a Newton method\n",
    "* Smaller linear system (no $A\\otimes J$)\n",
    "* If SDIRK ($\\gamma_ii=\\gamma$), one LU decomposition of $(I-\\Delta t \\gamma_{kk} J_yF(y^n))$ per timestep\n",
    "\n",
    "**Accuracy**: Similar tree-based conditions \n",
    "\n",
    "**Stability**:\n",
    "* Consider the linear Dahlquist equation $y'=\\lambda y$ with $Re(\\lambda)\\leq 0$ and define $z=\\lambda \\Delta t$.\n",
    "Then, the Rosenbrock method reduces to\n",
    "$$\n",
    "\\begin{align*}\n",
    "&G^{(k)}= z y^n +z\\sum_{j=1}^{k} \\underbrace{(\\alpha_{kj}+\\gamma_{kj})}_{a_{kj}} G^{(j)}, \\quad k=1,\\dots, S,\\\\\n",
    "&(I-z A ) \\underline{G} = z \\mathbf{1} y^n\\\\\n",
    "&y^{n+1} = y^n+  b^T \\underline{G} = \\left( 1+ b^T(I-zA)^{-1}\\mathbf{1}\\right) y^n.\n",
    "\\end{align*}\n",
    "$$\n",
    "Exactly the same stability function as a RK method, with $a_{ij}=\\alpha_{ij}+\\gamma_{ij}.$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples**:\n",
    "* RODAS3\n",
    "$$\n",
    "\\alpha = \\begin{pmatrix}\n",
    "0\\\\\n",
    "0&0\\\\\n",
    "1&0&0\\\\\n",
    "\\frac{3}{4} & -\\frac{1}{4}&\\frac{1}{2} &0\n",
    "\\end{pmatrix} \\qquad \n",
    "\\gamma = \\begin{pmatrix}\n",
    "\\frac12\\\\\n",
    "1&\\frac12\\\\\n",
    "-\\frac14&-\\frac14&\\frac12\\\\\n",
    "\\frac1{12}&\\frac1{12}&-\\frac23&\\frac12\n",
    "\\end{pmatrix} \\qquad\n",
    "b= \\begin{pmatrix}\n",
    "\\frac56 & -\\frac16& -\\frac16& \\frac12\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Code a Rosenbrock routine and test it on Robertson problem with RODAS3. Look at the computational times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rosenbrock(func, jac_func, tspan, alpha, gamma, b, y_0):\n",
    "    '''\n",
    "    Rosenbrock method\n",
    "    Input:\n",
    "    func (nonlinear) function of the ODE, takes input u, t\n",
    "    jac_func jacobian wrt to u of func, takes input u, t\n",
    "    tspan vector of timesteps (t^0,...,t^N)\n",
    "    alpha (S x S) matrix\n",
    "    gamma (S x S) matrix\n",
    "    b   S-array\n",
    "    y_0 initial value    \n",
    "    '''\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=len(y_0)       # dimension of the ODE\n",
    "    S = len(b)         # RK stages\n",
    "    G = np.zeros((dim,S))      # rhs of RK\n",
    "    I = np.eye(dim)\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions    \n",
    "    y[:,0]=y_0                 # first timestep \n",
    "    for n in range(N_time-1):    # loop through timesteps n=0,..., N-1\n",
    "        dt = tspan[n+1]-tspan[n]\n",
    "        JJ = jac_func(y[:,n],tspan[n])\n",
    "        for k in range(1,S): # G[:,0] is always zero\n",
    "            M = #MATRIX OF THE SYSTEM\n",
    "            linearized_terms = # LINEARIZED TERMS\n",
    "            nonlinear_terms = # NONLINEAR TERMS\n",
    "            rhs = nonlinear_terms + linearized_terms \n",
    "            G[:,k] = np.linalg.solve(M,rhs)\n",
    "        y[:,n+1] = y[:,n] + sum([b[j]*G[:,j] for j in range(S)])\n",
    "    return tspan, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RODAS3\n",
    "S=4\n",
    "alpha = np.zeros((S,S))\n",
    "alpha[2,0]=1.\n",
    "alpha[3,:]=np.array([3./4.,-1./4.,1./2.,0.])\n",
    "gamma = np.array(\n",
    "    [[1/2,0,0,0],\n",
    "    [1,1/2,0,0],\n",
    "    [-1/4,-1/4,1/2,0],\n",
    "    [1/12,1/12,-2/3,1/2]]\n",
    ")\n",
    "\n",
    "b=np.array([5/6,-1/6,-1/6,1/2])\n",
    "\n",
    "# Stiff problem: Robertson\n",
    "pr = ODEproblem(\"Robertson\")\n",
    "\n",
    "Nt=50\n",
    "t_span = np.array([np.exp(k) for k in np.linspace(-14,np.log(pr.T_fin),Nt)])\n",
    "\n",
    "scaling_factors=[1,1e4,1]\n",
    "\n",
    "\n",
    "%time tt,uu=Rosenbrock(pr.flux,pr.jacobian,t_span,alpha,gamma,b,pr.u0)\n",
    "plt.figure()\n",
    "for j in range(uu.shape[0]):\n",
    "    plt.semilogx(tt,uu[j,:]*scaling_factors[j])\n",
    "\n",
    "plt.ylim([-0.15,1.15])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMEX Runge Kutta methods\n",
    "In many situations it is interesting treating different parts of the ODE with different types of discretizations.\n",
    "\n",
    "#### Examples where explicit schemes fail\n",
    "* Advection-diffusion, advection-dispersion PDEs equations:\n",
    "$$\n",
    "\\begin{align*}\n",
    "&\\partial_t u + \\partial_x F(u) - d \\partial_{xx} u = 0,\\\\\n",
    "&\\partial_t u + \\partial_x F(u) + d \\partial_{xxx} u = 0.\n",
    "\\end{align*}\n",
    "$$\n",
    "For an explicit scheme to be stable for the advection part ($\\partial_x F(u)$) one needs CFL conditions of the type $\\Delta t \\leq C \\Delta x$ which are feasible, usually. \n",
    "For the diffusion term ($-d \\partial_{xx}u$) one needs CFL conditions of the type $\\Delta t \\leq C \\Delta x ^2$ and for the dispersion term ($d \\partial_{xxx} u $) one needs $\\Delta t \\leq C \\Delta x ^3$ which are prohibitive!!\n",
    "* ODEs/PDEs with stiff (linear) terms \n",
    "$$\n",
    "\\begin{align*}\n",
    "&\\partial_t u + F(u) + S(u) = 0,\\\\\n",
    "&\\partial_t u + \\partial_x F(u) + S(u) = 0.\n",
    "\\end{align*}\n",
    "$$\n",
    "Here, $\\partial_u S(u) \\gg 1$. This is more or less the [definition of stiff](https://en.wikipedia.org/wiki/Stiff_equation).\n",
    "   * Kinetic equations, [Boltzmann equations](https://en.wikipedia.org/wiki/Boltzmann_equation)\n",
    "   $$\n",
    "{\\frac {\\partial f}{\\partial t}}+{\\frac {\\mathbf {p} }{m}}\\cdot \\nabla f+\\mathbf {F} \\cdot {\\frac {\\partial f}{\\partial \\mathbf {p} }}=\\nu (f_{0}-f),\n",
    "   $$\n",
    "   with $\\nu \\gg 1.$\n",
    "\n",
    "\n",
    "#### Main idea\n",
    " * Split the PDE into two terms\n",
    " $$\n",
    " \\partial_t u + F(u) + S(u) = 0,\n",
    " $$\n",
    " with $F(u)$ **nonstiff** (non)linear and $S(u)$ **stiff term** (possibly linear).\n",
    " * Treat $F(u)$ explicitly and $S(u)$ implicitly.\n",
    "\n",
    "#### IMEX Euler\n",
    "$$\n",
    "\\frac{u^{n+1}-u^n}{\\Delta t} + F(u^n) + S(u^{n+1})=0. \n",
    "$$\n",
    " * If $S$ is linear $\\Longrightarrow$ little extra computation cost\n",
    " * Gained extra stability, we can run at larger $\\Delta t$ without losing stability, e.g. $\\Delta t \\approx \\Delta x $ for advection-diffusion/dispersion.\n",
    "\n",
    "#### IMEX Runge-Kutta\n",
    "* Some splitting methods of order 1 and 2\n",
    "* [Pareschi-Russo 2000 IMEX Runge--Kutta](https://arxiv.org/abs/1009.2757) generalization of those methods\n",
    "$$\n",
    "\\begin{cases}\n",
    "y^{(k)}=y^n + \\Delta t \\sum_{j=1}^{k-1} \\tilde{a}_{kj} F(t^n+\\tilde{c}_j\\Delta t,y^{(j)}) + \\Delta t \\sum_{j=1}^{S} a_{kj} S(t^n+c_j\\Delta t,y^{(j)}), \\quad k=1,\\dots, S,\\\\\n",
    "y^{n+1} = y^n+ \\Delta t \\sum_{j=1}^S \\tilde{b}_{j} F(t^n+\\tilde{c}_j\\Delta t,y^{(j)}) + \\Delta t \\sum_{j=1}^{S} b_{j} S(t^n+c_j\\Delta t,y^{(j)})\n",
    "\\end{cases}\n",
    "$$\n",
    "* Two Butcher Tableaux\n",
    "$$\\begin{array}\n",
    "{c|c}\n",
    "\\tilde{c}&\\tilde{A}\\\\\n",
    "\\hline\n",
    "& \\tilde{b}^T\n",
    "\\end{array}\n",
    "\\qquad\n",
    "\\begin{array}\n",
    "{c|c}\n",
    "c&A\\\\\n",
    "\\hline\n",
    "& b^T\n",
    "\\end{array}\n",
    "$$\n",
    "#### Order conditions\n",
    "Clearly, the Taylor expansions gets more complicated and there are more conditions on the two Butcher tableaux.\n",
    "* Order 1 \n",
    "$$\n",
    "\\sum_j b_j = 1 \\quad \\sum \\tilde{b}_j = 1\n",
    "$$\n",
    "* Order 2\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_j b_j c_j = \\frac12 \\qquad  \\sum_j \\tilde{b}_j \\tilde{c}_j = \\frac12 \\\\\n",
    "\\sum_j b_j \\tilde{c}_j = \\frac12 \\qquad  \\sum_j \\tilde{b}_j c_j = \\frac12\n",
    "\\end{align*}\n",
    "$$\n",
    "* Order 3\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_{ij} b_i a_{ij} c_j = \\frac16, \\quad \\sum_{i} b_i c_{i}^2  = \\frac13, \\quad\n",
    "\\sum_{ij} \\tilde{b}_i \\tilde{a}_{ij} \\tilde{c}_j = \\frac16, \\quad \\sum_{i} \\tilde{b}_i \\tilde{c}_{i}^2  = \\frac13, \\\\\n",
    "\\sum_{ij} \\tilde{b}_i \\tilde{a}_{ij} c_j = \\frac16, \\quad\n",
    "\\sum_{ij} \\tilde{b}_i a_{ij} \\tilde{c}_j = \\frac16, \\quad\n",
    "\\sum_{ij} {b}_i \\tilde{a}_{ij} \\tilde{c}_j = \\frac16, \\\\\n",
    "\\sum_{ij} \\tilde{b}_i {a}_{ij} {c}_j = \\frac16, \\quad \n",
    "\\sum_{ij} {b}_i \\tilde{a}_{ij} {c}_j = \\frac16, \\quad\n",
    "\\sum_{ij} {b}_i {a}_{ij} \\tilde{c}_j = \\frac16, \\\\\n",
    "\\sum_{i} \\tilde{b}_i \\tilde{c}_{i} c_i  = \\frac13, \\quad\n",
    "\\sum_{i} {b}_i \\tilde{c}_{i} c_i  = \\frac13, \\quad\n",
    "\\sum_{i} \\tilde{b}_i {c}_{i} c_i  = \\frac13, \\quad\n",
    "\\sum_{i} {b}_i \\tilde{c}_{i} \\tilde{c}_i  = \\frac13.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "#### Typical simplifications\n",
    "* $c_i = \\tilde{c}_i$\n",
    "* DIRK instead of fully implicit methods (for computational costs it makes a lot of sense!)\n",
    "\n",
    "#### Some Tableaux\n",
    "* IMEX midpoint\n",
    "$$\\begin{array}\n",
    "{c|cc}\n",
    "0&0 &0\\\\\n",
    "1/2& 1/2 &0\\\\\n",
    "\\hline\n",
    "& 0 & 1\n",
    "\\end{array}\n",
    "\\qquad\n",
    "\\begin{array}\n",
    "{c|cc}\n",
    "0&0 &0\\\\\n",
    "1/2& 0 & 1/2\\\\\n",
    "\\hline\n",
    "& 0 & 1\n",
    "\\end{array}\n",
    "$$\n",
    "* L-stable ARS(2,2,2), $\\gamma = 1-\\frac{\\sqrt{2}}{2},\\quad \\delta = 1-\\frac{1}{2\\gamma}$\n",
    "$$\\begin{array}\n",
    "{c|ccc}\n",
    "0&0 &0&0\\\\\n",
    "\\gamma &\\gamma & 0&0\\\\\n",
    "1 & \\delta &1-\\delta & 0\\\\\n",
    "\\hline\n",
    "& \\delta &1-\\delta & 0\n",
    "\\end{array}\n",
    "\\qquad\n",
    "\\begin{array}\n",
    "{c|ccc}\n",
    "0&0 &0&0\\\\\n",
    "\\gamma & 0& \\gamma &0\\\\\n",
    "1 & 0 & 1-\\gamma & \\gamma \\\\\n",
    "\\hline\n",
    "& 0 & 1-\\gamma & \\gamma\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "#### Stability\n",
    "Studying stability gets more tricky:\n",
    "$$\n",
    "\\partial_t y = \\lambda_1 y +\\lambda_2 y\n",
    "$$\n",
    "where $\\lambda_1 y$ plays the role of the explicit term and $\\lambda_2 y $ is the implicit one.\n",
    "One gets the stability function\n",
    "$$\n",
    "R(z_1,z_2 ) = 1+ (z_1\\tilde{b}^T + z_2 b^T)(I-z_1\\tilde{A}-z_2 A)^{-1}\\underline{1},\n",
    "$$\n",
    "with $z_1 = \\Delta t \\lambda_1$ and $z_2 = \\Delta t \\lambda_2$.\n",
    "This is not easy to visualize as $R:\\mathbb C \\times \\mathbb C  \\to \\mathbb C $.\n",
    "\n",
    "**Techniques**:\n",
    "* Consider $Re(z_1)=0 $ and $Im(z_2)=0$, it can happen for some spatial discretizations of advection--diffusion equations.\n",
    "* Find all $z_2 \\in \\mathbb C$ such that $|R(z_1,z_2)|\\leq 1$ for all $z_1 \\in \\lbrace |1+z_1|\\leq 1 \\rbrace$.\n",
    "* Find all $z_1 \\in \\mathbb C$ such that $|R(z_1,z_2)|\\leq 1$ for all $z_2 \\in \\mathbb C^-$.\n",
    "\n",
    "#### Accuracy wrt stiffness\n",
    "Often the accuracy has been studied for PDEs of the type \n",
    "$$\n",
    "\\partial_t u + F(u) = \\frac{1}{\\varepsilon} S(u) \n",
    "$$\n",
    "for $\\varepsilon \\to 0$.\n",
    "In these cases **order reduction** phenomena might appear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Extra: Test different methods on the following problem for t in [0,10]\n",
    "#  y' = A y + By\n",
    "A = np.array(\\\n",
    "    [[ 0.6, -0.2,  0.8],\\\n",
    "     [ 2.2, -0.4,  2.6],\\\n",
    "     [-0.4, -0.2, -0.2]])\n",
    "B = np.array(\\\n",
    "    [[-60.,  20.,  20.],\\\n",
    "     [ 60., -20., -20.],\\\n",
    "     [ 60., -20., -20.]])\n",
    "y0 = np.array([-1.,  2.,  0.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multistep Methods <a id='multistep'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the cons of RK is the need of computing many evaluations of the flux $F$ at each timestep. This can computationally cost a lot.\n",
    "One can instead exploit the knowledge of the previous states $y^{n-1},y^{n-2},\\dots,y^{n-k}$ to obtain $y^n$. \n",
    "Multistep methods interpolate previous states to extrapolate the new solution. \n",
    "\n",
    "Two types\n",
    "* Adams methods: use the values of $\\lbrace F(t^{n-j},y^{n-j})\\rbrace_{j=1}^k$\n",
    "* General methods: use also the values of $\\lbrace y^{n-j}\\rbrace_{j=1}^k$\n",
    "\n",
    "Example of a general linear multistep method\n",
    "\n",
    "$$\n",
    "y^{n+1}+\\sum_{j=1}^k \\alpha_j y^{n-j+1} = \\Delta t \\sum_{j=0}^k \\beta_j F(t^{n-j+1},y^{n-j+1})\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stability\n",
    "As for RK methods one can wonder whether these schemes are stable. Similarly, we proceed for Dahlquist's equation\n",
    "$$\n",
    "y'=qy,\\qquad q\\in \\mathbb C \\cap \\lbrace Re(q)<0 \\rbrace. \n",
    "$$\n",
    "Since the method is identical at each iteration, we suppose that $y^{n+1}= \\zeta^{n+1} y^0$ and the method will be stable if $|\\zeta|\\leq 1$.\n",
    "\n",
    "Inserting this ansatz into the multistep methods we obtain\n",
    "$$\n",
    "y^{n+1}+\\sum_{j=1}^k \\alpha_j y^{n-j+1} = \\Delta t q \\sum_{j=0}^k \\beta_j  y^{n-j+1}\\\\\n",
    "\\zeta^{k}+\\alpha_1 \\zeta^{k-1}+\\alpha_2 \\zeta^{k-2}+\\dots +\\alpha_k \\zeta^{0} = \\Delta t q (\\beta_0 \\zeta^k + \\beta_1 \\zeta^{k-1} +\\dots + \\beta_k \\zeta^0).\n",
    "$$\n",
    "This is a complex polynomial of degree $k$ in $\\zeta$ which depends on the parameter $\\Delta t q = z \\in \\mathbb C^-$. Let $\\zeta_i\\in \\mathbb C$ for $i=1,\\dots,k$ be the zeros of the previous equation. If $|\\zeta_i|\\leq 1$ for all $i$ and for the multiple zeros $|\\zeta_i|<1$, then the method is stable.\n",
    "\n",
    "Numerically, the task is more challenging than with RK methods. Here, *polynomial roots finding* algorithm are necessary.\n",
    "The **stability area**, i.e., all $z\\in \\mathbb C$ such that all the roots/multiple roots have modulus smaller or equal/smaller than 1.\n",
    "\n",
    "In contrast with RK schemes where a simple function evalution is required, for mutlistep methods this can be quite computationally expensive. \n",
    "\n",
    "* Trick: instead of looking at the map $z \\to \\lbrace \\zeta_i \\rbrace$, one can look for the inverse map $\\zeta\\to z$ given by the same equation\n",
    "$$\n",
    "z= \\frac{\\zeta^{k}+\\alpha_1 \\zeta^{k-1}+\\alpha_2 \\zeta^{k-2}+\\dots +\\alpha_k \\zeta^{0}}{\\beta_0 \\zeta^k + \\beta_1 \\zeta^{k-1} +\\dots + \\beta_k \\zeta^0}.\n",
    "$$\n",
    "\n",
    "Exploring the values of $\\zeta$ inside the unit circle, we find the stable values of $z$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stability of Adams of order 4\n",
    "\n",
    "![Stability of Adam4](https://github.com/accdavlo/HighOrderODESolvers/raw/master/images/chapter2/multistep_stability_adam4.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "**Taylor expansion of the method!**\n",
    "\n",
    "Let us substitute the exact solution into the method, we have a look at the residual after a taylor expansion\n",
    "$$\n",
    "y(t^{n+1})+\\sum_{j=1}^k \\alpha_j y(t^{n-j+1}) - \\Delta t \\sum_{j=0}^k \\beta_j F(t^{n-j+1},y^{n-j+1}) =\\\\ \n",
    "y(t^{n+1})+\\sum_{j=1}^k \\alpha_j y(t^{n-j+1}) - \\Delta t \\sum_{j=0}^k \\beta_j y'(t^{n-j+1})=\\\\\n",
    "y(t^{n+1})+\\sum_{j=1}^k \\alpha_j \\sum_{l=0}^p\\frac{(-j\\Delta t)^l}{l!} y^{(j)}(t^{n+1}) - \\Delta t \\sum_{j=0}^k \\beta_j \\sum_{l=0}^{p-1} \\frac{(-j\\Delta t)^l}{l!}  y^{(l+1)}(t^{n+1}) + O(\\Delta t^{p+1}).\n",
    "$$\n",
    "Let's collect terms with same order\n",
    "$$\n",
    "\\begin{align*}\n",
    "&y(t^{n+1})(1 + \\sum_{j=1}^k \\alpha_j)+\\\\\n",
    "\\Delta t &y'(t^{n+1}) \\left(  \\sum_{j=1}^k \\alpha_j \\frac{-j}{l!} -\\sum_{j=0}^k \\beta_j     \\right)+\\\\\n",
    "&\\dots\\\\\n",
    "\\Delta t^l &y^{(l)}(t^{n+1}) \\left(  \\sum_{j=1}^k \\alpha_j\\frac{(-j)^l}{l!} -\\sum_{j=0}^k \\beta_j  \\frac{(-j)^{l-1}}{(l-1)!}     \\right)+\\\\\n",
    "&\\dots\\\\\n",
    "\\Delta t^p &y^{(p)}(t^{n+1}) \\left(  \\sum_{j=1}^k \\alpha_j\\frac{(-j)^p}{p!} -\\sum_{j=0}^k \\beta_j  \\frac{(-j)^{p-1}}{(p-1)!}     \\right)+ O(\\Delta t^{p+1}).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Hence, the method to be of order $p$ has to verify that $1 + \\sum_{j=1}^k \\alpha_j=0$ and for all $l=1,\\dots,p$\n",
    "$$\n",
    " \\sum_{j=1}^k \\alpha_j\\frac{(-j)^l}{l!} -\\sum_{j=0}^k \\beta_j  \\frac{(-j)^{l-1}}{(l-1)!}  =0.\n",
    "$$\n",
    "\n",
    "* $p+1$ equations for $2k+1$ coefficients, quite a lot of freedom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adams Bashforth methods\n",
    "**Main idea**\n",
    "\n",
    "$$\n",
    "y(t^{n+1})=y(t^{n})+\\int_{t^{n}}^{t^{n+1}} F(t,y(t))dt \\approx y^{n+1} = y^{n}+\\int_{t^{n}}^{t^{n+1}} P_n (t) dt \n",
    "$$\n",
    "\n",
    "In particular, choose $P_n=P_{n,k}$ to be the interpolant polynomial of degree $\\leq k-1$ such that\n",
    "\n",
    "$$\n",
    "P_{n,k}(t^{n-j+1})=F^{n-j+1}:=F(t^{n-j+1},y^{n-j+1}),\\quad j=1,\\dots, k.\n",
    "$$\n",
    "\n",
    "Using Lagrange interpolation polynomials, we can write\n",
    "\n",
    "$$\n",
    "P_{n,k}(t):=\\sum_{j=1}^k F^{n-j+1} L_{n,j,k}(t), \\quad \\text{with } L_{n,j,k}(t)=\\prod_{i=1,i\\neq j}^{k} \\frac{ t-t^{n+1-i}}{t^{n+1-j}-t^{n+1-i}}\n",
    "$$\n",
    "\n",
    "Defining\n",
    "\n",
    "$$\n",
    "b_{n,j,k}:=\\frac{1}{t^{n+1}-t^{n}} \\int_{t^{n}}^{t^{n+1}} L_{n,j,k}(t) dt, \\quad j=1,\\dots,k\n",
    "$$\n",
    "\n",
    "the method reads\n",
    "\n",
    "$$\n",
    "y^{n+1}:=y^n + \\Delta t \\sum_{j=1}^k b_{n,j,k} F^{n-j+1}, \\quad \\text{for } n\\geq k\\\\\n",
    "F^{n+1}:=F(t^{n+1},y^{n+1}).\n",
    "$$\n",
    "\n",
    "* Explicit method\n",
    "* $k=0$ Explicit Euler\n",
    "* Error at each step (we can aim to) $\\mathcal O (\\Delta t^{k+1})$, global error is $\\mathcal O (\\Delta t^{k})$\n",
    "\n",
    "#### Starting values\n",
    "Starting with the initial value problem, to compute $y^1$ we do not know $y^{-1}, \\dots, y^{-k+1}$. One can proceed in different ways in this case.\n",
    "* Start with $k$ steps of RK methods\n",
    "* Start with an exact solution (if available)\n",
    "* Change $k$ along the method (order of accuracy could be lost -> Change the step size)\n",
    "* Few implicit steps and then explicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adams Bashforth parameters\n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|cccc}\n",
    "k & b_{n,1,k} & b_{n,2,k} & b_{n,3,k}  & b_{n,4,k} &b_{n,5,k}\\\\\n",
    "\\hline\n",
    "1& 1\\\\\n",
    "2& \\frac{3}{2} & -\\frac{1}{2}\\\\\n",
    "3& \\frac{23}{12} & -\\frac{4}{3} & \\frac{5}{12} \\\\\n",
    "4& \\frac{55}{24}& -\\frac{59}{24} & \\frac{37}{24} &-\\frac{3}{8} \\\\\n",
    "5& \\frac{1901}{720}& -\\frac{1387}{360} & \\frac{109}{30} &-\\frac{637}{360} & \\frac{251}{720} \n",
    "\\end{array} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be carefull with notation\n",
    "import nodepy.linear_multistep_method as lm\n",
    "for order in range(2,10):\n",
    "    print(\"Adam Bashforth Order %d\"%(order))\n",
    "    AB=lm.Adams_Bashforth(order)\n",
    "    plt.figure()\n",
    "    AB.plot_stability_region()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adams Moulton methods (implicit)\n",
    "\n",
    "In particular, choose $P_n=P_{n,k}$ to be the interpolant polynomial of degree $\\leq k$ such that\n",
    "\n",
    "$$\n",
    "P_{n,k}(t^{n-j})=F^{n-k}:=F(t^{n-j},y^{n-j}),\\quad j=0,\\dots, k.\n",
    "$$\n",
    "\n",
    "Using Lagrange interpolation polynomials, we can write\n",
    "\n",
    "$$\n",
    "P_{n,k}(t):=\\sum_{j=0}^k F^{n-j+1} L_{n,j,k}(t), \\quad \\text{with } L_{n,j,k}(t)=\\prod_{i=0,i\\neq j}^{k} \\frac{ t-t^{n-i+1}}{t^{n-j+1}-t^{n-i+1}}\n",
    "$$\n",
    "\n",
    "Defining\n",
    "\n",
    "$$\n",
    "b_{n,j,k}:=\\frac{1}{t^{n+1}-t^{n}} \\int_{t^{n}}^{t^{n+1}} L_{n,j,k}(t) dt, \\quad j=0,\\dots,k\n",
    "$$\n",
    "\n",
    "the method reads\n",
    "\n",
    "$$\n",
    "y^{n+1}:=y^n + \\Delta t \\sum_{j=0}^k b_{n,j,k} F^{n-j+1}, \\quad \\text{for } n\\geq k\\\\\n",
    "F^{n+1}=F(t^{n+1},y^{n+1}),\n",
    "$$\n",
    "\n",
    "i.e., at each step we have to solve\n",
    "\n",
    "$$\n",
    "y^{n+1}-\\Delta t b_{n,0,k} F(t^{n+1},y^{n+1}):=y^n + \\Delta t \\sum_{j=1}^k b_{n,j,k} F^{n-j+1}, \\quad \\text{for } n\\geq k\\\\\n",
    "$$\n",
    "\n",
    "Unique solution if $\\Delta t b_{n,0,k} L< 1$ ($L$ Lipschitz continuity constant of $F$), solution can be obtained with the fixed point iteration method.\n",
    "\n",
    "* Implicit method\n",
    "* $k=0$ Implicit Euler\n",
    "* Error at each step $\\mathcal O (\\Delta t^{k+2})$, global error is $\\mathcal O (\\Delta t^{k+1})$\n",
    "* Same problems with starting values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adams Moulton parameters\n",
    "\n",
    "$$\n",
    "\\begin{array}\n",
    "{c|ccccc|c}\n",
    "k & b_{n,0,k} & b_{n,1,k} & b_{n,2,k} & b_{n,3,k}  & b_{n,4,k} & Notes\\\\\n",
    "\\hline\n",
    "0& 1 &&&&& \\text{Implicit Euler}\\\\\n",
    "1& \\frac{1}{2} & \\frac{1}{2} &&&&\\text{ Crank-Nicolson}\\\\\n",
    "2& \\frac{5}{12} & \\frac{2}{3} & -\\frac{1}{12}  \\\\\n",
    "3& \\frac{3}{8}& \\frac{19}{24} & -\\frac{5}{24} & \\frac{1}{24} \\\\\n",
    "4& \\frac{251}{720}& \\frac{323}{360} & -\\frac{11}{30} & \\frac{53}{360} & -\\frac{19}{720} \n",
    "\\end{array} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be carefull with notation\n",
    "import nodepy.linear_multistep_method as lm\n",
    "for order in range(2,10):\n",
    "    print(\"Adam Moulton Order %d\"%(order))\n",
    "    AM =lm.Adams_Moulton(order-1)\n",
    "    plt.figure()\n",
    "    AM.plot_stability_region()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, except for order 1 and 2 (implicit Euler and Crank-Nicolson), the methods are not A-stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to render Adams Moulton explicit?\n",
    "\n",
    "Use Adams Bashforth (AB) to compute $y^{n+1,*}$, then update the value with Adams Moulton (AM) formula, where the obtained value can be substituted into $F(t^{n+1},y^{n+1,*})$. In particular, we use a $k^*$ for Adam Bashforth that is equal to $k$ of AM, this means that we use during AB one extra value of $F$ with respect to the ones we use in AM."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BDF (first implicit schemes by Curtiss, Hirschfelder in 1952)\n",
    "Backward difference are *the opposite* of Adams method. \n",
    "$$\n",
    "y^{n+1}+\\sum_{j=1}^k \\alpha_j y^{n-j+1} = \\Delta t \\beta_0 F(t^{n+1},y^{n+1})\n",
    "$$\n",
    "\n",
    "* Pro: most efficient implicit multistep methods\n",
    "* Cons: stable only up to order 6\n",
    "\n",
    "The relation on the order of accuracy gives the following system\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\sum_{j=1}^k \\alpha_j = -1\\\\\n",
    "\\sum_{j=1}^k j \\alpha_j = -\\beta_0\\\\\n",
    " \\sum_{j=1}^k \\alpha_j\\frac{(-j)^l}{l!} =0\\qquad l=2,\\dots,p.\n",
    " \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be carefull with notation\n",
    "import nodepy.linear_multistep_method as lm\n",
    "for order in range(2,10):\n",
    "    print(\"BDF Order %d\"%(order))\n",
    "    BDF=lm.backward_difference_formula(order)\n",
    "    plt.figure()\n",
    "    BDF.plot_stability_region()\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theorem (Dahlquist 1963)\n",
    "An A-stable multistep method must be of order $p\\leq 2.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the Adams Bashforth method\n",
    "\n",
    "Pass in input the coefficients $b_j$ of the scheme and the initial $k$ values needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise\n",
    "## explicit Adams Bashforth method\n",
    "def multiAB(flux, tspan, y_0, b):\n",
    "    # Solving u'=F(u,t)\n",
    "    # input: flux=F, tspan is a vector of times determining the RK steps\n",
    "    # input: y_0 the initial condition with the first k values of the solution\n",
    "    # input: b are k+1 b_j coefficients where the last one is 0\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=y_0.shape[0]          # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions\n",
    "    k = len(b)-1                # size of AB\n",
    "    if y_0.shape[1] < k:\n",
    "        raise ValueError(\"Input vector is too small\")\n",
    "    y[:,:k]=y_0                  # first timesteps \n",
    "    n0=k-1                       # last index assigned\n",
    "    Fu=np.zeros((dim,k))         # Flux at internal stages\n",
    "    for j in range(k):\n",
    "        Fu[:,j]=flux(y[:,j])\n",
    "    for n in range(n0,N_time-1):    # n=0,..., N-1\n",
    "        delta_t=tspan[n+1]-tspan[n]\n",
    "        y[:,n+1]=y[:,n]\n",
    "        for j in range(k):\n",
    "            y[:,n+1]=y[:,n+1]+ FILL IN       ## Update values\n",
    "        Fu[:,:k-1] = Fu[:,1:]                # Shift of fluxes (I don't need anymore the first one)\n",
    "        Fu[:,k-1] = flux(y[:,n+1])           # Compute the new flux\n",
    "    return tspan, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the Adams Bashforth method\n",
    "order = 2\n",
    "N=100 #5\n",
    "AB=lm.Adams_Bashforth(order)\n",
    "pr=ODEproblem(\"linear_system2\")\n",
    "t_span=np.linspace(0,pr.T_fin,N)\n",
    "y_0 = np.zeros((len(pr.u0),order))\n",
    "for j in range(order):\n",
    "    y_0[:,j] = pr.exact(pr.u0,t_span[j])\n",
    "    \n",
    "tt,uu=multiAB(pr.flux,t_span,y_0,AB.beta)\n",
    "plt.plot(tt,uu[0,:])\n",
    "plt.plot(tt,uu[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## TEST CONVERGENCE! \n",
    "pr=ODEproblem(\"linear_system2\")\n",
    "def error(tt,yy):\n",
    "    errors=np.zeros(len(tt))\n",
    "    for it, t in enumerate(tt):\n",
    "        errors[it]=np.linalg.norm(yy[:,it]-pr.exact(yy[:,0],t))\n",
    "    return np.mean(errors)\n",
    "\n",
    "Ns=[2**k for k in range(5,10)]\n",
    "maxOrder=6\n",
    "\n",
    "errorEx=np.zeros((maxOrder,len(Ns)))\n",
    "dts=    np.zeros(len(Ns))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for iN, N in enumerate(Ns):                                        # loop on the number of timesteps\n",
    "    tspan=np.linspace(0,pr.T_fin,N)\n",
    "    dts[iN]=tspan[1]-tspan[0]\n",
    "    for iorder in range(maxOrder):                                 # loop on the order\n",
    "        order=iorder+1\n",
    "        AB=lm.Adams_Bashforth(   FILL IN WITH THE CORRECT NUMBER    # Load the AB method of order order\n",
    "        y_0 = np.zeros((len(pr.u0),order))\n",
    "        for j in range(order):                                     # loop to initialize the first steps\n",
    "            y_0[:,j] = pr.exact(pr.u0,tspan[j])\n",
    "        tt,yy=multiAB(    FILL IN THE CORRECT VARIABLES            # Compute the simulation\n",
    "        errorEx[iorder,iN]=error(tt,yy)                            # compute the error\n",
    "\n",
    "plt.figure()\n",
    "for iorder in range(maxOrder):\n",
    "    order=iorder+1\n",
    "    plt.loglog(dts,errorEx[iorder,:],label=\"AB\"+str(order))\n",
    "    plt.loglog(dts,dts**(order)*errorEx[iorder,2]/dts[2]**order,\":\", label=\"order %d\"%(order))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pro exercise** Code the combined Adams Moulton Bashforth method\n",
    "Example $k$th order:\n",
    "\n",
    "$$\n",
    "y^{*,n+1}=y^n +\\Delta t \\sum_{j=1}^k b^{AB}_{n,j,k} F(y^{n+1-j})\\\\\n",
    "y^{n+1} = y^{n} +\\Delta t b^{AM}_{n,0,k-1} F(y^{*,n+1}) + \\Delta t \\sum_{j=1}^{k-1} b^{AM}_{n,j,k-1} F(y^{n+1-j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADAMS moulton Bashforth\n",
    "# We combine the two methods, in order to get something positive\n",
    "## explicit Adams Bashforth method\n",
    "def multiAMB(flux, tspan, y_0, bAB, bAM):\n",
    "    # Solving u'=F(u,t)\n",
    "    # input: flux=F, tspan is a vector of times determining the RK steps\n",
    "    # input: y_0 the initial condition with the first k values of the solution\n",
    "    # input: bAB are k+1 b_j coefficients where the last one is 0 of Adam Bashforth\n",
    "    # input: bAB are k b_j coefficients of Adams Moulton\n",
    "    N_time=len(tspan)  # N+1\n",
    "    dim=y_0.shape[0]          # S\n",
    "    y=np.zeros((dim,N_time))    # initializing the variable of solutions\n",
    "    k = len(bAB)-1                # size of AB\n",
    "    if y_0.shape[1] < k:\n",
    "        raise ValueError(\"Input vector is too small\")\n",
    "    y[:,:k]=y_0                  # first timesteps \n",
    "    n0=k-1                       # last index assigned\n",
    "    Fu=np.zeros((dim,k))         # Flux at internal stages\n",
    "\n",
    "    \n",
    "    \n",
    "    CODE THE METHOD DESCRIBED ABOVE\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return tspan, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if it works\n",
    "order = 2\n",
    "N=100 #5\n",
    "AB=lm.Adams_Bashforth(order)\n",
    "AM=lm.Adams_Moulton(order-1)\n",
    "pr=ODEproblem(\"linear_system2\")\n",
    "t_span=np.linspace(0,pr.T_fin,N)\n",
    "y_0 = np.zeros((len(pr.u0),order))\n",
    "for j in range(order):\n",
    "    y_0[:,j] = pr.exact(pr.u0,t_span[j])\n",
    "    \n",
    "tt,uu=multiAMB(pr.flux,t_span,y_0,AB.beta, AM.beta)\n",
    "plt.plot(tt,uu[0,:])\n",
    "plt.plot(tt,uu[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST CONVERGENCE on the usual problem and usual timesteps\n",
    "pr=ODEproblem(\"linear_system2\")\n",
    "def error(tt,yy):\n",
    "    errors=np.zeros(len(tt))\n",
    "    for it, t in enumerate(tt):\n",
    "        errors[it]=np.linalg.norm(yy[:,it]-pr.exact(yy[:,0],t))\n",
    "    return np.mean(errors)\n",
    "\n",
    "Ns=[2**k for k in range(5,10)]\n",
    "orders=range(2,7)\n",
    "maxOrder=len(orders)\n",
    "\n",
    "errorEx=np.zeros((maxOrder,len(Ns)))\n",
    "dts=    np.zeros(len(Ns))\n",
    "\n",
    "\n",
    "\n",
    "# Compute the error for orders and Ns as above and \n",
    "# plot it in a reasonable scale in order to compare it with a reference order"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
